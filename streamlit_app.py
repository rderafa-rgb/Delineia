# -*- coding: utf-8 -*-

import streamlit as st
from datetime import datetime, timezone, timedelta 
from research_pipeline import ResearchScopePipeline, OpenAlexClient, CooccurrenceAnalyzer, OPENALEX_EMAIL
from pdf_generator import generate_pdf_report
import pandas as pd
import networkx as nx
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
import json
import zipfile
from io import BytesIO
import numpy as np
from scipy import stats
import gspread
from google.oauth2.service_account import Credentials
import uuid
import time as time_module
import matplotlib.pyplot as plt

# ==================== GOOGLE SHEETS CONFIG ====================
GOOGLE_SHEETS_URL = "https://docs.google.com/spreadsheets/d/1BE2le2ZVm2ej20w7UF5T7RSjO-V_Ii0RuhZQ2vEQQLY/edit"
ABA_FORMULARIO_INICIAL = "formulario_inicial"
ABA_RESULTADOS_PIPELINE = "resultados_pipeline"
ABA_FORMULARIO_AVALIACAO = "formulario_avaliacao"

@st.cache_resource(show_spinner=False)
def conectar_google_sheets():
    """
    Conecta ao Google Sheets usando credenciais do Streamlit Secrets
    CORRE√á√ÉO APLICADA: Tratamento da private_key para converter 
    \\n literal em quebras de linha reais.
    """
    SCOPES = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    
    try:
        # Ler credenciais DOS SECRETS
        google_creds = st.secrets["google_credentials"]
        
        # Converter para dict
        creds_dict = dict(google_creds)
        
        if "private_key" in creds_dict:
            # Primeiro tenta substituir \\n (escaped)
            pk = creds_dict["private_key"]
            if "\\n" in pk:
                pk = pk.replace("\\n", "\n")
            creds_dict["private_key"] = pk
        
        # Criar credenciais a partir do dict
        creds = Credentials.from_service_account_info(
            creds_dict,
            scopes=SCOPES
        )
        
        # Autorizar e abrir planilha
        client = gspread.authorize(creds)
        sheet = client.open_by_url(GOOGLE_SHEETS_URL)
        
        print("‚úÖ Conex√£o com Google Sheets estabelecida!")
        return sheet
        
    except Exception as e:
        st.error(f"‚ùå Erro ao conectar Google Sheets: {e}")
        import traceback
        print(f"Detalhes do erro: {traceback.format_exc()}")
        return None

def enviar_formulario_inicial(form_data):
    """Envia dados do formul√°rio inicial para Google Sheets"""
    try:
        sheet = conectar_google_sheets()
        
        if not sheet:
            return None
        
        worksheet = sheet.worksheet(ABA_FORMULARIO_INICIAL)
                
        # Gerar ID √∫nico
        id_usuario = f"user_{uuid.uuid4().hex[:8]}"
        
        # Preparar linha
        row = [
            id_usuario,
            form_data['timestamp'],
            form_data['nome'],
            form_data['email'],
            form_data['tema'],
            form_data['questao'],
            form_data['palavras_chave'],
            form_data.get('google_academico', ''),
            form_data.get('confianca', '')
        ]
        
        worksheet.append_row(row, value_input_option='RAW')
        return id_usuario
        
    except Exception as e:
        st.error(f"‚ùå Erro ao enviar formul√°rio: {e}")
        return None

def enviar_resultados_pipeline(id_usuario, result, tempo_segundos):
    """Envia resultados do pipeline para Google Sheets"""
    try:
        sheet = conectar_google_sheets()
        if sheet is None:
            return False
        
        worksheet = sheet.worksheet(ABA_RESULTADOS_PIPELINE)
        
        # Preparar linha
        top_conceitos_str = ",".join(result.get('top_concepts', [])[:9])
        
        row = [
            id_usuario,
            datetime.now().strftime("%d/%m/%Y √†s %H:%M"),
            result.get('search_string', ''),
            '',  # termos_sugeridos
            result.get('full_report', '')[:500],
            result.get('search_objective', ''),
            result.get('articles_count', 0),
            top_conceitos_str,
            result['graph_stats']['nodes'],
            result['graph_stats']['edges'],
            result['graph_stats'].get('density', 0),
            round(tempo_segundos, 2)
        ]
        
        worksheet.append_row(row, value_input_option='RAW')
        return True
        
    except Exception as e:
        st.error(f"‚ùå Erro ao enviar resultados: {e}")
        return False

def enviar_formulario_avaliacao(id_usuario, avaliacao_data):
    """Envia avalia√ß√£o do usu√°rio para Google Sheets"""
    try:
        sheet = conectar_google_sheets()
        if sheet is None:
            return False
        
        worksheet = sheet.worksheet(ABA_FORMULARIO_AVALIACAO)
        
        # Calcular tempo total
        tempo_total = 0
        if 'timestamp_formulario_inicial' in st.session_state:
            tempo_total = round(time_module.time() - st.session_state.timestamp_formulario_inicial, 2)
        
        # Preparar linha
        row = [
            id_usuario,
            datetime.now().strftime("%d/%m/%Y √†s %H:%M"),
            avaliacao_data.get('q1', ''),
            avaliacao_data.get('q2', ''),
            avaliacao_data.get('q3', ''),
            avaliacao_data.get('q4', ''),
            avaliacao_data.get('q5', ''),
            avaliacao_data.get('q6', ''),
            avaliacao_data.get('q7', ''),
            avaliacao_data.get('q8', ''),
            avaliacao_data.get('q9', ''),
            avaliacao_data.get('q10', ''),
            avaliacao_data.get('q11', ''),
            avaliacao_data.get('q12', ''),
            avaliacao_data.get('q13', ''),
            avaliacao_data.get('q14', ''),
            avaliacao_data.get('q15', ''),
            avaliacao_data.get('q16', ''),
            avaliacao_data.get('q17', ''),
            avaliacao_data.get('q18', ''),
            avaliacao_data.get('q19', ''),
            avaliacao_data.get('q20', ''),
            avaliacao_data.get('nps', 0),
            avaliacao_data.get('nps_category', ''),
            avaliacao_data.get('q22', ''),
            avaliacao_data.get('q23', ''),
            avaliacao_data.get('q24', ''),
            avaliacao_data.get('q25', ''),
            avaliacao_data.get('q26', ''),
            avaliacao_data.get('q27', ''),
            avaliacao_data.get('q28', ''),
            avaliacao_data.get('q29', ''),
            avaliacao_data.get('q30', ''),
            'Sim' if avaliacao_data.get('aceite_continuidade', False) else 'N√£o',
            ",".join(st.session_state.get('badges', [])),
            tempo_total,
            st.session_state.get('play_video', False),
            st.session_state.get('open_prologo', False)
        ]
        
        worksheet.append_row(row, value_input_option='RAW')
        return True
        
    except Exception as e:
        st.error(f"‚ùå Erro ao enviar avalia√ß√£o: {e}")
        return False

# ==================== FUN√á√ÉO DE AN√ÅLISE DE ZIPF =================
def analyze_zipf(frequency_data):
    """
    Analisa a distribui√ß√£o de frequ√™ncias segundo a Lei de Zipf

    Args:
        frequency_data: Lista de tuplas (palavra, frequ√™ncia) ordenada por frequ√™ncia

    Returns:
        dict com m√©tricas e dados para plotagem
    """
    # Extrair frequ√™ncias
    frequencies = [freq for _, freq in frequency_data]

    # Criar ranks (1, 2, 3, ...)
    ranks = np.arange(1, len(frequencies) + 1)

    # Converter para arrays numpy
    ranks_array = np.array(ranks)
    freq_array = np.array(frequencies)

    # Aplicar log para an√°lise linear
    log_ranks = np.log10(ranks_array)
    log_freqs = np.log10(freq_array)

    # Regress√£o linear no espa√ßo log-log
    slope, intercept, r_value, p_value, std_err = stats.linregress(log_ranks, log_freqs)

    # Calcular R¬≤
    r_squared = r_value ** 2

    # Gerar linha de tend√™ncia
    trend_line = 10 ** (slope * log_ranks + intercept)

    # Interpreta√ß√£o
    if r_squared > 0.90:
        interpretation = "‚úÖ Forte ader√™ncia √† Lei de Zipf"
        quality = "excelente"
    elif r_squared > 0.75:
        interpretation = "‚ö†Ô∏è Ader√™ncia moderada √† Lei de Zipf"
        quality = "boa"
    else:
        interpretation = "‚ùå Fraca ader√™ncia √† Lei de Zipf"
        quality = "baixa"

    # An√°lise da inclina√ß√£o
    if -1.2 < slope < -0.8:
        slope_interpretation = "pr√≥ximo ao ideal (-1.0)"
    elif slope < -1.2:
        slope_interpretation = "vocabul√°rio mais concentrado que o esperado"
    else:
        slope_interpretation = "vocabul√°rio mais disperso que o esperado"

    return {
        'ranks': ranks_array,
        'frequencies': freq_array,
        'log_ranks': log_ranks,
        'log_freqs': log_freqs,
        'trend_line': trend_line,
        'slope': slope,
        'intercept': intercept,
        'r_squared': r_squared,
        'p_value': p_value,
        'interpretation': interpretation,
        'quality': quality,
        'slope_interpretation': slope_interpretation
    }

# ==================== CONFIGURA√á√ÉO DA P√ÅGINA ====================
st.set_page_config(
    page_title="Delin√©ia",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== CSS CUSTOMIZADO (BOT√ïES VERDES) ====================
st.markdown("""
<style>
    /* Bot√µes prim√°rios em verde claro */
    .stButton > button[kind="primary"] {
        background-color: #10b981 !important;
        color: white !important;
        border: none !important;
    }
    
    .stButton > button[kind="primary"]:hover {
        background-color: #059669 !important;
        color: white !important;
    }
    
    .stButton > button[kind="primary"]:active {
        background-color: #047857 !important;
    }
    
    /* Form submit buttons */
    .stFormSubmitButton > button {
        background-color: #10b981 !important;
        color: white !important;
        border: none !important;
    }
    
    .stFormSubmitButton > button:hover {
        background-color: #059669 !important;
    }
    
    /* Download buttons com type="primary" */
    .stDownloadButton > button[kind="primary"] {
        background-color: #10b981 !important;
        color: white !important;
    }
</style>
""", unsafe_allow_html=True)

# ==================== ESTADOS DA SESS√ÉO ====================
if 'step' not in st.session_state:
    st.session_state.step = 1
if 'resultado' not in st.session_state:
    st.session_state.resultado = None
if 'form_data' not in st.session_state:
    st.session_state.form_data = {}
if 'dashboard_data' not in st.session_state:
    st.session_state.dashboard_data = None
if 'dashboard_query' not in st.session_state:
    st.session_state.dashboard_query = ""
if 'avaliacao_completa' not in st.session_state:
    st.session_state.avaliacao_completa = False
if 'badges' not in st.session_state:
    st.session_state.badges = []
if 'play_video' not in st.session_state:
    st.session_state.play_video = False
if 'open_prologo' not in st.session_state:
    st.session_state.open_prologo = False
if 'selected_concepts' not in st.session_state:
    st.session_state.selected_concepts = []
if 'interpretation_generated' not in st.session_state:
    st.session_state.interpretation_generated = False
if 'personalized_interpretation' not in st.session_state:
    st.session_state.personalized_interpretation = None
if 'suggested_keywords' not in st.session_state:
    st.session_state.suggested_keywords = []
if 'suggested_strings' not in st.session_state:
    st.session_state.suggested_strings = {}
if 'sub_step' not in st.session_state:
    st.session_state.sub_step = 'a'  # 'a', 'b', 'c'

# ==================== FUN√á√ïES AUXILIARES ====================
def add_badge(badge_name: str) -> bool:
    """Adiciona badge ao perfil do usu√°rio"""
    if badge_name not in st.session_state.badges:
        st.session_state.badges.append(badge_name)
        return True
    return False

# ==================== ABAS PRINCIPAIS ====================
tab1, tab2 = st.tabs(["üìö Delineasc√≥pio", "üìä Painel"])

# ==================== ABA 1: DELINEASC√ìPIO ====================
with tab1:
    st.title("üìö Delin√©ia - Delineamento de Escopo Tem√°tico")
    st.caption("Sistema de apoio ao delineamento de projetos de pesquisa com IA e Bibliometria")

    # Barra de progresso gamificada (5 etapas)
    sub_step = st.session_state.get('sub_step', 'a')
    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        if st.session_state.step >= 1:
            st.success("‚úÖ 1. Formul√°rio inicial")
            if 'üéØ Explorador' not in st.session_state.badges:
                add_badge('üéØ Explorador')
        else:
            st.info("‚è≥ 1. Formul√°rio inicial")

    with col2:
        if st.session_state.step >= 2:
            st.success("‚úÖ 2. Grafo de conceitos")
            if 'üî¨ Pesquisador' not in st.session_state.badges:
                add_badge('üî¨ Pesquisador')
        else:
            st.info("‚è≥ 2. Grafo de conceitos")

    with col3:
        if st.session_state.step >= 2 and sub_step in ['b', 'c']:
            st.success("‚úÖ 3. Sele√ß√£o de conceitos")
            if 'üß© Seletor' not in st.session_state.badges:
                add_badge('üß© Seletor')
        elif st.session_state.step == 2 and sub_step == 'a':
            st.info("‚è≥ 3. Sele√ß√£o de conceitos")
        else:
            st.info("‚è≥ 3. Sele√ß√£o de conceitos")

    with col4:
        if st.session_state.step >= 2 and sub_step == 'c':
            st.success("‚úÖ 4. Relat√≥rio")
            if 'üèÜ Delineador' not in st.session_state.badges:
                add_badge('üèÜ Delineador')
        elif st.session_state.step > 2:
            st.success("‚úÖ 4. Relat√≥rio")
            if 'üèÜ Delineador' not in st.session_state.badges:
                add_badge('üèÜ Delineador')
        else:
            st.info("‚è≥ 4. Relat√≥rio")

    with col5:
        if st.session_state.get('avaliacao_completa', False):
            st.success("‚úÖ 5. Avalia√ß√£o")
            if 'üíé Avaliador' not in st.session_state.badges:
                add_badge('üíé Avaliador')
        elif st.session_state.step >= 3:
            st.warning("üîÑ 5. Avalia√ß√£o")
        else:
            st.info("‚è≥ 5. Avalia√ß√£o")

    # Mostrar badges conquistados
    if st.session_state.badges:
        st.markdown(f"**üèÖ Conquistas:** {' '.join(st.session_state.badges)}")

    st.divider()

    # ========== ETAPA 1: FORMUL√ÅRIO INICIAL ==========
    if st.session_state.step == 1:
        st.header("üìù 1. Formul√°rio Inicial")

        with st.form("formulario_inicial"):
            st.subheader("üë§ Identifica√ß√£o")
            col1, col2 = st.columns(2)

            with col1:
                nome = st.text_input(
                    "Nome completo*",
                    placeholder="Ex: Ana Silva",
                    help="Seu nome completo"
                )

            with col2:
                email = st.text_input(
                    "E-mail*",
                    placeholder="Ex: ana@email.com",
                    help="Seu e-mail para contato"
                )

            st.divider()
            st.subheader("üî¨ Projeto de Pesquisa")

            tema = st.text_input(
                "F1.1. Tema da Pesquisa*",
                placeholder="Ex: Jogos como estrat√©gia de ensino e aprendizagem na escola",
                help="Tema principal do seu projeto"
            )

            questao = st.text_area(
                "F1.2. Quest√£o de Pesquisa*",
                placeholder="Ex: Qual a percep√ß√£o dos professores sobre a efic√°cia dos jogos como estrat√©gia de ensino e aprendizagem na escola?",
                height=100,
                help="Pergunta principal que voc√™ quer responder"
            )

            palavras_chave = st.text_input(
                "F1.3. Palavras-chave* (separadas entre v√≠rgulas)",
                placeholder="Ex: Jogos, Ensino, Aprendizagem, Percep√ß√£o dos professores",
                help="Separe as palavras-chave por v√≠rgula"
            )

            google_academico = st.text_area(
                "F1.4. Se voc√™ fosse pesquisar refer√™ncias para seu projeto no Google Acad√™mico, o que voc√™ colocaria no campo de busca?*",
                placeholder="Ex: Uso de jogos na escola",
                help="Campo livre para indicar palavras, frases, etc. que voc√™ quer pesquisar",
                height=100
            )

            st.divider()
            st.subheader("üí≠ Autoavalia√ß√£o")

            confianca = st.radio(
                "F1.5. Qual seu n√≠vel de seguran√ßa em rela√ß√£o √†s palavras-chave escolhidas?",
                options=[
                    "Totalmente seguro",
                    "Seguro",
                    "Neutro",
                    "Inseguro",
                    "Totalmente inseguro"
                ],
                index=2,  # Neutro como padr√£o
                horizontal=True,
                help="Selecione seu n√≠vel de confian√ßa nas palavras-chave escolhidas"
            )
       
            st.divider()

            submitted = st.form_submit_button(
                "üöÄ Gerar Relat√≥rio de Delineamento",
                type="primary",
                use_container_width=True
            )

            if submitted:
                if not all([nome, email, tema, questao, palavras_chave]):
                    st.error("‚ö†Ô∏è Por favor, preencha todos os campos obrigat√≥rios (*)")
                else:
                    # Salvar dados do formul√°rio
                    st.session_state.form_data = {
                        'nome': nome,
                        'email': email,
                        'tema': tema,
                        'questao': questao,
                        'palavras_chave': palavras_chave,
                        'confianca': confianca,
                        'google_academico': google_academico,
                        'timestamp': datetime.now(timezone(timedelta(hours=-3))).strftime("%d/%m/%Y √†s %H:%M")
                    }

                    # Enviar para Google Sheets e salvar ID
                    id_usuario = enviar_formulario_inicial(st.session_state.form_data)
                    if id_usuario:
                        st.session_state.id_usuario = id_usuario
                        st.session_state.timestamp_formulario_inicial = time_module.time()

                    with st.spinner("üîÑ Processando... (aguarde 4-5 minutos)"):
                        try:
                            # Inicializar pipeline
                            pipe = ResearchScopePipeline(OPENALEX_EMAIL)

                            # Processar palavras-chave
                            kws = [k.strip() for k in palavras_chave.split(',') if k.strip()]

                            # Executar pipeline
                            tempo_inicio = time_module.time()
                            st.session_state.resultado = pipe.process(nome, tema, questao, kws)
                            tempo_fim = time_module.time()

                            # Enviar resultados para Google Sheets
                            if 'id_usuario' in st.session_state:
                                enviar_resultados_pipeline(
                                    st.session_state.id_usuario,
                                    st.session_state.resultado,
                                    tempo_fim - tempo_inicio
                                )

                            # Avan√ßar para pr√≥xima etapa
                            st.session_state.step = 2
                            st.rerun()

                        except Exception as e:
                            st.error(f"‚ùå Erro ao processar: {str(e)}")
                            st.exception(e)

    # ========== ETAPA 2: TRILHA DE APRENDIZAGEM ATIVA ==========
    elif st.session_state.step == 2:
        d = st.session_state.form_data
        r = st.session_state.resultado
        sub_step = st.session_state.get('sub_step', 'a')

        # ========== SUB-ETAPA 2a: VISUALIZA√á√ÉO DO GRAFO ==========
        if sub_step == 'a':
            st.header("üï∏Ô∏è 2. Grafo de conceitos")
            st.caption("Etapa 2: Explore o grafo e o gloss√°rio antes de selecionar os conceitos")

            # Bot√£o voltar
            if st.button("‚¨ÖÔ∏è Voltar ao Formul√°rio"):
                st.session_state.step = 1
                st.rerun()

            st.divider()

            # Informa√ß√µes do projeto (resumido)
            with st.expander("üìã Dados do Projeto", expanded=False):
                st.write(f"**Tema:** {d['tema']}")
                st.write(f"**Quest√£o:** {d['questao']}")
                st.write(f"**Palavras-chave:** {d['palavras_chave']}")

            # M√©tricas
            col1, col2, col3 = st.columns(3)
            col1.metric("üìö Artigos Analisados", r.get('articles_count', 0))
            col2.metric("üß© Conceitos no Grafo", r['graph_stats']['nodes'])
            col3.metric("üîó Conex√µes", r['graph_stats']['edges'])

            # Layout: Grafo e Gloss√°rio lado a lado
            col_grafo, col_glossario = st.columns([1, 1])

            with col_grafo:
                st.subheader("üï∏Ô∏è Grafo de Coocorr√™ncias")
                if r.get('visualization_path'):
                    st.image(r['visualization_path'], use_container_width=True)
                else:
                    st.warning("‚ö†Ô∏è Visualiza√ß√£o n√£o dispon√≠vel")

            with col_glossario:
                st.subheader("üìñ Gloss√°rio de Conceitos")
                with st.container(height=400):
                    st.markdown(r.get('glossary', '‚ö†Ô∏è Gloss√°rio n√£o dispon√≠vel'))

            # Instru√ß√£o para pr√≥xima etapa
            st.divider()
            st.info("""
            üí° **Pr√≥ximo passo:** Observe atentamente o grafo e o gloss√°rio acima. 
            Na pr√≥xima etapa, voc√™ selecionar√° os conceitos mais relevantes para sua pesquisa.
            Essa sele√ß√£o ser√° usada para gerar uma interpreta√ß√£o personalizada do grafo.
            """)

            # Bot√£o avan√ßar
            if st.button("Continuar para Sele√ß√£o de Conceitos ‚ñ∂Ô∏è", type="primary", use_container_width=True):
                st.session_state.sub_step = 'b'
                st.rerun()

        # ========== SUB-ETAPA 2b: SELE√á√ÉO DE CONCEITOS ==========
        elif sub_step == 'b':
            top_concepts = r.get('top_concepts', [])[:9]

            st.header("üéØ 3. Sele√ß√£o de Conceitos")
            st.caption("Etapa 3: Escolha os conceitos mais relevantes para sua pesquisa")

            # Navega√ß√£o
            if st.button("‚¨ÖÔ∏è Voltar ao Grafo"):
                st.session_state.sub_step = 'a'
                st.rerun()

            st.divider()

            # Contexto
            primeiro_nome = d['nome'].split()[0]
            st.markdown(f"""
            ### {primeiro_nome}, quais conceitos do grafo s√£o mais relevantes para seu projeto?

            Considerando seu tema **"{d['tema']}"**, selecione os conceitos que voc√™ considera 
            mais importantes para o delineamento do escopo da sua pesquisa.

            *Selecione pelo menos 1 conceito para continuar.*
            """)

            # Mostrar grafo como refer√™ncia (menor)
            with st.expander("üï∏Ô∏è Ver grafo novamente", expanded=False):
                if r.get('visualization_path'):
                    st.image(r['visualization_path'], use_container_width=True)

            st.divider()

            # Sele√ß√£o de conceitos com checkboxes
            st.subheader("üìã Conceitos Identificados na Rede")

            # Criar 3 colunas para os checkboxes
            cols = st.columns(3)
            selected = []

            for i, concept in enumerate(top_concepts):
                col_idx = i % 3
                with cols[col_idx]:
                    # Verificar se j√° estava selecionado antes
                    default_value = concept in st.session_state.get('selected_concepts', [])
                    if st.checkbox(concept, value=default_value, key=f"concept_{i}"):
                        selected.append(concept)

            # Atualizar session_state
            st.session_state.selected_concepts = selected

            # Contador
            st.divider()
            num_selected = len(selected)

            if num_selected == 0:
                st.warning("‚ö†Ô∏è Selecione pelo menos 1 conceito para continuar")
            else:
                st.success(f"‚úÖ **{num_selected} conceito(s) selecionado(s):** {', '.join(selected)}")

            # Bot√£o avan√ßar (s√≥ habilitado se tiver sele√ß√£o)
            st.divider()

            col1, col2 = st.columns(2)

            with col2:
                if num_selected >= 1:
                    if st.button("Gerar Relat√≥rio de Delineamento ‚ñ∂Ô∏è", type="primary", use_container_width=True):
                        with st.spinner("üîÑ Gerando relat√≥rio... (aguarde 2-3 minutos)"):
                            # Gerar conte√∫do personalizado
                            from research_pipeline import GeminiQueryGenerator
                            gemini = GeminiQueryGenerator()

                            primeiro_nome = d['nome'].split()[0]
                            tema = d['tema']
                            original_kws = [k.strip() for k in d.get('palavras_chave', '').split(',') if k.strip()]
                            all_concepts = r.get('top_concepts', [])[:9]

                            # Gerar interpreta√ß√£o contextualizada
                            st.session_state.personalized_interpretation = gemini.generate_contextualized_interpretation(
                                tema, primeiro_nome, selected, all_concepts
                            )

                            # Gerar sugest√µes de palavras-chave
                            st.session_state.suggested_keywords = gemini.generate_keyword_suggestions(
                                tema, primeiro_nome, selected, original_kws
                            )

                            # Gerar chaves de busca (agora passando os termos ricos!)
                            st.session_state.suggested_strings = gemini.generate_search_strings(
                                tema, 
                                selected, 
                                original_kws,
                                st.session_state.suggested_keywords  # <-- NOVO PAR√ÇMETRO
                            )

                            st.session_state.interpretation_generated = True

                        st.session_state.sub_step = 'c'
                        st.rerun()
                else:
                    st.button("Gerar Interpreta√ß√£o Personalizada ‚ñ∂Ô∏è", disabled=True, use_container_width=True)

        # ========== SUB-ETAPA 2c: INTERPRETA√á√ÉO PERSONALIZADA ==========
        elif sub_step == 'c':
            selected = st.session_state.get('selected_concepts', [])

            st.header("üìã 4. Relat√≥rio")
            st.caption("Etapa 4: Interpreta√ß√£o baseada nos conceitos que voc√™ selecionou")

            # Navega√ß√£o
            col_nav1, col_nav2 = st.columns([1, 3])
            with col_nav1:
                if st.button("‚¨ÖÔ∏è Voltar √† Sele√ß√£o"):
                    st.session_state.sub_step = 'b'
                    st.rerun()

            st.divider()

            # Resumo da sele√ß√£o
            st.success(f"‚úÖ **Conceitos selecionados:** {', '.join(selected)}")

            # Informa√ß√µes do projeto
            with st.container(border=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**üë§ Aluno:** {d['nome']}")
                    st.write(f"**üìß E-mail:** {d['email']}")
                with col2:
                    st.write(f"**üìÖ Data:** {d['timestamp']}")
                    st.write(f"**üí≠ Confian√ßa:** {d['confianca']}")

            with st.container(border=True):
                st.write(f"**üéØ Tema:** {d['tema']}")
                st.write(f"**‚ùì Quest√£o:** {d['questao']}")
                st.write(f"**üîë Palavras-chave:** {d['palavras_chave']}")

            # ========== SE√á√ÉO 1: AVALIA√á√ÉO INICIAL DO PROJETO ==========
            st.subheader("üìã Avalia√ß√£o do Projeto")
            with st.container(border=True):
                st.markdown(r.get('full_report', '‚ö†Ô∏è Avalia√ß√£o n√£o dispon√≠vel'))

            # ========== SE√á√ÉO 2: INTERPRETA√á√ÉO PERSONALIZADA ==========
            st.subheader("üí° Interpreta√ß√£o Personalizada do Grafo")
            with st.container(border=True):
                interpretation = st.session_state.get('personalized_interpretation', '')
                if interpretation:
                    st.markdown(interpretation)
                else:
                    st.markdown(r.get('graph_interpretation', '‚ö†Ô∏è Interpreta√ß√£o n√£o dispon√≠vel'))

            # ========== SE√á√ÉO 3: GRAFO ==========
            st.subheader("üï∏Ô∏è Grafo de Coocorr√™ncias")
            if r.get('visualization_path'):
                st.image(r['visualization_path'], use_container_width=True)

            # ========== SE√á√ÉO 4: GLOSS√ÅRIO ==========
            st.subheader("üìñ Gloss√°rio de Conceitos")
            with st.expander("Ver gloss√°rio completo", expanded=False):
                st.markdown(r.get('glossary', '‚ö†Ô∏è Gloss√°rio n√£o dispon√≠vel'))

            # ========== SE√á√ÉO 5: SUGEST√ïES DE PALAVRAS-CHAVE ==========
            st.subheader("üîë Sugest√µes de Palavras-chave")

            suggested_kws = st.session_state.get('suggested_keywords', [])

            if suggested_kws:
                for kw in suggested_kws:
                    with st.container(border=True):
                        col1, col2 = st.columns([1, 3])
                        with col1:
                            st.markdown(f"**{kw.get('term_en', 'N/A')}**")
                            st.caption(f"({kw.get('term_pt', 'N/A')})")
                        with col2:
                            st.write(kw.get('description', ''))
            else:
                st.info("Sugest√µes de palavras-chave n√£o dispon√≠veis")

            # ========== SE√á√ÉO 6: CHAVES DE BUSCA SUGERIDAS ==========
            st.subheader("üîé Chaves de Busca Sugeridas")
            st.caption("Copie as chaves de busca abaixo para usar no Painel ou em bases de dados")

            suggested_strings = st.session_state.get('suggested_strings', {})

            if suggested_strings:
                for key, data in suggested_strings.items():
                    with st.container(border=True):
                        st.markdown(f"**{data.get('titulo', key)}**")
                        st.caption(data.get('descricao', ''))

                        col_str, col_btn = st.columns([4, 1])

                        with col_str:
                            st.code(data.get('string', ''), language='text')

                        with col_btn:
                            if st.button("üìã Copiar", key=f"copy_{key}", use_container_width=True):
                                st.session_state.dashboard_query = data.get('string', '')
                                st.toast(f"‚úÖ Chave de busca copiada para o Painel!")
            else:
                # Fallback: mostrar chave de busca original
                search_string = r.get('search_string', 'N/A')
                with st.container(border=True):
                    st.markdown("**üîé Chave de Busca Original**")
                    col_str, col_btn = st.columns([4, 1])
                    with col_str:
                        st.code(search_string, language='text')
                    with col_btn:
                        if st.button("üìã Copiar", key="copy_original", use_container_width=True):
                            st.session_state.dashboard_query = search_string
                            st.toast("‚úÖ Chave de busca copiada para o Painel!")

            # ========== SE√á√ÉO 7: CHAVE DE TRANSPAR√äNCIA (ORIGINAL OPENALEX) ==========
            st.subheader("üî¨ Transpar√™ncia: Chave de Busca Usada")
            st.caption("Esta √© a chave de busca exata que foi usada para recuperar artigos do OpenAlex")
            
            with st.container(border=True):
                # Mostrar objetivo da busca
                search_objective = r.get('search_objective', '')
                if search_objective:
                    st.markdown(f"**Objetivo:** {search_objective}")
                    st.divider()
                
                # Mostrar chave original
                search_string = r.get('search_string', 'N/A')
                st.markdown("**Chave de busca executada:**")
                
                col_str, col_btn = st.columns([4, 1])
                
                with col_str:
                    st.code(search_string, language='text')
                
                with col_btn:
                    if st.button("üìã Copiar", key="copy_transparency", use_container_width=True):
                        st.session_state.dashboard_query = search_string
                        st.toast("‚úÖ Chave de busca copiada para o Painel!")
                
                # Estat√≠sticas
                articles_count = r.get('articles_count', 0)
                graph_stats = r.get('graph_stats', {})
                
                st.caption(f"üìä Resultados: {articles_count} artigos encontrados | "
                          f"{graph_stats.get('nodes', 0)} conceitos | "
                          f"{graph_stats.get('edges', 0)} coocorr√™ncias")
            
            # ========== SE√á√ÉO 8: A√á√ïES FINAIS ==========
            st.divider()

            col1, col2, col3 = st.columns(3)

            with col1:
                # PDF dispon√≠vel ap√≥s completar a trilha
                try:
                    # Adicionar dados da sele√ß√£o ao resultado para o PDF
                    r_completo = r.copy()
                    r_completo['selected_concepts'] = selected
                    r_completo['personalized_interpretation'] = st.session_state.get('personalized_interpretation', '')
                    r_completo['suggested_keywords'] = st.session_state.get('suggested_keywords', [])
                    r_completo['suggested_strings'] = st.session_state.get('suggested_strings', {})

                    pdf_bytes = generate_pdf_report(d, r_completo)
                    st.download_button(
                        "üì• Baixar PDF Completo",
                        pdf_bytes,
                        f"delineamento_{d['nome'].replace(' ', '_')}.pdf",
                        "application/pdf",
                        use_container_width=True,
                        type="primary"
                    )
                except Exception as e:
                    st.error(f"Erro ao gerar PDF: {str(e)}")

            with col2:
                if st.button("üìä Ir ao Painel", use_container_width=True):
                    st.info("üí° Use as chaves de busca sugeridas para explorar mais a literatura no Painel!")

            with col3:
                if st.button("üìù Avaliar Sistema", type="primary", use_container_width=True):
                    st.session_state.step = 3
                    st.rerun()

            # Dica final
            st.divider()
            st.info("""
            üéâ **Parab√©ns!** Voc√™ completou a trilha de delineamento!

            Agora voc√™ pode:
            - üì• **Baixar o PDF** com o relat√≥rio completo
            - üìä **Usar o Painel** para explorar mais a literatura
            - üìù **Avaliar o sistema** e nos ajudar a melhorar
            """)

            # Bot√£o novo projeto
            if st.button("üîÑ Iniciar Novo Projeto", use_container_width=True):
                st.session_state.step = 1
                st.session_state.resultado = None
                st.session_state.form_data = {}
                st.session_state.avaliacao_completa = False
                st.session_state.badges = []
                st.session_state.sub_step = 'a'
                st.session_state.selected_concepts = []
                st.session_state.interpretation_generated = False
                st.session_state.personalized_interpretation = None
                st.session_state.suggested_keywords = []
                st.session_state.suggested_strings = {}
                st.rerun()

# ========== ETAPA 3: AVALIA√á√ÉO EXPANDIDA ==========
    elif st.session_state.step == 3:
        st.header("‚≠ê 5. Avalia√ß√£o")
        st.caption("Suas respostas s√£o fundamentais para aprimorarmos o sistema!")

        st.info("""
üìä **Termo de Consentimento Livre e Esclarecido**
 
Convidamos voc√™ a participar da pesquisa sobre o uso de palavras-chave na pesquisa acad√™mica. Sua participa√ß√£o √© totalmente volunt√°ria, e voc√™ pode desistir a qualquer momento sem nenhum preju√≠zo.

O objetivo do estudo √© investigar como a avalia√ß√£o automatizada de defini√ß√µes preliminares de um projeto, como tema, quest√£o de pesquisa e palavras-chave, pode apoiar estudantes no delineamento do escopo do estudo e na delimita√ß√£o mais precisa de suas propostas.

Ressaltamos que nenhuma informa√ß√£o identific√°vel √© utilizada na pesquisa.

Caso tenha d√∫vidas ou necessite de mais informa√ß√µes, entre em contato por e-mail com o pesquisador respons√°vel, Rafael Antunes dos Santos (rafael.antunes@ufrgs.br), doutorando do Programa de P√≥s-Gradua√ß√£o em Inform√°tica na Educa√ß√£o, da Universidade Federal do Rio Grande do Sul.
                
Ao prosseguir com o preenchimento deste formul√°rio, voc√™ declara que entende os objetivos da pesquisa e concorda em participar voluntariamente.
""")

        with st.form("formulario_avaliacao"):

            # ==================== SE√á√ÉO 1: UTILIDADE PERCEBIDA ====================
            st.subheader("üíº Utilidade Percebida")

            q1 = st.radio(
                "F2.1. Usar o Delin√©ia melhora a minha capacidade de escolha de palavras-chave para o escopo da pesquisa",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q1"
            )

            q2 = st.radio(
                "F2.2. Usar o Delin√©ia aumenta minha produtividade na defini√ß√£o do projeto",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q2"
            )

            q3 = st.radio(
                "F2.3. O Delin√©ia √© √∫til para delimitar meu projeto de pesquisa",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q3"
            )

            q4 = st.radio(
                "F2.4. O Delin√©ia me ajuda a posicionar meu projeto na literatura do meu tema",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q4"
            )

            st.divider()

            # ==================== SE√á√ÉO 2: FACILIDADE DE USO ====================
            st.subheader("üéØ Facilidade de Uso Percebida")

            q5 = st.radio(
                "F2.5. O Delin√©ia √© f√°cil de usar",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q5"
            )

            q6 = st.radio(
                "F2.6. A intera√ß√£o com o Delin√©ia √© clara e compreens√≠vel",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q6"
            )

            q7 = st.radio(
                "F2.7. A navega√ß√£o entre as diferentes funcionalidades √© intuitiva",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q7"
            )

            st.divider()

            # ==================== SE√á√ÉO 3: QUALIDADE DA INFORMA√á√ÉO ====================
            st.subheader("üìä Qualidade da Informa√ß√£o")

            q8 = st.radio(
                "F2.8. As an√°lises e sugest√µes do Delin√©ia s√£o relevantes para meu projeto",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q8"
            )

            q9 = st.radio(
                "F2.9. A avalia√ß√£o gerada pela IA √© construtiva para meu projeto",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q9"
            )

            q10 = st.radio(
                "F2.10. As chaves de busca que foram oferecidas s√£o precisas para o meu tema",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q10"
            )

            q11 = st.radio(
                "F2.11. O grafo de coocorr√™ncias me ajudou a visualizar rela√ß√µes entre conceitos",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q11"
            )

            q12 = st.radio(
                "F2.12. O Delin√©ia me ajudou a formular perguntas de pesquisa mais precisas",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q12"
            )

            q13 = st.radio(
                "F2.13. O relat√≥rio em PDF √© adequado para apresentar ao meu orientador",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q13"
            )

            st.divider()

            # ==================== SE√á√ÉO 4: INTEN√á√ÉO DE USO ====================
            st.subheader("üîÆ Inten√ß√£o de Uso")

            q14 = st.radio(
                "F2.14. O tempo gasto usando o Delin√©ia compensa os resultados obtidos",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q14"
            )

            q15 = st.radio(
                "F2.15. Eu pretendo usar o Delin√©ia em projetos futuros",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q15"
            )

            q16 = st.radio(
                "F2.16. Eu usaria o Delin√©ia em diferentes fases da minha pesquisa (projeto, qualifica√ß√£o, defesa)",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q16"
            )

            st.divider()

            # ==================== SE√á√ÉO 5: CONFIAN√áA NO SISTEMA ====================
            st.subheader("üîí Confian√ßa no Sistema")

            q17 = st.radio(
                "F2.17. Eu confio nas an√°lises geradas pelo Delin√©ia",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q17"
            )

            q18 = st.radio(
                "F2.18. Eu me sinto confort√°vel em basear decis√µes acad√™micas com os resultados do Delin√©ia",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q18"
            )

            st.divider()

            # ==================== SE√á√ÉO 6: EXPERI√äNCIA DO USU√ÅRIO ====================
            st.subheader("‚ú® Experi√™ncia do Usu√°rio")

            q19 = st.radio(
                "F2.19. O design da interface √© agrad√°vel",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q19"
            )

            q20 = st.radio(
                "F2.20. O tempo de processamento do relat√≥rio foi adequado",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q20"
            )

            st.divider()

            # ==================== SE√á√ÉO 7: NET PROMOTER SCORE ====================
            st.subheader("‚≠ê Satisfa√ß√£o Geral (Net Promoter Score)")

            nps = st.slider(
                "F2.21. Em uma escala de 0 a 10, quanto voc√™ recomendaria o Delin√©ia para um colega?",
                min_value=0,
                max_value=10,
                value=5,
                help="0 = Definitivamente n√£o recomendaria | 10 = Definitivamente recomendaria"
            )

            # Mostrar categoria NPS em tempo real
            if nps >= 9:
                st.success("üåü **Promotor** - Obrigado pelo entusiasmo!")
            elif nps >= 7:
                st.info("üòê **Neutro** - O que podemos melhorar?")
            else:
                st.warning("üòû **Desanimado** - Queremos ouvir suas sugest√µes!")

            st.divider()

            # ==================== SE√á√ÉO 8: COMENT√ÅRIOS ADICIONAIS ====================
            st.subheader("üí¨ Coment√°rios Adicionais")

            q22 = st.text_area(
                "F2.22. O que voc√™ mais gostou no Delin√©ia?",
                height=100,
                key="q22",
                placeholder="Descreva os aspectos mais positivos da sua experi√™ncia..."
            )

            q23 = st.text_area(
                "F2.23. O que poderia ser melhorado?",
                height=100,
                key="q23",
                placeholder="Sugest√µes de melhorias, funcionalidades ausentes, problemas encontrados..."
            )

            q24 = st.text_area(
                "F2.24. Funcionalidades que voc√™ gostaria de ver no futuro:",
                height=100,
                key="q24",
                placeholder="Ideias para pr√≥ximas vers√µes..."
            )

            q25 = st.text_area(
                "F2.25. Como voc√™ usou (ou pretende usar) os resultados do Delin√©ia na sua pesquisa?",
                height=100,
                key="q25",
                placeholder="Ex: projeto de qualifica√ß√£o, artigo, revis√£o de literatura..."
            )

            st.divider()

            # ==================== SE√á√ÉO 9: AUTOAVALIA√á√ÉO ====================
            st.subheader("üîÑ Autoavalia√ß√£o")

            st.markdown("""
            **Reflex√£o sobre seu processo:**  
            No formul√°rio inicial (F1.5), voc√™ indicou seu n√≠vel de seguran√ßa em rela√ß√£o √†s palavras-chave escolhidas.  
            Agora, ap√≥s ter lido o relat√≥rio e as an√°lises do Delin√©ia, como voc√™ avalia sua escolha inicial?
            """)

            q26 = st.radio(
                "F2.26. Considerando as palavras-chave escolhidas inicialmente e a leitura do relat√≥rio, qual seu n√≠vel de seguran√ßa em rela√ß√£o √†s palavras-chave que voc√™ definiu para a pesquisa bibliogr√°fica do seu projeto?",
                ["Totalmente seguro", "Seguro", "Neutro", "Inseguro", "Totalmente inseguro"],
                horizontal=True,
                key="q26"
            )

            # Mostrar compara√ß√£o se dispon√≠vel
            if 'form_data' in st.session_state and 'confianca' in st.session_state.form_data:
                confianca_inicial = st.session_state.form_data['confianca']
                st.info(f"üí° **Sua resposta inicial (F1.5):** {confianca_inicial}")

            st.divider()

            # ==================== SE√á√ÉO 10: PERFIL DO RESPONDENTE ====================
            st.subheader("üë§ Perfil do Respondente (Opcional)")

            col1, col2 = st.columns(2)

            with col1:
                q27 = st.selectbox(
                    "F2.27. N√≠vel acad√™mico:",
                    ["Prefiro n√£o informar", "Gradua√ß√£o", "Especializa√ß√£o", "Mestrado",
                     "Doutorado", "P√≥s-Doutorado", "Docente"],
                    key="q27"
                )

                q28 = st.selectbox(
                    "F2.28. Experi√™ncia pr√©via com bibliometria:",
                    ["Nenhuma", "B√°sica", "Intermedi√°ria", "Avan√ßada"],
                    key="q28"
                )

            with col2:
                q29 = st.selectbox(
                    "F2.29. √Årea do conhecimento:",
                    ["Prefiro n√£o informar", "Ci√™ncias Exatas", "Ci√™ncias Biol√≥gicas", "Ci√™ncias da Sa√∫de",
                     "Ci√™ncias Agr√°rias", "Ci√™ncias Sociais Aplicadas", "Ci√™ncias Humanas",
                     "Lingu√≠stica/Letras/Artes", "Engenharias", "Multidisciplinar"],
                    key="q29"
                )

                q30 = st.selectbox(
                    "F2.30. Tempo gasto usando o Delin√©ia hoje:",
                    ["< 15 min", "15-30 min", "30-60 min", "> 1 hora"],
                    key="q30"
                )

            st.divider()

            # ==================== SE√á√ÉO 11: CONVITE √Ä CONTINUIDADE ====================
            st.subheader("ü§ù Convite √† Continuidade da Pesquisa")

            st.markdown("""
            **Queremos continuar contando com voc√™!**
            
            Esta pesquisa n√£o termina aqui. Estamos desenvolvendo novas funcionalidades e gostar√≠amos 
            de convid√°-lo(a) para participar de outras etapas do estudo, como:
            
            - üé• **Sess√µes mediadas por videoconfer√™ncia** para observa√ß√£o de uso
            - üéì **Oficinas e treinamentos** sobre bibliometria e ferramentas de pesquisa
            - üß™ **Testes de novas funcionalidades** antes do lan√ßamento p√∫blico
            - üìä **Entrevistas em profundidade** sobre suas estrat√©gias de pesquisa
            
            Sua participa√ß√£o √© volunt√°ria e voc√™ poder√° desistir a qualquer momento. 
            Caso aceite, entraremos em contato por e-mail com mais informa√ß√µes.
            """)

            aceite_continuidade = st.checkbox(
                "‚úÖ **Sim, aceito participar de outras fases desta pesquisa e autorizo contato por e-mail**",
                key="aceite_continuidade",
                help="Ao marcar esta op√ß√£o, voc√™ demonstra interesse em contribuir com o desenvolvimento do Delin√©ia"
            )

            if aceite_continuidade:
                st.success("üéâ Obrigado por aceitar continuar conosco! Voc√™ receber√° um e-mail com mais informa√ß√µes em breve.")

            st.divider()

            # ==================== BOT√ÉO DE ENVIO ====================
            submitted = st.form_submit_button(
                "üì§ Enviar Avalia√ß√£o",
                type="primary",
                use_container_width=True
            )

            if submitted:
                # Calcular categoria NPS
                if nps >= 9:
                    nps_category = "Promotor üåü"
                elif nps >= 7:
                    nps_category = "Neutro üòê"
                else:
                    nps_category = "Detrator üòû"

                # Armazenar respostas
                avaliacao_data = {
                    # Perguntas Likert (F2.1-F2.20)
                    'q1': q1, 'q2': q2, 'q3': q3, 'q4': q4, 'q5': q5,
                    'q6': q6, 'q7': q7, 'q8': q8, 'q9': q9, 'q10': q10,
                    'q11': q11, 'q12': q12, 'q13': q13, 'q14': q14, 'q15': q15,
                    'q16': q16, 'q17': q17, 'q18': q18, 'q19': q19, 'q20': q20,
                    # NPS (F2.21)
                    'nps': nps,
                    'nps_category': nps_category,
                    # Campos abertos (F2.22-F2.25)
                    'q22': q22,
                    'q23': q23,
                    'q24': q24,
                    'q25': q25,
                    # Autoavalia√ß√£o (F2.26)
                    'q26': q26,
                    # Perfil (F2.27-F2.30)
                    'q27': q27,
                    'q28': q28,
                    'q29': q29,
                    'q30': q30,
                    # Convite √† continuidade
                    'aceite_continuidade': aceite_continuidade,
                    # Metadados
                    'timestamp': datetime.now().isoformat()
                }

                # Salvar em session_state
                st.session_state.avaliacao_completa = True
                st.session_state.avaliacao_data = avaliacao_data

                # Enviar para Google Sheets
                if 'id_usuario' in st.session_state:
                    enviar_formulario_avaliacao(
                        st.session_state.id_usuario,
                        avaliacao_data
                    )

                # Badge de conclus√£o
                if 'üíé Avaliador' not in st.session_state.badges:
                    add_badge('üíé Avaliador')

                # Feedback visual
                st.success("‚úÖ Avalia√ß√£o enviada com sucesso!")
                st.balloons()

                # Resumo da avalia√ß√£o
                continuidade_msg = "Sim ‚úÖ" if aceite_continuidade else "N√£o"
                
                st.info(f"""
                üìä **Resumo da sua avalia√ß√£o:**

                ‚Ä¢ **NPS:** {nps}/10 ({nps_category})
                ‚Ä¢ **N√≠vel acad√™mico:** {q27}
                ‚Ä¢ **Experi√™ncia bibliom√©trica:** {q28}
                ‚Ä¢ **√Årea:** {q29}
                ‚Ä¢ **Tempo de uso:** {q30}
                ‚Ä¢ **Aceite para continuidade:** {continuidade_msg}

                üèÜ **Badge desbloqueado:** Avaliador

                Obrigado por dedicar seu tempo para avaliar o Delin√©ia!
                Seu feedback √© essencial para o desenvolvimento cont√≠nuo do sistema.
                """)

                # Avan√ßar para pr√≥xima etapa
                st.session_state.step = 4
                st.rerun()
    
    # ========== ETAPA 4: CONCLUS√ÉO ==========
    elif st.session_state.step == 4:
        st.success("üéâ Parab√©ns! Voc√™ completou todas as etapas!")
        st.markdown("### üèÜ Conquista Desbloqueada: Delineador!")
        st.balloons()

        primeiro_nome = st.session_state.form_data['nome'].split()[0]

        st.write(f"**{primeiro_nome}**, voc√™ concluiu com sucesso:")
        st.write("‚úÖ Delineamento completo do projeto")
        st.write("‚úÖ An√°lise bibliom√©trica avan√ßada")
        st.write("‚úÖ Avalia√ß√£o do sistema Delin√©ia")
        st.write(f"\n**üèÖ Suas conquistas:** {' '.join(st.session_state.badges)}")

        st.divider()

        # ========== PR√äMIO: V√çDEO MUSICAL ==========
        st.markdown("### üéµ Pr√™mio Especial: Uma palavra no escuro")
        
        st.markdown("""
        <div style="text-align: justify; 
                    background-color: #ffffff; 
                    border-left: 4px solid #28a745; 
                    padding: 1rem; 
                    border-radius: 0.25rem;
                    color: #000000;">
        Como reconhecimento pela sua dedica√ß√£o, presenteamos voc√™ com uma obra que simboliza 
        o processo de constru√ß√£o do conhecimento: a busca por palavras que iluminam 
        caminhos no escuro da incerteza. Uma homenagem √† Jorge Luis Borges e √† sua Biblioteca de Babel.
        <div>
        """, unsafe_allow_html=True)

        # Embedar v√≠deo do YouTube
        video_url = "https://www.youtube.com/embed/aoKVEJc-7MU"
        
        st.markdown(
            f"""
            <div style="display: flex; justify-content: center; margin: 2rem 0;">
                <iframe width="700" height="394" 
                        src="{video_url}" 
                        frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                        allowfullscreen>
                </iframe>
            </div>
            """,
            unsafe_allow_html=True
        )

        # Cr√©ditos em expander
        with st.expander("üìú Cr√©ditos e Informa√ß√µes"):
            st.markdown("""
            <div style="text-align: center; 
                        background-color: #f8f9fa; 
                        padding: 1.5rem; 
                        border-radius: 0.5rem;
                        color: #000000;">
            
            **T√≠tulo:** A palavra no escuro ou os dialetos do po√ßo
                        
            **√Ålbum:** Os olhos de Borges (Vers√£o musical do livro hom√¥nimo)
                        
            **Livro:** BRASIL, J.V. *Os olhos de Borges*. Porto Alegre: WS Editor, 1997.
                        
            **Autoria:** Jaime Vaz Brasil
                        
            **Int√©rprete(s):** Hique Gomez

            **Letra:** Jaime Vaz Brasil
                                    
            **M√∫sica:** Hique Gomez 
                                   
            **Produ√ß√£o:** FUMPROARTE/POA e Instituto Fernando Pessoa
                                    
            **Ano:** 1999
            
            ---
            
            **Conex√£o com o Delin√©ia:**
            
            Esta m√∫sica integra o universo po√©tico que inspira a constru√ß√£o do sistema Delin√©ia. 
            A met√°fora da "palavra no escuro" ecoa o processo de delineamento do escopo de pesquisa: 
            buscar, na vastid√£o da literatura cient√≠fica, as palavras-chave que iluminam o caminho 
            do conhecimento.
            
            Assim como os "dialetos do po√ßo" sugerem m√∫ltiplas vozes emergindo da profundidade, 
            o Delin√©ia revela as m√∫ltiplas dimens√µes conceituais que estruturam um campo de pesquisa, 
            auxiliando estudantes a encontrarem suas pr√≥prias vozes acad√™micas.
            </div>
            """, unsafe_allow_html=True)
        col1, col2, col3 = st.columns([1, 2, 1])

        with col2:
            if st.button("üìú Leia o pr√≥logo da tese", use_container_width=True):
                st.session_state.open_prologo = True
                st.info("""
                **O Delineasc√≥pio**

Esta √© uma palavra que respira. *Delineamento*‚Ä¶

N√£o √© uma palavra-ponto, uma palavra-fim. N√£o √© limite, fronteira ou conclus√£o. Embora o Novo Dicion√°rio Aur√©lio, em sua precis√£o cartogr√°fica, nos diga que delinear tenha o significado de "[...] fixar os limites de; estremar, demarcar", a verdadeira alma da palavra reside em sua outra defini√ß√£o: "[...] tra√ßar as linhas gerais de; esbo√ßar, debuxar".[^1] Esta √© uma palavra-processo. Uma palavra-verbo que se disfar√ßa de substantivo. No seu cora√ß√£o, pulsa o ato de delinear, do latim *delineare*, "[...] por via erudita".[^2] Em sua fam√≠lia, registrada nas colunas dos l√©xicos do vocabul√°rio ortogr√°fico da Academia Brasileira de Letras[^3], encontramos o delineador (aquele que tra√ßa) e o delineado (aquilo que foi tra√ßado). Mas o delineamento √© algo mais. √â o "[...] ato de delinear".[^4] N√£o √© o tra√ßo, mas o tra√ßar. N√£o √© o mapa, mas o mapear. √â "[...] o primeiro esbo√ßo ou projeto de qualquer obra; plano geral".[^5] √â o gesto inaugural da cria√ß√£o. √â o primeiro tra√ßo.

O Dicion√°rio Houaiss nos conta um segredo: a palavra j√° circulava em 1552[^6]. Mil quinhentos e cinquenta e dois. Pensemos nisso. Esta n√£o √© uma palavra da Revolu√ß√£o Industrial. N√£o nasceu fria, met√°lica, otimizada sob uma linha de montagem, no distanciamento entre idealiza√ß√£o e produ√ß√£o. Ela nasceu no auge do Renascimento, numa era de explora√ß√£o febril, quando o mundo conhecido se expandia e exigia ser desenhado, quando os mapas eram mais suposi√ß√£o do que certeza. Sua primeira defini√ß√£o registrada, "[...] ato ou efeito de delinear(-se); esbo√ßo, delinea√ß√£o, tra√ßado [...]", era usada para o "[...] esbo√ßo do projeto de repara√ß√£o a ser feita em qualquer parte de embarca√ß√£o".[^7]

Que po√©tica inaugural! O delineamento n√£o √© sobre construir o navio do zero; √© sobre o reparo. √â sobre olhar para uma estrutura que j√° existe (uma ideia, um navio, um campo de estudo) e tra√ßar o plano para sua renova√ß√£o, sua travessia. O navio da pesquisa do estudante j√° existe, ancorado no porto da sua intui√ß√£o, mas com o casco opaco de incertezas. Ele precisa ser delineado para poder navegar.

Frequentemente, quando buscamos uma tradu√ß√£o apressada, a l√≠ngua inglesa nos oferece, friamente, *design*. Mas *design* √© uma palavra que trai a alma do delineamento. *Design* carrega o peso da ind√∫stria, do produto final, da ergonomia. O *design* √© assertivo, muitas vezes dogm√°tico. Ele se imp√µe √† mat√©ria. O *design* √© a cadeira, o *iPhone*, o motor: solu√ß√µes acabadas, polidas, fechadas em si. Delineamento √© o oposto. √â uma palavra de escuta. O delineamento √© a pergunta ganhando forma.

O verbo delinear, "[...] tra√ßar as linhas gerais de; esbo√ßar, debuxar",[^8] √© um ato de humildade. O delineador n√£o inventa o contorno do continente; ele tra√ßa o contorno que descobre. O *design* fecha; o delineamento abre. O *design* √© a certeza do engenheiro; o delineamento √© a hesita√ß√£o do artista diante da tela em branco. √â por isso que o delineamento √© a palavra-raiz da cultura das descobertas, sejam elas art√≠sticas, filos√≥ficas, cient√≠ficas ou mesmo industriais. A descoberta n√£o √© um *design*, mas um delineamento. √â o ato de tatear no escuro e, aos poucos, "[...] tra√ßar as linhas gerais, o plano de; projetar, planejar".[^9] √â a transforma√ß√£o da incerteza em foco.

E aqui, uma busca interessante se revela. A palavra delineamento √©, em si, um ato da cr√≠tica, da an√°lise e da academia, mas √© rara dentro da prosa de fic√ß√£o ou dos versos de poesia. Parece ser uma palavra que usamos para observar a literatura, e n√£o uma palavra que a literatura usa para observar o mundo. Um romancista provavelmente escreveria "o contorno do seu rosto" ou "o tra√ßado do plano", mas raramente "o delineamento do seu rosto". A palavra pertence ao analista, ao pesquisador. A encontramos em textos de cr√≠tica liter√°ria, operando do mesmo modo como esta tese prop√µe: o processo de dar forma, tra√ßar perfis e estruturar a descoberta.

Um ensaio sobre Erico Verissimo e Graham Greene menciona o "[...] delineamento de dois perfis de personagens [...]".[^10] Um estudo sobre Machado de Assis foca no "[...] delineamento do percurso da escrita de 'O alienista' [...]",[^11] analisando como Machado de Assis esbo√ßou e refez sua obra. Um cr√≠tico, sobre o poeta Dem√©trio Vieira Diniz, afirma que seu livro "[...] atesta e faz saber o delineamento de uma singular dic√ß√£o".[^12] √â a palavra que usamos para entender a cria√ß√£o, perfeita para descrever o processo de descoberta que o aluno, no centro desta tese, est√° colocado a realizar.

Em um canto esquecido da estante, em um Dicion√°rio de Comunica√ß√£o, encontramos um artefato. Ao buscar uma remissiva da entrada principal do verbete "Episc√≥pio", lemos: "Aparelho baseado na reflex√£o de luz, que se destina √† proje√ß√£o de imagens de objetos opacos (tais como fotografias, desenhos etc.). Tamb√©m chamado de delineasc√≥pio ou de projetor opaco".[^13] *Delineasc√≥pio*: o-que-projeta-o-delineado [sic].

Um aparelho (*sc√≥pio*) que torna vis√≠vel (*proje√ß√£o*) um esbo√ßo ou tra√ßado (*del√≠nea*). Aqui, a po√©tica se completa. O conhecimento come√ßa n√£o com a luz, mas com um objeto opaco. Qual √© o "objeto opaco" sen√£o a ideia inicial de um pesquisador? √â aqui que a palavra encontra sua casa nesta tese: "*Grandes modelos de linguagem e an√°lise de coocorr√™ncia de palavras-chave para o delineamento do escopo de projetos de pesquisa no ensino superior*".

O estudante chega ao ensino superior carregando esse objeto opaco. Ele o segura nas m√£os. O projeto o chama, em linguagem t√©cnica, de "necessidade de informa√ß√£o", de uma etapa de "formula√ß√£o" marcada por "sentimentos iniciais de d√∫vida e confus√£o", ou o estado de "pr√©-foco" onde a "incerteza √© um estado cognitivo que comumente causa sintomas afetivos de ansiedade e falta de confian√ßa".[^14] Como encontrar as agulhas certas nos palheiros mais loucos?

Simbolicamente, √© uma intui√ß√£o turva. Um vulto. Um interesse que ainda n√£o tem palavras. √â um desenho que n√£o pode ser visto. √â um mapa por fazer. Como tra√ßar o que ainda n√£o se v√™? √â preciso, ent√£o, um delineasc√≥pio. Um aparelho de luz refletida. N√£o a luz que cega, mas a que projeta os contornos do que j√° est√° l√°. Esta tese √© uma das engrenagens da engenharia desta m√°quina. O estudante coloca seu objeto opaco (sua ideia de tema, sua quest√£o de pesquisa inicial, suas primeiras palavras-chave) na m√°quina. A m√°quina, ent√£o, usa duas fontes de luz para projetar essa ideia na grande teia da literatura cient√≠fica.

A primeira luz √© a an√°lise de coocorr√™ncia de palavras. Ela funciona exatamente como um episc√≥pio: ela reflete a luz sobre o objeto opaco do aluno e projeta as conex√µes que ele n√£o podia ver. O estudante v√™ seu termo (por exemplo, "*gamification*") e, de repente, projetado na tela, ele o v√™ ligado a "*motivation*", "*higher education*", "*engagement*", "*learning outcomes*". O grafo de coocorr√™ncia √© a proje√ß√£o. O opaco tornou-se vis√≠vel, relacional, deline√°vel. O estudante pode, agora, pegar seu l√°pis e tra√ßar as conex√µes que a luz revelou. A m√°quina oferece uma vis√£o complementar dos conceitos centrais.

A segunda luz √© generativa. S√£o os grandes modelos de linguagem (LLMs). Se a coocorr√™ncia √© a proje√ß√£o, o LLM √© o *feedback*, a media√ß√£o. √â a voz que ajuda o estudante a ajustar o foco do delineasc√≥pio. Ele n√£o se limita a projetar o que existe; ele conversa com a proje√ß√£o. Ele oferece o *feedback* textual automatizado. Ele olha para a proje√ß√£o e sussurra: "As palavras-chave designadas para o projeto se mostram alinhadas... No entanto, algumas express√µes ainda podem ser consideradas gen√©ricas... √â recomend√°vel que voc√™ considere a possibilidade de incorporar termos mais descritivos‚Ä¶ Converse com seu orientador‚Ä¶".[^15] Ele sugere novas lentes, novas palavras. O delineamento do escopo deixa de ser uma tarefa burocr√°tica de defini√ß√£o de limites e se torna um ato po√©tico de proje√ß√£o e descoberta. Deixa de ser um ato de solid√£o e passa a ser um ato de media√ß√£o. E no centro deste ato, o estudante. Este projeto coloca o aluno no centro desse processo. O estudante n√£o √© um receptor passivo de *design*. Ele √© o delineador[^16].

Esta tese reconhece a luta humana nesse processo. Ela se ancora em modelos te√≥ricos que s√£o, em ess√™ncia, mapas da alma deste estudante-pesquisador. Ela se fundamenta no modelo de Kuhlthau, que entende a busca como uma passagem dolorosa e necess√°ria da "incerteza" para a confian√ßa.[^17] Ela se baseia no modelo cognitivo de escrita de Flower e Hayes, que entende a escrita n√£o como uma tradu√ß√£o linear, mas como um processo recursivo de "planejamento, gera√ß√£o de ideias, organiza√ß√£o e defini√ß√£o de metas"[^18], ou seja, o pr√≥prio ato de delinear. E se alicer√ßa no modelo de comportamento informacional de Wilson, que mapeia o "comportamento de busca" e as "barreiras" que tornam a ideia opaca em primeiro lugar.[^19]

O delineamento proposto nesta tese √©, portanto, terap√™utico. Ele oferece ao estudante, que "enfrenta dificuldades" e "in√∫meros desafios", as ferramentas n√£o para resolver seu problema, mas para v√™-lo projetado. A ferramenta torna-se uma mediadora do pensamento cient√≠fico, um andaime para a autonomia investigativa, um fomento ao pensamento cr√≠tico.

Em 1552, o delineamento era o esbo√ßo para reparar um navio e prepar√°-lo para a travessia. Hoje, o delineamento √© o esbo√ßo para reparar a confian√ßa do estudante-pesquisador, dando-lhe o mapa: o delineasc√≥pio para sua pr√≥pria travessia intelectual. A pesquisa, assim como a arte, n√£o √© sobre ter respostas prontas, mas sobre a coragem de fazer o tra√ßo inicial, de navegar a incerteza e, aos poucos, dar forma ao pensamento. Minha tese √© a hist√≥ria da constru√ß√£o desse delineasc√≥pio. √â um convite para trocar a ansiedade da p√°gina em branco pela descoberta mediada do primeiro tra√ßo. √â uma palavra que acolhe a jornada do estudante, celebrando o esbo√ßo tanto quanto a obra final.

Para que todo estudante, segurando seu objeto opaco, possa encontrar a luz para projet√°-lo e, enfim, come√ßar a delinear‚Ä¶

‚Ä¶ *Delin√©ia !!!*

---

**Notas:**

[^1]: FERREIRA, A.B.H. *Novo dicion√°rio Aur√©lio da l√≠ngua portuguesa*. 4.ed. Curitiba: Positivo, 2009.
[^2]: NASCENTES, A. *Dicion√°rio etimol√≥gico resumido*. Rio de Janeiro: INL, 1966.
[^3]: ACADEMIA BRASILEIRA DE LETRAS. *Vocabul√°rio ortogr√°fico da l√≠ngua portuguesa*. 5.ed. S√£o Paulo: Global, 2009.
[^4]: FERREIRA, op. cit., p. 614.
[^5]: Ibid.
[^6]: HOUAISS, A.; VILLAR, M.S. *Dicion√°rio Houaiss da l√≠ngua portuguesa*. Rio de Janeiro: Objetiva, 2009.
[^7]: Ibid.
[^8]: FERREIRA, op. cit. p. 614.
[^9]: HOUAISS, op. cit., p. 610.
[^10]: DIAS, R.C. Americanos ing√™nuos e vietnamitas silenciosas: uma abordagem intertextual de O americano tranquilo e O prisioneiro. *Pap√©is*. Campo Grande, v. 23, n. 46, p. 61-75, 2019.
[^11]: CRESTANI, J.L. O Alienista: an√°lise das variantes do folhetim e do livro. *SOLETRAS*, v. 10, n. 19, p. 156-166, 2010.
[^12]: DANTAS, M.L. O trem azul do destino da poesia de Dem√©trio Diniz. *Letras In.verso e Re.verso*. 2016.
[^13]: RABA√áA, C.A.; BARBOSA, G.G. *Dicion√°rio de comunica√ß√£o*. 2.ed. Rio de Janeiro: Campus, 2002.
[^14]: Trechos da tese sobre modelos de comportamento informacional.
[^15]: Exemplo de feedback gerado pelo sistema Delin√©ia.
[^16]: FERREIRA, op. cit., p. 614.
[^17]: KUHLTHAU, C.C. *Seeking meaning:* a process approach to library and information services. 2.ed. Westport: Libraries Unlimited, 2004.
[^18]: FLOWER, L.; HAYES, J.R. A cognitive process theory of writing. *College Composition and Communication*, v. 32, n. 4, p. 365‚Äì387, 1981.
[^19]: WILSON, T.D. On user studies and information needs. *Journal of Documentation*, v. 37, n. 1, p. 3-15, 1981.

**Desnorte**

O mundo √© este monte: palha e p√≥.
 
Um caos de fibra, um tato quase cego,
 
Onde me perco e nada mais congrego,
 
Mergulhado em um vasto e mudo "s√≥".

                        
Perdi o mapa; a rota √© s√≥ tormento.
 
A perspectiva √© turva, escura n√©voa;
 
A d√∫vida √© um peso, noite, treva,
 
E o "qu√™ fazer" corr√≥i a cada momento.


A in√©rcia abre a estrada do fracasso;
 
O n√£o saber √© um jugo, um precip√≠cio,
 
N√£o h√° repouso ou fim neste compasso.
                        

Resta encontrar, no caos, o puro ind√≠cio:
 
A agulha. O a√ßo. O ponto duro e escasso.
 
Que sangre o dedo, mas que estanque o v√≠cio.


üîç

                        
""")

        st.divider()

        if st.button("üîÑ Iniciar Novo Delineamento", use_container_width=True):
            st.session_state.step = 1
            st.session_state.resultado = None
            st.session_state.form_data = {}
            st.session_state.avaliacao_completa = False
            st.session_state.badges = []
            st.rerun()

# ==================== ABA 2: PAINEL DE AN√ÅLISE ====================
with tab2:
    st.title("üìä Painel de Explora√ß√£o de Dados")
    st.caption("An√°lise profunda dos dados do OpenAlex")

    # Sidebar para configura√ß√£o
    with st.sidebar:
        st.header("‚öôÔ∏è Configurar Busca")

        # Campo de busca
        query = st.text_input(
            "Chave de Busca:",
            value=st.session_state.get('dashboard_query', "HIV/AIDS AND Brasil"),
            help="Use operadores: AND, OR, NOT"
        )

        if 'dashboard_query' in st.session_state and st.session_state.dashboard_query:
            st.info("üìã Chave de busca copiada do Delineasc√≥pio")

        st.divider()
        st.subheader("üîß Filtros")

        # Op√ß√£o de sincronizar configura√ß√µes
        with st.expander("‚öôÔ∏è Configura√ß√µes Avan√ßadas"):
            sync_config = st.checkbox("Usar configura√ß√£o padr√£o", value=True)

            if sync_config:
                st.info("**Configura√ß√£o Padr√£o:**\n- Limite: 500 artigos\n- Score m√≠nimo: 0.35\n- Level m√≠nimo: 0")
                limit = 500
                min_score = 0.35
                min_level = 0
            else:
                limit = st.slider("Limite de artigos:", 10, 500, 100, 10,
                    help="N√∫mero m√°ximo de artigos a buscar na API OpenAlex")
                min_score = st.slider("Score m√≠nimo:", 0.0, 1.0, 0.35, 0.05,
                    help="Relev√¢ncia m√≠nima do conceito (0-1). Valores maiores = conceitos mais relevantes")
                min_level = st.slider("Level m√≠nimo:", 0, 5, 0, 1,
                    help="N√≠vel hier√°rquico do conceito (0-5). 0 = geral, 5 = muito espec√≠fico")

        min_cooc = st.slider("Coocorr√™ncia m√≠nima:", 1, 10, 2, 1,
            help="Frequ√™ncia m√≠nima de coocorr√™ncia para formar aresta no grafo")

        st.divider()

        # Bot√£o de buscar
        if st.button("üîç Buscar", type="primary", use_container_width=True):
            with st.spinner("üîÑ Em processamento, confira no Painel"):
                try:
                    # Inicializar cliente
                    client = OpenAlexClient(OPENALEX_EMAIL)

                    # Buscar artigos
                    articles = client.search_articles(client.normalize_query(query), limit)

                    # Extrair conceitos
                    concepts_lists = []
                    for article in articles:
                        concepts = [
                            c['name'] for c in article.get('concepts', [])
                            if c['score'] >= min_score and c['level'] >= min_level
                        ]
                        if concepts:
                            concepts_lists.append(concepts)

                    # Construir grafo
                    analyzer = CooccurrenceAnalyzer()
                    G = analyzer.build_graph(concepts_lists, min_cooc)

                    # Salvar dados
                    st.session_state.dashboard_data = {
                        'articles': articles,
                        'concepts_lists': concepts_lists,
                        'graph': G
                    }

                    # Mostrar detalhes
                    with st.expander("üìã Detalhes da Busca"):
                        st.write(f"**Chave de busca enviada:** {query}")
                        st.write(f"**Limite:** {limit}")
                        st.write(f"**Coocorr√™ncia m√≠nima:** {min_cooc}")
                        st.write(f"**Filtros:** score‚â•{min_score}, level‚â•{min_level}")
                        st.write(f"**Artigos retornados:** {len(articles)}")
                        st.write(f"**Conceitos extra√≠dos:** {len(concepts_lists)}")
                        st.write(f"**N√≥s no grafo:** {len(G.nodes())}")

                    st.success(f"‚úÖ {len(articles)} artigos | {len(G.nodes())} conceitos")

                except Exception as e:
                    st.error(f"‚ùå Erro: {str(e)}")

        st.divider()

        # ========== SE√á√ÉO SOBRE ==========
        with st.expander("üìã Sobre o Delin√©ia"):
            st.markdown("""
            ### O que √© o Delin√©ia?
            O Delin√©ia √© um sistema de apoio ao delineamento do escopo tem√°tico de projetos de pesquisa no ensino superior e foi desenvolvido como parte de uma tese de doutorado em Inform√°tica na Educa√ß√£o. O sistema combina intelig√™ncia artificial generativa (Google Gemini) com an√°lise bibliom√©trica de coocorr√™ncia de palavras (OpenAlex) para auxiliar estudantes de gradua√ß√£o e de p√≥s-gradua√ß√£o no esbo√ßo de seus projetos de pesquisa.
        
            ### Desenvolvimento
            **Autor:** Rafael Antunes dos Santos  
            
            **Institui√ß√£o:**             
            - Universidade Federal do Rio Grande do Sul (UFRGS) 
            - Centro Interdisciplinar de Novas Tecnologias na Educa√ß√£o (Cinted)
            - Programa de P√≥s-Gradua√ß√£o em Inform√°tica na Educa√ß√£o (PPGIE)
              
            **N√≠vel:** Doutorado  
            **Orientador:** Prof. Dr. Eliseo Berni Reategui  
        
            **Forma√ß√£o Anterior:**
            - Mestre em Comunica√ß√£o e Informa√ß√£o pela UFRGS (PPGCOM)  
            - Bacharel em Biblioteconomia pela UFRGS (DCI/FABICO) - CRB10/1898
        
            **Curr√≠culo Lattes:** [http://lattes.cnpq.br/5228660998907867](http://lattes.cnpq.br/5228660998907867)
        
            ### Abordagem Interdisciplinar
            Este projeto situa-se no di√°logo entre Inform√°tica na Educa√ß√£o e Ci√™ncia da Informa√ß√£o, explorando como tecnologias de IA podem apoiar processos de pesquisa cient√≠fica no ensino superior.
        
            ### Funcionalidades
            - **Delineasc√≥pio:** Feedback personalizado sobre projetos de pesquisa
            - **Painel:** An√°lise profunda de dados do OpenAlex:
              - **Artigos:** Contagens de artigos e links de acesso
              - **Conceitos:** Contagens de conceitos, nuvem de palavras e Lei de Zipf
              - **Coocorr√™ncias:** Contagens de associa√ß√µes entre conceitos e matrizes
              - **Grafo:** Visualiza√ß√£o interativa
              - **Mapa Tem√°tico:** Posi√ß√£o do cluster
              - **Estat√≠sticas:** Resumo breve
              - **Exporta√ß√£o:** Dados em JSON, CSV, GraphML, BibTeX, RIS
        
            ### Tecnologias
            - Python / Streamlit
            - Google Gemini AI 2.5 Pro / Anthropic Claude Opus 4.5
            - OpenAlex API
            - NetworkX, Plotly, ReportLab
        
            ### Contato
            üìß rafael.antunes@ufrgs.br
            üìß rderafa@gmail.com           
        
            ### Vers√£o
            Delin√©ia I - 2025

            ### Agradecimentos
            Ao **Orientador** Eliseo Berni Reategui; Aos **Professores** Alexandra Lorandi, Alexandre Ribas Semeler, Dante Augusto Couto Barone, Elisa Boff, Fernando Becker, Gabriela Trindade Perry, Ida Regina Chitto Stumpf, Leandro Krug Wives, Marcus Vinicius de Azevedo Basso, Maria de F√°tima Santos Maia, Milton Antonio Zaro, Patr√≠cia Fernanda da Silva, Rafael Port da Rocha, Regina Helena Van der Laan, Renato Ventura Bayan Henriques, Rosa Maria Vicari, Samile Andr√©a de Souza Vanz, S√©rgio Roberto Kieling Franco, Sonia Elisa Caregnato e Vanessa Soares Maurente. Aos colegas do grupo de pesquisa **GTech.Edu** e √† **CAPES**, pela concess√£o de bolsa de estudos.
            """)
    
    # √Årea principal do painel
    if st.session_state.dashboard_data is None:
        st.info("üëà Configure os par√¢metros na barra lateral e clique em **Buscar** para iniciar a an√°lise")

        # Mostrar exemplo
        with st.expander("üí° Exemplo de uso"):
            st.markdown("""
            **Como usar o Painel:**

            1. **Digite uma chave de busca** (ex: "machine learning AND education")
            2. **Ajuste os filtros** conforme necess√°rio
            3. **Clique em Buscar** para processar
            4. **Explore as abas** com diferentes an√°lises
            5. **Exporte os dados** quando necess√°rio

            **Dica:** Voc√™ pode copiar as chaves de busca do Delineasc√≥pio!
            """)

    else:
        # Recuperar dados
        data = st.session_state.dashboard_data
        articles = data['articles']
        concepts_lists = data['concepts_lists']
        G = data['graph']

        # Criar sub-abas para an√°lises
        t1, t2, t3, t4, t5, t6, t7 = st.tabs([
            "üìö Artigos",
            "üß© Conceitos",
            "üîó Coocorr√™ncias",
            "üï∏Ô∏è Grafo",
            "üó∫Ô∏è Mapa Tem√°tico",
            "üìä Estat√≠sticas",
            "üíæ Exporta√ß√£o"
        ])

        # ========== SUB-ABA 1: ARTIGOS (COM DOI/URL) - VERS√ÉO CORRIGIDA ==========
        with t1:
            st.header("üìö Artigos Analisados")
            st.metric("Total de Artigos", len(articles))

            # ‚ú® TABELA COM COLUNA DOI/URL ‚ú®
            df_articles = pd.DataFrame([
                {
                    'T√≠tulo': (lambda t: t[:80] + '...' if len(t) > 80 else t)(a.get('title') or 'Sem t√≠tulo'),
                    'Ano': a.get('year', 'N/A'),
                    'Conceitos': len(a.get('concepts', [])),
                    'DOI/URL': a.get('doi', a.get('url', 'N/A'))
                }
                for a in articles
            ])

            # Configurar coluna como link clic√°vel
            st.dataframe(
                df_articles,
                use_container_width=True,
                height=400,
                column_config={
                    "DOI/URL": st.column_config.LinkColumn(
                        "üîó DOI/URL",
                        help="Clique para abrir o artigo",
                        display_text="Abrir artigo"
                    )
                }
            )
    
            if len(articles) > 0:
                st.divider()
                st.subheader("üîç Detalhes do Artigo")
    
                # Seletor de artigo - CORRIGIDO
                idx = st.selectbox(
                    "Selecione um artigo:",
                    range(len(articles)),
                    format_func=lambda i: f"{i+1}. {(articles[i].get('title') or 'Sem t√≠tulo')[:60]}..."
                )
    
                selected = articles[idx]
    
                col1, col2 = st.columns([2, 1])
    
                with col1:
                    st.write(f"**T√≠tulo:** {selected.get('title') or 'Sem t√≠tulo'}")
                    st.write(f"**Ano:** {selected.get('year', 'N/A')}")
    
                    # ‚ú® EXIBIR LINK CLIC√ÅVEL ‚ú®
                    link = selected.get('doi', selected.get('url', ''))
                    if link:
                        st.markdown(f"**üîó Link:** [{link}]({link})")
                    else:
                        st.write("**üîó Link:** N/A")
    
                with col2:
                    st.metric("Conceitos", len(selected.get('concepts', [])))
    
                st.subheader("üìã Conceitos do Artigo")
    
                concepts_df = pd.DataFrame([
                    {
                        'Conceito': c['name'],
                        'Score': f"{c['score']:.3f}",
                        'Level': c['level']
                    }
                    for c in selected.get('concepts', [])
                ])
    
                if not concepts_df.empty:
                    st.dataframe(concepts_df, use_container_width=True)
                else:
                    st.info("Nenhum conceito encontrado")
    
                with st.expander("üîç Ver JSON completo"):
                    st.json(selected)

        # ========== SUB-ABA 2: CONCEITOS ==========
        with t2:
            st.header("üß© An√°lise de Conceitos")

            # Estat√≠sticas gerais
            all_concepts = [c for cl in concepts_lists for c in cl]
            freq = Counter(all_concepts)

            col1, col2, col3 = st.columns(3)
            col1.metric("Artigos com Conceitos", len(concepts_lists))
            col2.metric("Conceitos √önicos", len(freq))
            col3.metric("Total de Ocorr√™ncias", len(all_concepts))

            st.divider()

            # ===== NUVEM DE PALAVRAS (com Plotly) =====
            st.subheader("‚òÅÔ∏è Nuvem de Conceitos")
            
            # Criar dicion√°rio de frequ√™ncias
            freq_dict = dict(freq.most_common(50))
            
            if freq_dict:
                import random
                random.seed(42)
                
                # Preparar dados
                words = list(freq_dict.keys())
                frequencies = list(freq_dict.values())
                max_freq = max(frequencies)
                min_freq = min(frequencies)
                
                # Normalizar tamanhos (entre 12 e 80)
                sizes = [12 + (f - min_freq) / (max_freq - min_freq) * 68 if max_freq > min_freq else 40 for f in frequencies]
                
                # Posi√ß√µes em espiral/org√¢nica
                n = len(words)
                x_positions = []
                y_positions = []
                for i in range(n):
                    angle = i * 2.4  # √Çngulo √°ureo
                    radius = 10 + i * 1.5
                    x_positions.append(50 + radius * np.cos(angle) * 0.8)
                    y_positions.append(50 + radius * np.sin(angle) * 0.5)
                
                # Paleta de cores mais harm√¥nica
                color_palette = ['#e63946', '#f4a261', '#2a9d8f', '#264653', '#e9c46a', 
                                '#023e8a', '#0077b6', '#8338ec', '#ff006e', '#06d6a0']
                colors = [color_palette[i % len(color_palette)] for i in range(n)]
                
                # Criar figura
                fig_cloud = go.Figure()
                
                for i, word in enumerate(words):
                    fig_cloud.add_trace(go.Scatter(
                        x=[x_positions[i]],
                        y=[y_positions[i]],
                        mode='text',
                        text=[word],
                        textfont=dict(size=sizes[i], color=colors[i], family='Arial Black'),
                        hoverinfo='text',
                        hovertext=f'{word}: {frequencies[i]} ocorr√™ncias',
                        showlegend=False
                    ))
                
                fig_cloud.update_layout(
                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 100]),
                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 100]),
                    height=450,
                    margin=dict(l=0, r=0, t=10, b=10),
                    plot_bgcolor='white'
                )
                
                st.plotly_chart(fig_cloud, use_container_width=True)
            else:
                st.info("Sem dados suficientes para gerar nuvem de palavras")
            
            st.divider()

            # Top conceitos
            st.subheader("üèÜ Conceitos Mais Frequentes")

            top_n = st.slider("N√∫mero de conceitos:", 10, 50, 20, 5, key="top_concepts")

            df_freq = pd.DataFrame(
                freq.most_common(top_n),
                columns=['Conceito', 'Frequ√™ncia']
            )

            # Gr√°fico de barras
            fig = px.bar(
                df_freq,
                x='Frequ√™ncia',
                y='Conceito',
                orientation='h',
                title=f"Top {top_n} Conceitos Mais Frequentes",
                color='Frequ√™ncia',
                color_continuous_scale='blues'
            )
            fig.update_layout(
                height=600,
                yaxis={'categoryorder': 'total ascending'}
            )

            st.plotly_chart(fig, use_container_width=True)

            # An√°lise de Zipf
            def analyze_zipf(frequency_data):
                """
                Analisa a distribui√ß√£o de frequ√™ncias segundo a Lei de Zipf

                Args:
                    frequency_data: Lista de tuplas (palavra, frequ√™ncia) ordenada por frequ√™ncia

                Returns:
                    dict com m√©tricas e dados para plotagem
                """
                # Extrair frequ√™ncias
                frequencies = [freq for _, freq in frequency_data]

                # Criar ranks (1, 2, 3, ...)
                ranks = np.arange(1, len(frequencies) + 1)

                # Converter para arrays numpy
                ranks_array = np.array(ranks)
                freq_array = np.array(frequencies)

                # Aplicar log para an√°lise linear
                log_ranks = np.log10(ranks_array)
                log_freqs = np.log10(freq_array)

                # Regress√£o linear no espa√ßo log-log
                slope, intercept, r_value, p_value, std_err = stats.linregress(log_ranks, log_freqs)

                # Calcular R¬≤
                r_squared = r_value ** 2

                # Gerar linha de tend√™ncia
                trend_line = 10 ** (slope * log_ranks + intercept)

                # Interpreta√ß√£o
                if r_squared > 0.90:
                    interpretation = "‚úÖ Forte ader√™ncia √† Lei de Zipf"
                    quality = "excelente"
                elif r_squared > 0.75:
                    interpretation = "‚ö†Ô∏è Ader√™ncia moderada √† Lei de Zipf"
                    quality = "boa"
                else:
                    interpretation = "‚ùå Fraca ader√™ncia √† Lei de Zipf"
                    quality = "baixa"

                # An√°lise da inclina√ß√£o
                if -1.2 < slope < -0.8:
                    slope_interpretation = "pr√≥ximo ao ideal (-1.0)"
                elif slope < -1.2:
                    slope_interpretation = "vocabul√°rio mais concentrado que o esperado"
                else:
                    slope_interpretation = "vocabul√°rio mais disperso que o esperado"

                return {
                    'ranks': ranks_array,
                    'frequencies': freq_array,
                    'log_ranks': log_ranks,
                    'log_freqs': log_freqs,
                    'trend_line': trend_line,
                    'slope': slope,
                    'intercept': intercept,
                    'r_squared': r_squared,
                    'p_value': p_value,
                    'interpretation': interpretation,
                    'quality': quality,
                    'slope_interpretation': slope_interpretation
                }

            # Executar an√°lise de Zipf
            if len(freq) > 0:
                st.divider()
                st.subheader("üìà An√°lise da Lei de Zipf")

                st.markdown("""
                A **Lei de Zipf** prediz que a frequ√™ncia de uma palavra √© inversamente proporcional
                ao seu ranking. Em um gr√°fico log-log, isso aparece como uma linha reta com inclina√ß√£o
                pr√≥xima a -1.0.
                """)

                # Preparar dados (tuplas de palavra, frequ√™ncia)
                frequency_data = freq.most_common()

                # Chamar a fun√ß√£o de an√°lise
                zipf_results = analyze_zipf(frequency_data)

                # Exibir m√©tricas
                col1, col2, col3 = st.columns(3)
                col1.metric("R¬≤ (Ader√™ncia)", f"{zipf_results['r_squared']:.3f}")
                col2.metric("Inclina√ß√£o", f"{zipf_results['slope']:.3f}")
                col3.metric("Qualidade", zipf_results['quality'].upper())

                # Interpreta√ß√µes
                st.info(f"**{zipf_results['interpretation']}** - Inclina√ß√£o {zipf_results['slope_interpretation']}")

                # Gr√°fico log-log
                fig_zipf = go.Figure()

                # Dados reais
                fig_zipf.add_trace(go.Scatter(
                    x=zipf_results['ranks'],
                    y=zipf_results['frequencies'],
                    mode='markers',
                    name='Dados Observados',
                    marker=dict(size=8, color='blue'),
                    text=[word for word, _ in frequency_data],
                    hovertemplate='<b>%{text}</b><br>Rank: %{x}<br>Frequ√™ncia: %{y}<extra></extra>'
                ))

                # Linha de tend√™ncia (Lei de Zipf)
                fig_zipf.add_trace(go.Scatter(
                    x=zipf_results['ranks'],
                    y=zipf_results['trend_line'],
                    mode='lines',
                    name='Lei de Zipf (te√≥rico)',
                    line=dict(color='red', dash='dash', width=2)
                ))

                fig_zipf.update_layout(
                    title='Distribui√ß√£o de Zipf (Escala Log-Log)',
                    xaxis_title='Ranking (log)',
                    yaxis_title='Frequ√™ncia (log)',
                    xaxis_type='log',
                    yaxis_type='log',
                    height=500,
                    hovermode='closest'
                )

                st.plotly_chart(fig_zipf, use_container_width=True)

                # Explica√ß√£o adicional
                with st.expander("‚ÑπÔ∏è Como interpretar"):
                    st.markdown(f"""
                    **R¬≤ = {zipf_results['r_squared']:.3f}**
                    - R¬≤ > 0.90: Excelente ader√™ncia √† Lei de Zipf
                    - 0.75 < R¬≤ < 0.90: Boa ader√™ncia
                    - R¬≤ < 0.75: Baixa ader√™ncia

                    **Inclina√ß√£o = {zipf_results['slope']:.3f}**
                    - Ideal: pr√≥ximo a -1.0
                    - Mais negativo: vocabul√°rio concentrado em poucas palavras
                    - Menos negativo: vocabul√°rio mais distribu√≠do

                    **Signific√¢ncia estat√≠stica**: p-value = {zipf_results['p_value']:.6f}
                    """)

            # Tabela
            st.divider()
            st.subheader("üìã Tabela de Frequ√™ncias")
            st.dataframe(df_freq, use_container_width=True)

            st.divider()

            # Distribui√ß√£o
            st.subheader("üìä Distribui√ß√£o de Conceitos por Artigo")

            concepts_per_article = [len(c) for c in concepts_lists]

            fig2 = px.histogram(
                x=concepts_per_article,
                nbins=20,
                labels={'x': 'N√∫mero de conceitos', 'y': 'Frequ√™ncia'},
                title="Distribui√ß√£o de Conceitos por Artigo"
            )

            st.plotly_chart(fig2, use_container_width=True)

            if len(concepts_per_article) > 0:
                col1, col2, col3 = st.columns(3)
                col1.metric("M√©dia", f"{sum(concepts_per_article)/len(concepts_per_article):.1f}")
                col2.metric("M√≠nimo", min(concepts_per_article))
                col3.metric("M√°ximo", max(concepts_per_article))

        # ========== SUB-ABA 3: COOCORR√äNCIAS ==========
        with t3:
            st.header("üîó An√°lise de Coocorr√™ncias")

            # Calcular pares
            pairs = Counter()
            for concepts in concepts_lists:
                for i, c1 in enumerate(concepts):
                    for c2 in concepts[i+1:]:
                        if c1 != c2:
                            pairs[tuple(sorted([c1, c2]))] += 1

            st.metric("Pares √önicos", len(pairs))

            st.divider()

            # Top pares
            st.subheader("üèÜ Coocorr√™ncias Mais Frequentes")

            top_pairs = st.slider("N√∫mero de pares:", 10, 100, 30, 10, key="top_pairs")

            df_pairs = pd.DataFrame([
                {
                    'Conceito 1': c1,
                    'Conceito 2': c2,
                    'Frequ√™ncia': f
                }
                for (c1, c2), f in pairs.most_common(top_pairs)
            ])

            st.dataframe(df_pairs, use_container_width=True)

            st.divider()

            # Matriz de calor
            st.subheader("üî• Matriz de Calor de Coocorr√™ncias")

            top_heatmap = st.slider("Conceitos na matriz:", 5, 20, 10, 1, key="heatmap_size")

            top_concepts = [c for c, _ in freq.most_common(top_heatmap)]

            # Criar matriz
            matrix = pd.DataFrame(0, index=top_concepts, columns=top_concepts)

            for (c1, c2), f in pairs.items():
                if c1 in top_concepts and c2 in top_concepts:
                    matrix.loc[c1, c2] = f
                    matrix.loc[c2, c1] = f

            fig = px.imshow(
                matrix,
                labels=dict(x="Conceito", y="Conceito", color="Coocorr√™ncias"),
                title=f"Matriz de Calor - Top {top_heatmap} Conceitos",
                color_continuous_scale='Blues'
            )
            fig.update_layout(height=600)

            st.plotly_chart(fig, use_container_width=True)

            st.divider()

            # Distribui√ß√£o de frequ√™ncias
            st.subheader("üìà Distribui√ß√£o das Frequ√™ncias de Coocorr√™ncia")

            freqs = list(pairs.values())

            fig3 = px.histogram(
                x=freqs,
                nbins=30,
                labels={'x': 'Frequ√™ncia de coocorr√™ncia', 'y': 'N√∫mero de pares'},
                title="Distribui√ß√£o das Frequ√™ncias"
            )

            st.plotly_chart(fig3, use_container_width=True)

        st.divider()

        # ========== SUB-ABA 4: GRAFO ==========
        with t4:
            st.header("üï∏Ô∏è An√°lise do Grafo")

            # M√©tricas do grafo
            col1, col2, col3, col4 = st.columns(4)

            col1.metric("N√≥s", len(G.nodes()))
            col2.metric("Arestas", len(G.edges()))

            if len(G.nodes()) > 0:
                col3.metric("Densidade", f"{nx.density(G):.4f}")
                avg_degree = sum(dict(G.degree()).values()) / len(G.nodes())
                col4.metric("Grau M√©dio", f"{avg_degree:.2f}")

            if len(G.nodes()) > 0:
                st.divider()

                # Centralidade
                st.subheader("üìä An√°lise de Centralidade")

                tipo_centralidade = st.selectbox(
                    "Tipo de centralidade:",
                    ["Grau", "Intermedia√ß√£o", "Proximidade"],
                    key="centrality_type"
                )

                if tipo_centralidade == "Grau":
                    centrality = nx.degree_centrality(G)
                elif tipo_centralidade == "Intermedia√ß√£o":
                    centrality = nx.betweenness_centrality(G)
                else:
                    centrality = nx.closeness_centrality(G)

                top_central = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:20]

                df_central = pd.DataFrame(top_central, columns=['Conceito', 'Centralidade'])

                fig = px.bar(
                    df_central,
                    x='Centralidade',
                    y='Conceito',
                    orientation='h',
                    title=f"Top 20 - Centralidade de {tipo_centralidade}",
                    color='Centralidade',
                    color_continuous_scale='viridis'
                )
                fig.update_layout(
                    height=600,
                    yaxis={'categoryorder': 'total ascending'}
                )

                st.plotly_chart(fig, use_container_width=True)

                st.divider()

                # Comunidades
                st.subheader("üë• Detec√ß√£o de Comunidades (Cluster)")

                try:
                    from networkx.algorithms import community
                    communities = list(community.greedy_modularity_communities(G))

                    st.metric("N√∫mero de Comunidades", len(communities))

                    for i, comm in enumerate(communities, 1):
                        with st.expander(f"Comunidade {i} ({len(comm)} conceitos)"):
                            members = list(comm)[:20]
                            st.write(", ".join(members))
                            if len(comm) > 20:
                                st.caption(f"... e mais {len(comm)-20} conceitos")

                except Exception as e:
                    st.info("N√£o foi poss√≠vel detectar comunidades")

                st.divider()

                # Visualiza√ß√£o interativa
                st.subheader("üé® Visualiza√ß√£o Interativa")

                if len(G.nodes()) <= 100:
                    top_viz = st.slider("N√≥s a visualizar:", 5, min(50, len(G.nodes())), 15, key="viz_nodes")

                    top_nodes = [n for n, _ in sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:top_viz]]

                    Gv = G.subgraph(top_nodes).copy()
                    pos = nx.spring_layout(Gv, k=0.5, iterations=50, seed=42)

                    # Criar tra√ßos
                    edge_trace = go.Scatter(
                        x=[],
                        y=[],
                        mode='lines',
                        line=dict(width=0.5, color='#888'),
                        hoverinfo='none'
                    )

                    for edge in Gv.edges():
                        x0, y0 = pos[edge[0]]
                        x1, y1 = pos[edge[1]]
                        edge_trace['x'] += tuple([x0, x1, None])
                        edge_trace['y'] += tuple([y0, y1, None])

                    node_trace = go.Scatter(
                        x=[],
                        y=[],
                        mode='markers+text',
                        hoverinfo='text',
                        text=[],
                        textposition="top center",
                        marker=dict(
                            size=[],
                            color=[],
                            colorscale='Viridis',
                            showscale=True,
                            colorbar=dict(title="Centralidade")
                        )
                    )

                    for node in Gv.nodes():
                        x, y = pos[node]
                        node_trace['x'] += tuple([x])
                        node_trace['y'] += tuple([y])
                        node_trace['text'] += tuple([node[:20]])
                        node_trace['marker']['size'] += tuple([centrality[node] * 50 + 10])
                        node_trace['marker']['color'] += tuple([centrality[node]])

                    fig = go.Figure(
                        data=[edge_trace, node_trace],
                        layout=go.Layout(
                            title="Rede Interativa de Conceitos",
                            showlegend=False,
                            hovermode='closest',
                            margin=dict(b=0, l=0, r=0, t=40),
                            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                            height=700
                        )
                    )

                    st.plotly_chart(fig, use_container_width=True)

                else:
                    st.warning("‚ö†Ô∏è Grafo muito grande (>100 n√≥s). Use filtros para reduzir o tamanho.")

        st.divider()

        # ========== SUB-ABA 5: MAPA TEM√ÅTICO =========
        with t5:
            st.header("üó∫Ô∏è Mapa Tem√°tico (Diagrama Estrat√©gico)")

            st.markdown("""
            O **Mapa Tem√°tico** organiza os conceitos em clusters e os classifica em quatro quadrantes
            a partir de centralidade (import√¢ncia no campo) e densidade (coes√£o interna):

            - üéØ **Temas Motores**: Centrais e bem desenvolvidos (PRIORIZE)
            - üî∑ **Temas Nicho**: Especializados e coesos
            - üî∂ **Temas B√°sicos**: Transversais, mas em desenvolvimento
            - üî¥ **Temas Emergentes / Declinantes**: Fronteiras de pesquisa
            """)

            if len(G.nodes()) < 5:
                st.warning("‚ö†Ô∏è Poucos conceitos no grafo para gerar um mapa tem√°tico confi√°vel (m√≠nimo ‚âà 10).")
            else:
                col1, col2 = st.columns(2)

                with col1:
                    cluster_method = st.selectbox(
                        "M√©todo de Clusteriza√ß√£o:",
                        ["louvain", "greedy"],
                        help="Algoritmo para detectar comunidades no grafo de coocorr√™ncias"
                    )

                with col2:
                    min_cluster_size = st.slider(
                        "Tamanho m√≠nimo do cluster:",
                        min_value=2,
                        max_value=10,
                        value=3,
                        help="Quantidade m√≠nima de conceitos por cluster"
                    )

                if st.button("üîç Gerar Mapa Tem√°tico", type="primary", key="generate_thematic_map"):
                    try:
                        from thematic_map_module import ThematicMapAnalyzer

                        with st.spinner("üîÑ Detectando clusters e calculando m√©tricas do mapa tem√°tico..."):
                            tm_analyzer = ThematicMapAnalyzer(G, concepts_lists)
                            tm_analyzer.detect_clusters(
                                method=cluster_method,
                                min_size=min_cluster_size
                            )
                            metrics_df = tm_analyzer.analyze_clusters()

                        if metrics_df is None or len(metrics_df) == 0:
                            st.warning("‚ö†Ô∏è Nenhum cluster detectado. Verifique os par√¢metros ou amplie o corpus.")
                        else:
                            # ---------- Converter m√©tricas em estrutura 'thematic_data' ----------
                            thematic_data = []
                            tipo_map = {
                                "Q1: Motor Themes": "Motor Theme",
                                "Q2: Basic/Transversal Themes": "Basic Theme",
                                "Q3: Niche Themes": "Niche Theme",
                                "Q4: Emerging/Declining Themes": "Emerging/Declining Theme",
                            }

                            centralidades = []
                            densidades = []

                            # garante alinhamento: mesma ordem de metrics_df e tm_analyzer.clusters
                            for idx, row in metrics_df.reset_index(drop=True).iterrows():
                                quadrante = ThematicMapAnalyzer.classify_quadrant(
                                    row["centralidade_norm"],
                                    row["densidade_norm"]
                                )
                                tipo = tipo_map.get(quadrante, "Basic Theme")

                                # conceitos do cluster (set -> lista ordenada)
                                conceitos_cluster = sorted(tm_analyzer.clusters[idx])
                                tamanho_cluster = len(conceitos_cluster)

                                # conceito principal: primeiro da lista de principais ou primeiro do cluster
                                if isinstance(row.get("conceitos_principais", ""), str) and row["conceitos_principais"].strip():
                                    conceito_principal = row["conceitos_principais"].split(",")[0].strip()
                                else:
                                    conceito_principal = conceitos_cluster[0] if conceitos_cluster else ""

                                registro = {
                                    "cluster_id": idx + 1,
                                    "nome": row["nome"],
                                    "tipo": tipo,
                                    "tamanho": tamanho_cluster,
                                    "centralidade": float(row["centralidade"]),
                                    "densidade": float(row["densidade"]),
                                    "conceitos": conceitos_cluster,
                                    "conceito_principal": conceito_principal,
                                }

                                thematic_data.append(registro)
                                centralidades.append(registro["centralidade"])
                                densidades.append(registro["densidade"])

                            if not thematic_data:
                                st.warning("‚ö†Ô∏è Clusters foram detectados, mas n√£o foi poss√≠vel montar o mapa tem√°tico.")
                            else:
                                # ---------- M√©tricas de topo ----------
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    st.metric("Total de Clusters", len(thematic_data))
                                with col2:
                                    motor_themes = sum(1 for t in thematic_data if t["tipo"] == "Motor Theme")
                                    st.metric("Motor Themes", motor_themes)
                                with col3:
                                    total_concepts = sum(t["tamanho"] for t in thematic_data)
                                    st.metric("Conceitos Agrupados", total_concepts)
                                with col4:
                                    st.metric("Tamanho M√©dio", f"{total_concepts / len(thematic_data):.1f}")

                                # ---------- Diagrama estrat√©gico ----------
                                med_centrality = sum(centralidades) / len(centralidades)
                                med_density = sum(densidades) / len(densidades)

                                color_map = {
                                    "Motor Theme": "#2ecc71",               # verde
                                    "Niche Theme": "#3498db",               # azul
                                    "Emerging/Declining Theme": "#e74c3c",  # vermelho
                                    "Basic Theme": "#f39c12",               # amarelo
                                }

                                colors_list = [color_map.get(t["tipo"], "#95a5a6") for t in thematic_data]

                                fig_mapa = go.Figure()

                                fig_mapa.add_hline(y=med_density, line_dash="dash", line_color="gray")
                                fig_mapa.add_vline(x=med_centrality, line_dash="dash", line_color="gray")

                                fig_mapa.add_trace(go.Scatter(
                                    x=centralidades,
                                    y=densidades,
                                    mode="markers+text",
                                    marker=dict(
                                        size=[20 + t["tamanho"] * 5 for t in thematic_data],
                                        color=colors_list,
                                        line=dict(width=2, color="white"),
                                        opacity=0.85,
                                    ),
                                    text=[f"C{t['cluster_id']}" for t in thematic_data],
                                    textposition="middle center",
                                    textfont=dict(size=10, color="white", family="Arial Black"),
                                    hovertemplate=(
                                        "<b>%{customdata[0]}</b><br>" +
                                        "Centralidade: %{x:.3f}<br>" +
                                        "Densidade: %{y:.3f}<br>" +
                                        "Tipo: %{customdata[1]}<br>" +
                                        "Tamanho: %{customdata[2]} conceitos<br>" +
                                        "<extra></extra>"
                                    ),
                                    customdata=[
                                        [t["nome"], t["tipo"], t["tamanho"]]
                                        for t in thematic_data
                                    ],
                                    showlegend=False
                                ))

                                fig_mapa.update_layout(
                                    title="Diagrama Estrat√©gico dos Clusters Tem√°ticos",
                                    xaxis_title="Centralidade",
                                    yaxis_title="Densidade",
                                    height=600,
                                    plot_bgcolor="white",
                                    xaxis=dict(gridcolor="lightgray"),
                                    yaxis=dict(gridcolor="lightgray"),
                                )

                                st.plotly_chart(fig_mapa, use_container_width=True)

                                # ---------- Detalhamento dos clusters ----------
                                st.markdown("### üìã Detalhamento dos Clusters")

                                tipo_icons = {
                                    "Motor Theme": "üéØ",
                                    "Basic Theme": "üî∂",
                                    "Niche Theme": "üíé",
                                    "Emerging/Declining Theme": "üî¥",
                                }

                                for cluster in thematic_data:
                                    icon = tipo_icons.get(cluster["tipo"], "‚ö™")

                                    with st.expander(f"{icon} {cluster['nome']} - {cluster['tipo']}"):
                                        col1, col2 = st.columns([2, 1])

                                        with col1:
                                            st.write("**Conceitos:**")
                                            concepts_display = ", ".join(cluster["conceitos"][:10])
                                            if len(cluster["conceitos"]) > 10:
                                                concepts_display += f" ... (+{len(cluster['conceitos']) - 10} mais)"
                                            st.write(concepts_display)

                                        with col2:
                                            st.metric("Centralidade", f"{cluster['centralidade']:.3f}")
                                            st.metric("Densidade", f"{cluster['densidade']:.3f}")
                                            st.metric("Tamanho", cluster["tamanho"])

                                        # Interpreta√ß√£o sint√©tica
                                        if "Motor" in cluster["tipo"]:
                                            st.success("üéØ Tema central e maduro. **PRIORIZE** na revis√£o de literatura.")
                                        elif "Niche" in cluster["tipo"]:
                                            st.info(f"üíé Tema especializado. √ötil para nichos relacionados a '{cluster['conceito_principal']}'.")
                                        elif "Basic" in cluster["tipo"]:
                                            st.warning("üî∂ Tema transversal. Oportunidade para pesquisas integradoras.")
                                        else:
                                            st.error("üî¥ Tema emergente ou em decl√≠nio. Fronteira de pesquisa.")

                            # ---------- Explica√ß√£o metodol√≥gica ----------
                            with st.expander("‚ÑπÔ∏è Sobre a metodologia"):
                                st.markdown("""
                                Este mapa tem√°tico segue a l√≥gica do *Diagrama Estrat√©gico*:

                                - **Densidade**: m√©dia dos pesos das arestas internas do cluster (coes√£o interna).
                                - **Centralidade**: soma dos pesos das arestas que ligam o cluster a outros clusters (relev√¢ncia global).
                                - A posi√ß√£o de cada cluster no plano Centralidade √ó Densidade permite interpretar seu papel
                                  na estrutura do campo de pesquisa.

                                Refer√™ncias:

                                - ARIA, M.; CUCCURULLO, C. Bibliometrix: An R-tool for comprehensive science mapping analysis. *Journal of Informetrics*, v.11, n.4, p.959‚Äì975, 2017. Doi: http://dx.doi.org/10.1016/j.joi.2017.08.007
                                - HE, Q. (1999). Knowledge discovery through co-word analysis. *Library Trends*, v.48, n.1, p.133‚Äì159, 1999. Dispon√≠vel em: https://www.proquest.com/scholarly-journals/knowledge-discovery-through-co-word-analysis/docview/220452924/se-2 
                                """)

                    except ImportError:
                        st.error("""
                        N√£o foi poss√≠vel importar o m√≥dulo `thematic_map_module`.
                        Verifique se o arquivo `thematic_map_module.py` est√° no mesmo diret√≥rio
                        de `streamlit_app.py` e se voc√™ executou a c√©lula que o cria no Colab.
                        """)
                    except Exception as e:
                        st.error(f"Erro ao gerar mapa tem√°tico: {e}")
                        with st.expander("üêõ Detalhes t√©cnicos do erro"):
                            st.exception(e)

        # ========== SUB-ABA 6: ESTAT√çSTICAS ==========
        with t6:
            st.header("üìä Estat√≠sticas Completas")

            st.subheader("üìã Resumo Geral")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**üìö Dados:**")
                st.write(f"‚Ä¢ Artigos: {len(articles)}")
                st.write(f"‚Ä¢ Com conceitos: {len(concepts_lists)}")
                if len(articles) > 0:
                    st.write(f"‚Ä¢ Aproveitamento: {len(concepts_lists)/len(articles)*100:.1f}%")
                st.write(f"‚Ä¢ Conceitos total: {len(all_concepts)}")
                st.write(f"‚Ä¢ √önicos: {len(set(all_concepts))}")

            with col2:
                st.markdown("**üï∏Ô∏è Grafo:**")
                st.write(f"‚Ä¢ N√≥s: {len(G.nodes())}")
                st.write(f"‚Ä¢ Arestas: {len(G.edges())}")
                if len(G.nodes()) > 0:
                    st.write(f"‚Ä¢ Densidade: {nx.density(G):.4f}")
                    if nx.is_connected(G):
                        st.write(f"‚Ä¢ Di√¢metro: {nx.diameter(G)}")
                    else:
                        st.write(f"‚Ä¢ Di√¢metro: N/A (grafo desconexo)")
                    st.write(f"‚Ä¢ Componentes: {nx.number_connected_components(G)}")

            st.divider()

            # Distribui√ß√µes
            st.subheader("üìà Distribui√ß√µes")

            col1, col2 = st.columns(2)

            with col1:
                if len(G.nodes()) > 0:
                    degrees = [d for n, d in G.degree()]

                    fig = px.histogram(
                        x=degrees,
                        nbins=20,
                        labels={'x': 'Grau', 'y': 'Frequ√™ncia'},
                        title="Distribui√ß√£o de Graus"
                    )

                    st.plotly_chart(fig, use_container_width=True)

            with col2:
                if len(G.edges()) > 0:
                    weights = [d['weight'] for u, v, d in G.edges(data=True)]

                    fig = px.histogram(
                        x=weights,
                        nbins=20,
                        labels={'x': 'Peso', 'y': 'Frequ√™ncia'},
                        title="Distribui√ß√£o dos Pesos das Arestas"
                    )

                    st.plotly_chart(fig, use_container_width=True)

        # ========== SUB-ABA 7: EXPORTA√á√ÉO ==========
        with t7:
            st.header("üíæ Exporta√ß√£o de Dados")

            col1, col2, col3 = st.columns(3)

            # JSON
            with col1:
                st.subheader("üìÑ JSON")

                st.download_button(
                    "üì• Artigos (JSON)",
                    json.dumps(articles, indent=2, ensure_ascii=False),
                    "articles.json",
                    "application/json",
                    use_container_width=True
                )

                st.download_button(
                    "üì• Conceitos (JSON)",
                    json.dumps(concepts_lists, indent=2, ensure_ascii=False),
                    "concepts.json",
                    "application/json",
                    use_container_width=True
                )

                cooc_json = [
                    {"conceito1": c1, "conceito2": c2, "frequencia": f}
                    for (c1, c2), f in pairs.items()
                ]

                st.download_button(
                    "üì• Coocorr√™ncias (JSON)",
                    json.dumps(cooc_json, indent=2, ensure_ascii=False),
                    "cooccurrences.json",
                    "application/json",
                    use_container_width=True
                )

            # CSV
            with col2:
                st.subheader("üìä CSV")

                df_articles_export = pd.DataFrame([
                    {
                        'title': a.get('title', ''),
                        'year': a.get('year', ''),
                        'num_concepts': len(a.get('concepts', []))
                    }
                    for a in articles
                ])

                st.download_button(
                    "üì• Artigos (CSV)",
                    df_articles_export.to_csv(index=False),
                    "articles.csv",
                    "text/csv",
                    use_container_width=True
                )

                df_concepts = pd.DataFrame(
                    freq.most_common(),
                    columns=['concept', 'frequency']
                )

                st.download_button(
                    "üì• Conceitos (CSV)",
                    df_concepts.to_csv(index=False),
                    "concepts.csv",
                    "text/csv",
                    use_container_width=True
                )

                edges_list = [[u, v, d['weight']] for u, v, d in G.edges(data=True)]
                df_cooc = pd.DataFrame(edges_list, columns=['source', 'target', 'weight'])

                st.download_button(
                    "üì• Coocorr√™ncias (CSV)",
                    df_cooc.to_csv(index=False),
                    "cooccurrences.csv",
                    "text/csv",
                    use_container_width=True
                )

            # Outros formatos
            with col3:
                st.subheader("üîß Outros")

                import tempfile

                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.graphml') as f:
                    nx.write_graphml(G, f.name)
                    with open(f.name, 'r') as file:
                        graphml_content = file.read()

                st.download_button(
                    "üì• Grafo (GraphML)",
                    graphml_content,
                    "graph.graphml",
                    "application/xml",
                    use_container_width=True
                )

                st.caption("Para Gephi/Cytoscape")

            st.divider()

            # Zip completo
            st.subheader("üì¶ Pacote Completo")

            if st.button("üéÅ Gerar ZIP com Todos os Dados", use_container_width=True):
                with st.spinner("üì¶ Gerando arquivo ZIP..."):
                    zip_buffer = BytesIO()

                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                        # JSON
                        zf.writestr('articles.json', json.dumps(articles, indent=2, ensure_ascii=False))
                        zf.writestr('concepts.json', json.dumps(concepts_lists, indent=2, ensure_ascii=False))
                        zf.writestr('cooccurrences.json', json.dumps(cooc_json, indent=2, ensure_ascii=False))

                        # CSV
                        zf.writestr('articles.csv', df_articles_export.to_csv(index=False))
                        zf.writestr('concepts.csv', df_concepts.to_csv(index=False))
                        zf.writestr('cooccurrences.csv', df_cooc.to_csv(index=False))

                        # GraphML
                        zf.writestr('graph.graphml', graphml_content)

                        # README
                        readme = f"""# Delin√©ia IX - Dados Exportados

Data: {datetime.now().strftime("%d/%m/%Y √†s %H:%M")}
Query: {query}

## Arquivos inclu√≠dos:

### JSON
- articles.json: Lista completa de artigos
- concepts.json: Conceitos extra√≠dos por artigo
- cooccurrences.json: Pares de coocorr√™ncias

### CSV
- articles.csv: Artigos (t√≠tulo, ano, num_conceitos)
- concepts.csv: Conceitos e frequ√™ncias
- cooccurrences.csv: Rede de coocorr√™ncias

### Grafo
- graph.graphml: Grafo no formato GraphML (Gephi/Cytoscape)

## Estat√≠sticas:
- Artigos: {len(articles)}
- Conceitos √∫nicos: {len(freq)}
- N√≥s no grafo: {len(G.nodes())}
- Arestas: {len(G.edges())}
"""
                        zf.writestr('README.txt', readme)

                    st.download_button(
                        "üì• Baixar painel_completo.zip",
                        zip_buffer.getvalue(),
                        "painel_completo.zip",
                        "application/zip",
                        use_container_width=True
                    )