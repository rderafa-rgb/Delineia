# -*- coding: utf-8 -*-

import streamlit as st
from datetime import datetime
from research_pipeline import ResearchScopePipeline, OpenAlexClient, CooccurrenceAnalyzer, OPENALEX_EMAIL
from pdf_generator import generate_pdf_report
import pandas as pd
import networkx as nx
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
import json
import zipfile
from io import BytesIO
import numpy as np
from scipy import stats

# ==================== FUNÃ‡ÃƒO DE ANÃLISE DE ZIPF =================
def analyze_zipf(frequency_data):
    """
    Analisa a distribuiÃ§Ã£o de frequÃªncias segundo a Lei de Zipf

    Args:
        frequency_data: Lista de tuplas (palavra, frequÃªncia) ordenada por frequÃªncia

    Returns:
        dict com mÃ©tricas e dados para plotagem
    """
    # Extrair frequÃªncias
    frequencies = [freq for _, freq in frequency_data]

    # Criar ranks (1, 2, 3, ...)
    ranks = np.arange(1, len(frequencies) + 1)

    # Converter para arrays numpy
    ranks_array = np.array(ranks)
    freq_array = np.array(frequencies)

    # Aplicar log para anÃ¡lise linear
    log_ranks = np.log10(ranks_array)
    log_freqs = np.log10(freq_array)

    # RegressÃ£o linear no espaÃ§o log-log
    slope, intercept, r_value, p_value, std_err = stats.linregress(log_ranks, log_freqs)

    # Calcular RÂ²
    r_squared = r_value ** 2

    # Gerar linha de tendÃªncia
    trend_line = 10 ** (slope * log_ranks + intercept)

    # InterpretaÃ§Ã£o
    if r_squared > 0.90:
        interpretation = "âœ… Forte aderÃªncia Ã  Lei de Zipf"
        quality = "excelente"
    elif r_squared > 0.75:
        interpretation = "âš ï¸ AderÃªncia moderada Ã  Lei de Zipf"
        quality = "boa"
    else:
        interpretation = "âŒ Fraca aderÃªncia Ã  Lei de Zipf"
        quality = "baixa"

    # AnÃ¡lise da inclinaÃ§Ã£o
    if -1.2 < slope < -0.8:
        slope_interpretation = "prÃ³ximo ao ideal (-1.0)"
    elif slope < -1.2:
        slope_interpretation = "vocabulÃ¡rio mais concentrado que o esperado"
    else:
        slope_interpretation = "vocabulÃ¡rio mais disperso que o esperado"

    return {
        'ranks': ranks_array,
        'frequencies': freq_array,
        'log_ranks': log_ranks,
        'log_freqs': log_freqs,
        'trend_line': trend_line,
        'slope': slope,
        'intercept': intercept,
        'r_squared': r_squared,
        'p_value': p_value,
        'interpretation': interpretation,
        'quality': quality,
        'slope_interpretation': slope_interpretation
    }

# ==================== CONFIGURAÃ‡ÃƒO DA PÃGINA ====================
st.set_page_config(
    page_title="DelinÃ©ia",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== ESTADOS DA SESSÃƒO ====================
if 'step' not in st.session_state:
    st.session_state.step = 1
if 'resultado' not in st.session_state:
    st.session_state.resultado = None
if 'form_data' not in st.session_state:
    st.session_state.form_data = {}
if 'dashboard_data' not in st.session_state:
    st.session_state.dashboard_data = None
if 'dashboard_query' not in st.session_state:
    st.session_state.dashboard_query = ""
if 'avaliacao_completa' not in st.session_state:
    st.session_state.avaliacao_completa = False
if 'badges' not in st.session_state:
    st.session_state.badges = []

# ==================== FUNÃ‡Ã•ES AUXILIARES ====================
def add_badge(badge_name: str) -> bool:
    """Adiciona badge ao perfil do usuÃ¡rio"""
    if badge_name not in st.session_state.badges:
        st.session_state.badges.append(badge_name)
        return True
    return False

# ==================== ABAS PRINCIPAIS ====================
tab1, tab2 = st.tabs(["ğŸ“š DelineascÃ³pio", "ğŸ“Š Dashboard"])

# ==================== ABA 1: DELINEASCÃ“PIO ====================
with tab1:
    st.title("ğŸ“š DelinÃ©ia - Sistema de Delineamento de Escopo TemÃ¡tico")
    st.caption("Ferramenta de apoio ao delineamento de projetos de pesquisa com IA e bibliometria")

    # Barra de progresso gamificada
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.session_state.step >= 1:
            st.success("âœ… Etapa 1/3: FormulÃ¡rio")
            if 'ğŸ¯ Explorador' not in st.session_state.badges:
                add_badge('ğŸ¯ Explorador')
        else:
            st.info("â³ Etapa 1/3: FormulÃ¡rio inicial")

    with col2:
        if st.session_state.step >= 2:
            st.success("âœ… Etapa 2/3: RelatÃ³rio")
            if 'ğŸ”¬ Pesquisador' not in st.session_state.badges:
                add_badge('ğŸ”¬ Pesquisador')
        else:
            st.info("â³ Etapa 2/3: Aguardando dados")

    with col3:
        if st.session_state.step >= 3:
            st.success("âœ… Etapa 3/3: AvaliaÃ§Ã£o")
            if 'ğŸ† Mestre Delineador' not in st.session_state.badges:
                add_badge('ğŸ† Mestre Delineador')
        else:
            st.info("â³ Etapa 3/3: AvaliaÃ§Ã£o")

    # Mostrar badges conquistados
    if st.session_state.badges:
        st.markdown(f"**ğŸ… Conquistas:** {' '.join(st.session_state.badges)}")

    st.divider()

    # ========== ETAPA 1: FORMULÃRIO INICIAL ==========
    if st.session_state.step == 1:
        st.header("ğŸ“ FormulÃ¡rio Inicial")

        with st.form("formulario_inicial"):
            st.subheader("ğŸ‘¤ IdentificaÃ§Ã£o")
            col1, col2 = st.columns(2)

            with col1:
                nome = st.text_input(
                    "Nome completo*",
                    placeholder="Ex: Ana Silva",
                    help="Seu nome completo"
                )

            with col2:
                email = st.text_input(
                    "E-mail*",
                    placeholder="Ex: ana@email.com",
                    help="Seu e-mail para contato"
                )

            st.divider()
            st.subheader("ğŸ”¬ Projeto de Pesquisa")

            tema = st.text_input(
                "F1.1. Tema da Pesquisa*",
                placeholder="Ex: Pesquisa brasileira em HIV/AIDS",
                help="Tema principal do seu projeto"
            )

            questao = st.text_area(
                "F1.2. QuestÃ£o de Pesquisa*",
                placeholder="Ex: Como os tÃ³picos de pesquisa em HIV/AIDS evoluÃ­ram no Brasil?",
                height=100,
                help="Pergunta principal que vocÃª quer responder"
            )

            palavras_chave = st.text_input(
                "F1.3. Palavras-chave*",
                placeholder="Ex: HIV/AIDS, Pesquisa, Brasil",
                help="Separe as palavras-chave por vÃ­rgula"
            )

            google_academico = st.text_area(
                "F1.4. Se vocÃª fosse pesquisar referÃªncias para seu projeto no Google AcadÃªmico, o que vocÃª colocaria no campo de busca?*",
                placeholder="Ex: Pesquisas sobre HIV/AIDS no Brasil",
                help="Campo livre para indicar palavras, frases, etc. que vocÃª quer pesquisar",
                height=100
            )

            st.divider()
            st.subheader("ğŸ’­ AutoavaliaÃ§Ã£o")

            confianca = st.select_slider(
                "F1.5. Qual seu nÃ­vel de seguranÃ§a em relaÃ§Ã£o Ã s palavras-chave escolhidas?",
                options=[
                    "Totalmente inseguro",
                    "Inseguro",
                    "Neutro",
                    "Seguro",
                    "Totalmente seguro"
                ],
                value="Neutro",
                help="Avalie sua confianÃ§a nas palavras-chave selecionadas"
            )

            st.divider()

            submitted = st.form_submit_button(
                "ğŸš€ Gerar RelatÃ³rio de Delineamento",
                type="primary",
                use_container_width=True
            )

            if submitted:
                if not all([nome, email, tema, questao, palavras_chave]):
                    st.error("âš ï¸ Por favor, preencha todos os campos obrigatÃ³rios (*)")
                else:
                    # Salvar dados do formulÃ¡rio
                    st.session_state.form_data = {
                        'nome': nome,
                        'email': email,
                        'tema': tema,
                        'questao': questao,
                        'palavras_chave': palavras_chave,
                        'confianca': confianca,
                        'google_academico': google_academico,
                        'timestamp': datetime.now().strftime("%d/%m/%Y Ã s %H:%M")
                    }

                    with st.spinner("ğŸ”„ Processando... (aguarde 2-3 minutos)"):
                        try:
                            # Inicializar pipeline
                            pipe = ResearchScopePipeline(OPENALEX_EMAIL)

                            # Processar palavras-chave
                            kws = [k.strip() for k in palavras_chave.split(',') if k.strip()]

                            # Executar pipeline
                            st.session_state.resultado = pipe.process(nome, tema, questao, kws)

                            # AvanÃ§ar para prÃ³xima etapa
                            st.session_state.step = 2
                            st.rerun()

                        except Exception as e:
                            st.error(f"âŒ Erro ao processar: {str(e)}")
                            st.exception(e)

    # ========== ETAPA 2: RELATÃ“RIO ==========
    elif st.session_state.step == 2:
        d = st.session_state.form_data
        r = st.session_state.resultado

        st.header("ğŸ“Š RelatÃ³rio de Delineamento")
        st.caption("[ RelatÃ³rio produzido por InteligÃªncia Artificial ]")

        # BotÃµes de aÃ§Ã£o
        col1, col2, col3, col4 = st.columns([2, 1, 1, 1])

        with col1:
            if st.button("â¬…ï¸ Voltar ao FormulÃ¡rio"):
                st.session_state.step = 1
                st.rerun()

        with col2:
            try:
                pdf_bytes = generate_pdf_report(d, r)
                st.download_button(
                    "ğŸ“¥ Baixar PDF",
                    pdf_bytes,
                    f"delineamento_{d['nome'].replace(' ', '_')}.pdf",
                    "application/pdf",
                    use_container_width=True
                )
            except Exception as e:
                st.error(f"Erro ao gerar PDF: {str(e)}")

        with col3:
            if st.button("ğŸ“ Avaliar Sistema", type="primary", use_container_width=True):
                st.session_state.step = 3
                st.rerun()

        with col4:
            if st.button("ğŸ”„ Novo Projeto"):
                st.session_state.step = 1
                st.session_state.resultado = None
                st.session_state.form_data = {}
                st.session_state.avaliacao_completa = False
                st.session_state.badges = []
                st.rerun()

        st.divider()

        # InformaÃ§Ãµes do projeto
        with st.container(border=True):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**ğŸ‘¤ Aluno:** {d['nome']}")
                st.write(f"**ğŸ“§ E-mail:** {d['email']}")
            with col2:
                st.write(f"**ğŸ“… Data:** {d['timestamp']}")
                st.write(f"**ğŸ’­ ConfianÃ§a:** {d['confianca']}")

        with st.container(border=True):
            st.write(f"**ğŸ¯ Tema:** {d['tema']}")
            st.write(f"**â“ QuestÃ£o:** {d['questao']}")
            st.write(f"**ğŸ”‘ Palavras-chave:** {d['palavras_chave']}")

        # AvaliaÃ§Ã£o do projeto
        st.subheader("ğŸ“‹ AvaliaÃ§Ã£o do Projeto")
        st.markdown(r.get('full_report', 'âš ï¸ AvaliaÃ§Ã£o nÃ£o disponÃ­vel'))

        st.markdown("Com base nas palavras-chave fornecidas, desenvolvemos uma string de busca:")

        # String de busca
        st.subheader("ğŸ” String de Busca")

        search_string = r.get('search_string', 'N/A')

        col_a, col_b = st.columns([3, 1])

        with col_a:
            with st.expander("ğŸ“„ Ver string completa", expanded=True):
                st.code(search_string, language='text')

        with col_b:
            if st.button("ğŸ“‹ Copiar para Dashboard", use_container_width=True):
                st.session_state.dashboard_query = search_string
                st.success("âœ… Copiado!")

        st.write(f"**Objetivo:** {r.get('search_objective', '')}")

        st.markdown("Elaborou-se um modelo de visualizaÃ§Ã£o das coocorrÃªncias entre conceitos:")

        # MÃ©tricas
        col1, col2, col3 = st.columns(3)
        col1.metric("ğŸ“š Artigos Analisados", r.get('articles_count', 0))
        col2.metric("ğŸ§© Conceitos Identificados", r['graph_stats']['nodes'])
        col3.metric("ğŸ”— ConexÃµes no Grafo", r['graph_stats']['edges'])

        # Grafo de coocorrÃªncia
        st.subheader("ğŸ•¸ï¸ Grafo de CoocorrÃªncia de Conceitos")

        if r.get('visualization_path'):
            st.image(r['visualization_path'], use_container_width=True)
        else:
            st.warning("âš ï¸ VisualizaÃ§Ã£o nÃ£o disponÃ­vel")

        # GlossÃ¡rio
        st.subheader("ğŸ“– GlossÃ¡rio de Conceitos")
        st.markdown(r.get('glossary', 'âš ï¸ GlossÃ¡rio nÃ£o disponÃ­vel'))

        # InterpretaÃ§Ã£o
        st.subheader("ğŸ’¡ InterpretaÃ§Ã£o do Grafo")
        st.write(r.get('graph_interpretation', 'âš ï¸ InterpretaÃ§Ã£o nÃ£o disponÃ­vel'))

        # CTA para avaliaÃ§Ã£o
        st.divider()
        st.info("ğŸ’ Ajude a melhorar o DelinÃ©ia! Complete a avaliaÃ§Ã£o e desbloqueie o distintivo **ğŸ† Mestre Delineador**")

        if st.button("â¡ï¸ Ir para AvaliaÃ§Ã£o", type="primary", use_container_width=True):
            st.session_state.step = 3
            st.rerun()

# ========== ETAPA 3: AVALIAÃ‡ÃƒO EXPANDIDA ==========
    elif st.session_state.step == 3:
        st.header("ğŸ“‹ AvaliaÃ§Ã£o do Sistema DelinÃ©ia")
        st.caption("Suas respostas sÃ£o fundamentais para aprimorarmos a ferramenta!")

        st.info("ğŸ“Š **Novo formulÃ¡rio expandido:** 30 perguntas + NPS + 4 campos abertos")

        with st.form("formulario_avaliacao"):

            # ==================== SEÃ‡ÃƒO 1: UTILIDADE PERCEBIDA ====================
            st.subheader("ğŸ’¼ Utilidade Percebida")

            q1 = st.radio(
                "1. Usar o DelinÃ©ia melhora minha capacidade de delinear o escopo da pesquisa",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q1"
            )

            q2 = st.radio(
                "2. Usar o DelinÃ©ia aumenta minha produtividade na definiÃ§Ã£o do projeto",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q2"
            )

            q3 = st.radio(
                "3. O DelinÃ©ia Ã© Ãºtil para delimitar meu projeto de pesquisa",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q3"
            )

            # â­ NOVA PERGUNTA
            q4 = st.radio(
                "4. O DelinÃ©ia me ajuda a identificar lacunas na literatura do meu tema",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q4"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 2: FACILIDADE DE USO ====================
            st.subheader("ğŸ¯ Facilidade de Uso Percebida")

            q5 = st.radio(
                "5. Aprender a usar o DelinÃ©ia Ã© fÃ¡cil para mim",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q5"
            )

            q6 = st.radio(
                "6. A interaÃ§Ã£o com o DelinÃ©ia Ã© clara e compreensÃ­vel",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q6"
            )

            q7 = st.radio(
                "7. Eu acho o DelinÃ©ia fÃ¡cil de usar",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q7"
            )

            # â­ NOVA PERGUNTA
            q8 = st.radio(
                "8. A navegaÃ§Ã£o entre as diferentes funcionalidades Ã© intuitiva",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q8"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 3: QUALIDADE DA INFORMAÃ‡ÃƒO ====================
            st.subheader("ğŸ“Š Qualidade da InformaÃ§Ã£o")

            q9 = st.radio(
                "9. As informaÃ§Ãµes fornecidas pelo DelinÃ©ia sÃ£o precisas",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q9"
            )

            q10 = st.radio(
                "10. As anÃ¡lises e sugestÃµes do sistema sÃ£o relevantes para meu projeto",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q10"
            )

            q11 = st.radio(
                "11. O grafo de coocorrÃªncias me ajudou a visualizar relaÃ§Ãµes entre conceitos",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q11"
            )

            # â­ NOVA PERGUNTA
            q12 = st.radio(
                "12. A avaliaÃ§Ã£o gerada pela IA Ã© construtiva e especÃ­fica para meu projeto",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q12"
            )

            st.divider()

            # ==================== â­ SEÃ‡ÃƒO 4: FUNCIONALIDADES ESPECÃFICAS (NOVA) ====================
            st.subheader("ğŸ—ºï¸ AvaliaÃ§Ã£o de Funcionalidades EspecÃ­ficas")

            q13 = st.radio(
                "13. O Mapa TemÃ¡tico EstratÃ©gico me ajudou a posicionar meu tema na literatura",
                ["NÃ£o usei", "Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=False,
                key="q13"
            )

            q14 = st.radio(
                "14. A anÃ¡lise de Zipf foi Ãºtil para entender a distribuiÃ§Ã£o de conceitos",
                ["NÃ£o usei", "Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=False,
                key="q14"
            )

            q15 = st.radio(
                "15. O Dashboard exploratÃ³rio permite insights que eu nÃ£o teria manualmente",
                ["NÃ£o usei", "Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=False,
                key="q15"
            )

            q16 = st.radio(
                "16. O relatÃ³rio em PDF Ã© adequado para apresentar ao meu orientador",
                ["NÃ£o gerei PDF", "Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=False,
                key="q16"
            )

            st.divider()

            # ==================== â­ SEÃ‡ÃƒO 5: COMPARAÃ‡ÃƒO (NOVA) ====================
            st.subheader("âš–ï¸ ComparaÃ§Ã£o com MÃ©todos Tradicionais")

            q17 = st.radio(
                "17. O DelinÃ©ia Ã© mais eficiente que realizar buscas manuais em bases de dados",
                ["Nunca fiz busca manual", "Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=False,
                key="q17"
            )

            q18 = st.radio(
                "18. As visualizaÃ§Ãµes do DelinÃ©ia sÃ£o mais informativas que tabelas tradicionais",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q18"
            )

            q19 = st.radio(
                "19. O tempo gasto usando o DelinÃ©ia compensa os resultados obtidos",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q19"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 6: INTENÃ‡ÃƒO DE USO ====================
            st.subheader("ğŸ”® IntenÃ§Ã£o de Uso")

            q20 = st.radio(
                "20. Eu pretendo usar o DelinÃ©ia em projetos futuros",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q20"
            )

            q21 = st.radio(
                "21. Eu recomendaria o DelinÃ©ia para colegas",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q21"
            )

            # â­ NOVA PERGUNTA
            q22 = st.radio(
                "22. Eu usaria o DelinÃ©ia em diferentes fases da minha pesquisa (projeto, qualificaÃ§Ã£o, defesa)",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q22"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 7: CONFIANÃ‡A NO SISTEMA ====================
            st.subheader("ğŸ”’ ConfianÃ§a no Sistema")

            q23 = st.radio(
                "23. Eu confio nas anÃ¡lises geradas pelo DelinÃ©ia",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q23"
            )

            q24 = st.radio(
                "24. O sistema demonstra conhecimento sobre metodologia de pesquisa",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q24"
            )

            # â­ NOVA PERGUNTA
            q25 = st.radio(
                "25. Eu me sinto confortÃ¡vel em basear decisÃµes acadÃªmicas nos resultados do DelinÃ©ia",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q25"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 8: EXPERIÃŠNCIA DO USUÃRIO ====================
            st.subheader("âœ¨ ExperiÃªncia do UsuÃ¡rio")

            q26 = st.radio(
                "26. O design da interface Ã© agradÃ¡vel",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q26"
            )

            q27 = st.radio(
                "27. O tempo de processamento do relatÃ³rio foi adequado",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q27"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 9: IMPACTO EDUCACIONAL ====================
            st.subheader("ğŸ“š Impacto Educacional")

            q28 = st.radio(
                "28. O DelinÃ©ia me ensinou conceitos novos sobre bibliometria",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q28"
            )

            q29 = st.radio(
                "29. Usar o DelinÃ©ia melhorou minha alfabetizaÃ§Ã£o informacional",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q29"
            )

            # â­ NOVA PERGUNTA
            q30 = st.radio(
                "30. O sistema me ajudou a formular perguntas de pesquisa mais precisas",
                ["Discordo Totalmente", "Discordo", "Neutro", "Concordo", "Concordo Totalmente"],
                horizontal=True,
                key="q30"
            )

            st.divider()

            # ==================== â­ SEÃ‡ÃƒO 10: NPS (NOVA) ====================
            st.subheader("â­ SatisfaÃ§Ã£o Geral (Net Promoter Score)")

            nps = st.slider(
                "Em uma escala de 0 a 10, quanto vocÃª recomendaria o DelinÃ©ia para um colega?",
                min_value=0,
                max_value=10,
                value=5,
                help="0 = Definitivamente nÃ£o recomendaria | 10 = Definitivamente recomendaria"
            )

            # Mostrar categoria NPS em tempo real
            if nps >= 9:
                st.success("ğŸŒŸ **Promotor** - Obrigado pelo entusiasmo!")
            elif nps >= 7:
                st.info("ğŸ˜ **Neutro** - O que podemos melhorar?")
            else:
                st.warning("ğŸ˜ **Detrator** - Queremos ouvir suas sugestÃµes!")

            st.divider()

            # ==================== CAMPOS ABERTOS ====================
            st.subheader("ğŸ’¬ ComentÃ¡rios Adicionais")

            positivo = st.text_area(
                "O que vocÃª mais gostou no DelinÃ©ia?",
                height=100,
                key="positive_feedback",
                placeholder="Descreva os aspectos mais positivos da sua experiÃªncia..."
            )

            melhorias = st.text_area(
                "O que poderia ser melhorado?",
                height=100,
                key="improvements",
                placeholder="SugestÃµes de melhorias, funcionalidades ausentes, problemas encontrados..."
            )

            futuro = st.text_area(
                "Funcionalidades que vocÃª gostaria de ver no futuro:",
                height=100,
                key="future_features",
                placeholder="Ideias para prÃ³ximas versÃµes..."
            )

            # â­ NOVA PERGUNTA ABERTA
            uso = st.text_area(
                "Como vocÃª usou (ou pretende usar) os resultados do DelinÃ©ia em sua pesquisa?",
                height=100,
                key="usage_context",
                placeholder="Ex: projeto de qualificaÃ§Ã£o, artigo, revisÃ£o de literatura..."
            )

            st.divider()

            # ==================== â­ DADOS DEMOGRÃFICOS (NOVO) ====================
            st.subheader("ğŸ‘¤ Perfil do Respondente (Opcional)")

            col1, col2 = st.columns(2)

            with col1:
                nivel = st.selectbox(
                    "NÃ­vel acadÃªmico:",
                    ["Prefiro nÃ£o informar", "GraduaÃ§Ã£o", "EspecializaÃ§Ã£o", "Mestrado",
                     "Doutorado", "PÃ³s-Doutorado", "Docente"],
                    key="nivel_academico"
                )

                experiencia = st.selectbox(
                    "ExperiÃªncia prÃ©via com bibliometria:",
                    ["Nenhuma", "BÃ¡sica", "IntermediÃ¡ria", "AvanÃ§ada"],
                    key="experiencia_biblio"
                )

            with col2:
                area = st.selectbox(
                    "Ãrea do conhecimento:",
                    ["Prefiro nÃ£o informar", "CiÃªncias Exatas", "CiÃªncias BiolÃ³gicas", "CiÃªncias da SaÃºde",
                     "CiÃªncias AgrÃ¡rias", "CiÃªncias Sociais Aplicadas", "CiÃªncias Humanas",
                     "LinguÃ­stica/Letras/Artes", "Engenharias", "Multidisciplinar"],
                    key="area_conhecimento"
                )

                tempo_uso = st.selectbox(
                    "Tempo gasto usando o DelinÃ©ia hoje:",
                    ["< 15 min", "15-30 min", "30-60 min", "> 1 hora"],
                    key="tempo_uso"
                )

            st.divider()

            # ==================== BOTÃƒO DE ENVIO ====================
            submitted = st.form_submit_button(
                "ğŸ“¤ Enviar AvaliaÃ§Ã£o",
                type="primary",
                use_container_width=True
            )

            if submitted:
                # Calcular categoria NPS
                if nps >= 9:
                    nps_category = "Promotor ğŸŒŸ"
                elif nps >= 7:
                    nps_category = "Neutro ğŸ˜"
                else:
                    nps_category = "Detrator ğŸ˜"

                # Armazenar respostas
                avaliacao_data = {
                    # Perguntas Likert
                    'q1': q1, 'q2': q2, 'q3': q3, 'q4': q4, 'q5': q5,
                    'q6': q6, 'q7': q7, 'q8': q8, 'q9': q9, 'q10': q10,
                    'q11': q11, 'q12': q12, 'q13': q13, 'q14': q14, 'q15': q15,
                    'q16': q16, 'q17': q17, 'q18': q18, 'q19': q19, 'q20': q20,
                    'q21': q21, 'q22': q22, 'q23': q23, 'q24': q24, 'q25': q25,
                    'q26': q26, 'q27': q27, 'q28': q28, 'q29': q29, 'q30': q30,
                    # NPS
                    'nps': nps,
                    'nps_category': nps_category,
                    # Campos abertos
                    'positivo': positivo,
                    'melhorias': melhorias,
                    'futuro': futuro,
                    'uso': uso,
                    # DemogrÃ¡fico
                    'nivel': nivel,
                    'experiencia': experiencia,
                    'area': area,
                    'tempo_uso': tempo_uso,
                    # Metadados
                    'timestamp': datetime.now().isoformat()
                }

                # Salvar em session_state
                st.session_state.avaliacao_completa = True
                st.session_state.avaliacao_data = avaliacao_data

                # Badge de conclusÃ£o
                add_badge('ğŸ† Mestre Avaliador')

                # Feedback visual
                st.success("âœ… AvaliaÃ§Ã£o enviada com sucesso!")
                st.balloons()

                # Resumo da avaliaÃ§Ã£o
                st.info(f"""
                ğŸ“Š **Resumo da sua avaliaÃ§Ã£o:**

                â€¢ **NPS:** {nps}/10 ({nps_category})
                â€¢ **NÃ­vel acadÃªmico:** {nivel}
                â€¢ **ExperiÃªncia bibliomÃ©trica:** {experiencia}
                â€¢ **Ãrea:** {area}
                â€¢ **Tempo de uso:** {tempo_uso}

                ğŸ† **Badge desbloqueado:** Mestre Avaliador

                Obrigado por dedicar seu tempo para avaliar o DelinÃ©ia!
                Seu feedback Ã© essencial para o desenvolvimento contÃ­nuo do sistema.
                """)

                # AvanÃ§ar para prÃ³xima etapa
                st.session_state.step = 4
                st.rerun()

    # ========== ETAPA 4: CONCLUSÃƒO ==========
    elif st.session_state.step == 4:
        st.success("ğŸ‰ ParabÃ©ns! VocÃª completou todas as etapas!")
        st.markdown("### ğŸ† Conquista Desbloqueada: Mestre Delineador!")
        st.balloons()

        primeiro_nome = st.session_state.form_data['nome'].split()[0]

        st.write(f"**{primeiro_nome}**, vocÃª concluiu com sucesso:")
        st.write("âœ… Delineamento completo do projeto")
        st.write("âœ… AnÃ¡lise bibliomÃ©trica avanÃ§ada")
        st.write("âœ… AvaliaÃ§Ã£o do sistema DelinÃ©ia")
        st.write(f"\n**ğŸ… Suas conquistas:** {' '.join(st.session_state.badges)}")

        st.divider()

        col1, col2, col3 = st.columns([1, 2, 1])

        with col2:
            if st.button("ğŸ“œ Baixar Certificado de ConclusÃ£o", use_container_width=True):
                st.info("ğŸš§ Funcionalidade em desenvolvimento")

        st.divider()

        if st.button("ğŸ”„ Iniciar Novo Delineamento", use_container_width=True):
            st.session_state.step = 1
            st.session_state.resultado = None
            st.session_state.form_data = {}
            st.session_state.avaliacao_completa = False
            st.session_state.badges = []
            st.rerun()

# ==================== ABA 2: DASHBOARD DE ANÃLISE ====================
with tab2:
    st.title("ğŸ“Š Dashboard de ExploraÃ§Ã£o de Dados")
    st.caption("AnÃ¡lise profunda dos dados do OpenAlex")

    # Sidebar para configuraÃ§Ã£o
    with st.sidebar:
        st.header("âš™ï¸ Configurar Busca")

        # Campo de busca
        query = st.text_input(
            "String de Busca:",
            value=st.session_state.get('dashboard_query', "HIV/AIDS AND Brasil"),
            help="Use operadores: AND, OR, NOT"
        )

        if 'dashboard_query' in st.session_state and st.session_state.dashboard_query:
            st.info("ğŸ“‹ String copiada do DelineascÃ³pio")

        st.divider()
        st.subheader("ğŸ”§ Filtros")

        # OpÃ§Ã£o de sincronizar configuraÃ§Ãµes
        with st.expander("âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas"):
            sync_config = st.checkbox("Usar configuraÃ§Ã£o padrÃ£o", value=True)

            if sync_config:
                st.info("**ConfiguraÃ§Ã£o PadrÃ£o:**\n- Limite: 500 artigos\n- Score mÃ­nimo: 0.35\n- Level mÃ­nimo: 0")
                limit = 500
                min_score = 0.35
                min_level = 0
            else:
                limit = st.slider("Limite de artigos:", 10, 500, 100, 10)
                min_score = st.slider("Score mÃ­nimo:", 0.0, 1.0, 0.35, 0.05)
                min_level = st.slider("Level mÃ­nimo:", 0, 5, 0, 1)

        min_cooc = st.slider("CoocorrÃªncia mÃ­nima:", 1, 10, 2, 1)

        st.divider()

        # BotÃ£o de buscar
        if st.button("ğŸ” Buscar", type="primary", use_container_width=True):
            with st.spinner("ğŸ”„ Em processamento, confira no Dashboard"):
                try:
                    # Inicializar cliente
                    client = OpenAlexClient(OPENALEX_EMAIL)

                    # Buscar artigos
                    articles = client.search_articles(client.normalize_query(query), limit)

                    # Extrair conceitos
                    concepts_lists = []
                    for article in articles:
                        concepts = [
                            c['name'] for c in article.get('concepts', [])
                            if c['score'] >= min_score and c['level'] >= min_level
                        ]
                        if concepts:
                            concepts_lists.append(concepts)

                    # Construir grafo
                    analyzer = CooccurrenceAnalyzer()
                    G = analyzer.build_graph(concepts_lists, min_cooc)

                    # Salvar dados
                    st.session_state.dashboard_data = {
                        'articles': articles,
                        'concepts_lists': concepts_lists,
                        'graph': G
                    }

                    # Mostrar detalhes
                    with st.expander("ğŸ“‹ Detalhes da Busca"):
                        st.write(f"**String enviada:** {query}")
                        st.write(f"**Limite:** {limit}")
                        st.write(f"**Filtros:** scoreâ‰¥{min_score}, levelâ‰¥{min_level}")
                        st.write(f"**Artigos retornados:** {len(articles)}")
                        st.write(f"**Conceitos extraÃ­dos:** {len(concepts_lists)}")
                        st.write(f"**NÃ³s no grafo:** {len(G.nodes())}")

                    st.success(f"âœ… {len(articles)} artigos | {len(G.nodes())} conceitos")

                except Exception as e:
                    st.error(f"âŒ Erro: {str(e)}")

        st.divider()

        # ========== SEÃ‡ÃƒO SOBRE ==========
        with st.expander("ğŸ“š Sobre o DelinÃ©ia"):
            st.markdown("""
            ### O que Ã© o DelinÃ©ia?
            O DelinÃ©ia Ã© um sistema de apoio ao delineamento do escopo temÃ¡tico de projetos de pesquisa no ensino superior, desenvolvido como parte de uma tese de doutorado. A ferramenta combina InteligÃªncia Artificial (Google Gemini) com anÃ¡lise bibliomÃ©trica de coocorrÃªncia de palavras (OpenAlex) para auxiliar estudantes de graduaÃ§Ã£o e de pÃ³s-graduaÃ§Ã£o no esboÃ§o de seus projetos de pesquisa.
        
            ### Desenvolvimento
            **Autor:** Rafael Antunes dos Santos  
            **InstituiÃ§Ã£o:** Universidade Federal do Rio Grande do Sul (UFRGS), Centro Interdisciplinar de Novas Tecnologias na EducaÃ§Ã£o (Cinted), Programa de PÃ³s-GraduaÃ§Ã£o em InformÃ¡tica na EducaÃ§Ã£o (PPGIE)  
            **NÃ­vel:** Doutorado  
            **Orientador:** Prof. Dr. Eliseo Berni Reategui  
        
            **FormaÃ§Ã£o Anterior:**  
            - Mestre em ComunicaÃ§Ã£o e InformaÃ§Ã£o pela UFRGS (PPGCOM)  
            - Bacharel em Biblioteconomia pela UFRGS (DCI/FABICO) - CRB10/1898
        
            **CurrÃ­culo Lattes:** [http://lattes.cnpq.br/5228660998907867](http://lattes.cnpq.br/5228660998907867)
        
            ### Abordagem Interdisciplinar
            Este projeto situa-se no diÃ¡logo entre InformÃ¡tica na EducaÃ§Ã£o e CiÃªncia da InformaÃ§Ã£o, explorando como tecnologias de IA podem apoiar processos de pesquisa cientÃ­fica no ensino superior.
        
            ### Funcionalidades
            - **DelineascÃ³pio:** Feedback personalizado sobre projetos de pesquisa
            - **Dashboard:** AnÃ¡lise profunda dos dados do OpenAlex:
              - **Artigos:** Contagens de artigos e links de acesso
              - **Conceitos:** Contagens de conceitos e Lei de Zipf
              - **CoocorrÃªncias:** Contagens de associaÃ§Ãµes entre conceitos e matriz de calor
              - **Grafo:** VisualizaÃ§Ã£o interativa
              - **Mapa TemÃ¡tico:** PosiÃ§Ã£o de cluster na literatura recuperada
              - **EstatÃ­sticas:** Resumo breve
              - **ExportaÃ§Ã£o:** Dados em JSON, CSV, GraphML
        
            ### Tecnologias
            - Python / Streamlit
            - Google Gemini AI 2.5 Pro / Anthropic Claude Sonnet 4.5
            - OpenAlex API
            - NetworkX, Plotly, ReportLab
        
            ### Contato
            ğŸ“§ rafael.antunes@ufrgs.br
        
            ### VersÃ£o
            DelinÃ©ia XIV - 2025

            ### Agradecimentos
            Aos Professores Leandro Krug Wives, Rosa Maria Vicari, Dante Augusto Couto Barone, PatrÃ­cia Fernanda da Silva, SÃ©rgio Roberto Kieling Franco, Renato Ventura Bayan Henriques, Milton Antonio Zaro, Fernando Becker, Vanessa Soares Maurente, Elisa Boff, Alessandra Lorandi e Gabriela Trindade Perry
            Aos colegas do grupo de pesquisa GTech.Edu
            Ã€ CAPES
            """)
    
    # Ãrea principal do dashboard
    if st.session_state.dashboard_data is None:
        st.info("ğŸ‘ˆ Configure os parÃ¢metros na barra lateral e clique em **Buscar** para iniciar a anÃ¡lise")

        # Mostrar exemplo
        with st.expander("ğŸ’¡ Exemplo de uso"):
            st.markdown("""
            **Como usar o Dashboard:**

            1. **Digite uma string de busca** (ex: "machine learning AND education")
            2. **Ajuste os filtros** conforme necessÃ¡rio
            3. **Clique em Buscar** para processar
            4. **Explore as abas** com diferentes anÃ¡lises
            5. **Exporte os dados** quando necessÃ¡rio

            **Dica:** VocÃª pode copiar a string de busca do DelineascÃ³pio!
            """)

    else:
        # Recuperar dados
        data = st.session_state.dashboard_data
        articles = data['articles']
        concepts_lists = data['concepts_lists']
        G = data['graph']

        # Criar sub-abas para anÃ¡lises
        t1, t2, t3, t4, t5, t6, t7 = st.tabs([
            "ğŸ“š Artigos",
            "ğŸ§© Conceitos",
            "ğŸ”— CoocorrÃªncias",
            "ğŸ•¸ï¸ Grafo",
            "ğŸ—ºï¸ Mapa TemÃ¡tico",
            "ğŸ“Š EstatÃ­sticas",
            "ğŸ’¾ ExportaÃ§Ã£o"
        ])

        # ========== SUB-ABA 1: ARTIGOS (COM DOI/URL) ==========
        with t1:
            st.header("ğŸ“š Artigos Analisados")
            st.metric("Total de Artigos", len(articles))

            # âœ¨ TABELA COM COLUNA DOI/URL âœ¨
            df_articles = pd.DataFrame([
                {
                    'TÃ­tulo': a.get('title', '')[:80] + '...' if len(a.get('title', '')) > 80 else a.get('title', ''),
                    'Ano': a.get('year', 'N/A'),
                    'Conceitos': len(a.get('concepts', [])),
                    'DOI/URL': a.get('doi', a.get('url', 'N/A'))
                }
                for a in articles
            ])

            # Configurar coluna como link clicÃ¡vel
            st.dataframe(
                df_articles,
                use_container_width=True,
                height=400,
                column_config={
                    "DOI/URL": st.column_config.LinkColumn(
                        "ğŸ”— DOI/URL",
                        help="Clique para abrir o artigo",
                        display_text="Abrir artigo"
                    )
                }
            )

            if len(articles) > 0:
                st.divider()
                st.subheader("ğŸ” Detalhes do Artigo")

                # Seletor de artigo
                idx = st.selectbox(
                    "Selecione um artigo:",
                    range(len(articles)),
                    format_func=lambda i: f"{i+1}. {articles[i].get('title', '')[:60]}..."
                )

                selected = articles[idx]

                col1, col2 = st.columns([2, 1])

                with col1:
                    st.write(f"**TÃ­tulo:** {selected.get('title', 'N/A')}")
                    st.write(f"**Ano:** {selected.get('year', 'N/A')}")

                    # âœ¨ EXIBIR LINK CLICÃVEL âœ¨
                    link = selected.get('doi', selected.get('url', ''))
                    if link:
                        st.markdown(f"**ğŸ”— Link:** [{link}]({link})")
                    else:
                        st.write("**ğŸ”— Link:** N/A")

                with col2:
                    st.metric("Conceitos", len(selected.get('concepts', [])))

                st.subheader("ğŸ“‹ Conceitos do Artigo")

                concepts_df = pd.DataFrame([
                    {
                        'Conceito': c['name'],
                        'Score': f"{c['score']:.3f}",
                        'Level': c['level']
                    }
                    for c in selected.get('concepts', [])
                ])

                if not concepts_df.empty:
                    st.dataframe(concepts_df, use_container_width=True)
                else:
                    st.info("Nenhum conceito encontrado")

                with st.expander("ğŸ” Ver JSON completo"):
                    st.json(selected)

        # ========== SUB-ABA 2: CONCEITOS ==========
        with t2:
            st.header("ğŸ§© AnÃ¡lise de Conceitos")

            # EstatÃ­sticas gerais
            all_concepts = [c for cl in concepts_lists for c in cl]
            freq = Counter(all_concepts)

            col1, col2, col3 = st.columns(3)
            col1.metric("Artigos com Conceitos", len(concepts_lists))
            col2.metric("Conceitos Ãšnicos", len(freq))
            col3.metric("Total de OcorrÃªncias", len(all_concepts))

            st.divider()

            # Top conceitos
            st.subheader("ğŸ† Conceitos Mais Frequentes")

            top_n = st.slider("NÃºmero de conceitos:", 10, 50, 20, 5, key="top_concepts")

            df_freq = pd.DataFrame(
                freq.most_common(top_n),
                columns=['Conceito', 'FrequÃªncia']
            )

            # GrÃ¡fico de barras
            fig = px.bar(
                df_freq,
                x='FrequÃªncia',
                y='Conceito',
                orientation='h',
                title=f"Top {top_n} Conceitos Mais Frequentes",
                color='FrequÃªncia',
                color_continuous_scale='blues'
            )
            fig.update_layout(
                height=600,
                yaxis={'categoryorder': 'total ascending'}
            )

            st.plotly_chart(fig, use_container_width=True)

            # AnÃ¡lise de Zipf
            def analyze_zipf(frequency_data):
                """
                Analisa a distribuiÃ§Ã£o de frequÃªncias segundo a Lei de Zipf

                Args:
                    frequency_data: Lista de tuplas (palavra, frequÃªncia) ordenada por frequÃªncia

                Returns:
                    dict com mÃ©tricas e dados para plotagem
                """
                # Extrair frequÃªncias
                frequencies = [freq for _, freq in frequency_data]

                # Criar ranks (1, 2, 3, ...)
                ranks = np.arange(1, len(frequencies) + 1)

                # Converter para arrays numpy
                ranks_array = np.array(ranks)
                freq_array = np.array(frequencies)

                # Aplicar log para anÃ¡lise linear
                log_ranks = np.log10(ranks_array)
                log_freqs = np.log10(freq_array)

                # RegressÃ£o linear no espaÃ§o log-log
                slope, intercept, r_value, p_value, std_err = stats.linregress(log_ranks, log_freqs)

                # Calcular RÂ²
                r_squared = r_value ** 2

                # Gerar linha de tendÃªncia
                trend_line = 10 ** (slope * log_ranks + intercept)

                # InterpretaÃ§Ã£o
                if r_squared > 0.90:
                    interpretation = "âœ… Forte aderÃªncia Ã  Lei de Zipf"
                    quality = "excelente"
                elif r_squared > 0.75:
                    interpretation = "âš ï¸ AderÃªncia moderada Ã  Lei de Zipf"
                    quality = "boa"
                else:
                    interpretation = "âŒ Fraca aderÃªncia Ã  Lei de Zipf"
                    quality = "baixa"

                # AnÃ¡lise da inclinaÃ§Ã£o
                if -1.2 < slope < -0.8:
                    slope_interpretation = "prÃ³ximo ao ideal (-1.0)"
                elif slope < -1.2:
                    slope_interpretation = "vocabulÃ¡rio mais concentrado que o esperado"
                else:
                    slope_interpretation = "vocabulÃ¡rio mais disperso que o esperado"

                return {
                    'ranks': ranks_array,
                    'frequencies': freq_array,
                    'log_ranks': log_ranks,
                    'log_freqs': log_freqs,
                    'trend_line': trend_line,
                    'slope': slope,
                    'intercept': intercept,
                    'r_squared': r_squared,
                    'p_value': p_value,
                    'interpretation': interpretation,
                    'quality': quality,
                    'slope_interpretation': slope_interpretation
                }

            # Executar anÃ¡lise de Zipf
            if len(freq) > 0:
                st.divider()
                st.subheader("ğŸ“ˆ AnÃ¡lise da Lei de Zipf")

                st.markdown("""
                A **Lei de Zipf** prediz que a frequÃªncia de uma palavra Ã© inversamente proporcional
                ao seu ranking. Em um grÃ¡fico log-log, isso aparece como uma linha reta com inclinaÃ§Ã£o
                prÃ³xima a -1.0.
                """)

                # Preparar dados (tuplas de palavra, frequÃªncia)
                frequency_data = freq.most_common()

                # Chamar a funÃ§Ã£o de anÃ¡lise
                zipf_results = analyze_zipf(frequency_data)

                # Exibir mÃ©tricas
                col1, col2, col3 = st.columns(3)
                col1.metric("RÂ² (AderÃªncia)", f"{zipf_results['r_squared']:.3f}")
                col2.metric("InclinaÃ§Ã£o", f"{zipf_results['slope']:.3f}")
                col3.metric("Qualidade", zipf_results['quality'].upper())

                # InterpretaÃ§Ãµes
                st.info(f"**{zipf_results['interpretation']}** - InclinaÃ§Ã£o {zipf_results['slope_interpretation']}")

                # GrÃ¡fico log-log
                fig_zipf = go.Figure()

                # Dados reais
                fig_zipf.add_trace(go.Scatter(
                    x=zipf_results['ranks'],
                    y=zipf_results['frequencies'],
                    mode='markers',
                    name='Dados Observados',
                    marker=dict(size=8, color='blue'),
                    text=[word for word, _ in frequency_data],
                    hovertemplate='<b>%{text}</b><br>Rank: %{x}<br>FrequÃªncia: %{y}<extra></extra>'
                ))

                # Linha de tendÃªncia (Lei de Zipf)
                fig_zipf.add_trace(go.Scatter(
                    x=zipf_results['ranks'],
                    y=zipf_results['trend_line'],
                    mode='lines',
                    name='Lei de Zipf (teÃ³rico)',
                    line=dict(color='red', dash='dash', width=2)
                ))

                fig_zipf.update_layout(
                    title='DistribuiÃ§Ã£o de Zipf (Escala Log-Log)',
                    xaxis_title='Ranking (log)',
                    yaxis_title='FrequÃªncia (log)',
                    xaxis_type='log',
                    yaxis_type='log',
                    height=500,
                    hovermode='closest'
                )

                st.plotly_chart(fig_zipf, use_container_width=True)

                # ExplicaÃ§Ã£o adicional
                with st.expander("â„¹ï¸ Como interpretar"):
                    st.markdown(f"""
                    **RÂ² = {zipf_results['r_squared']:.3f}**
                    - RÂ² > 0.90: Excelente aderÃªncia Ã  Lei de Zipf
                    - 0.75 < RÂ² < 0.90: Boa aderÃªncia
                    - RÂ² < 0.75: Baixa aderÃªncia

                    **InclinaÃ§Ã£o = {zipf_results['slope']:.3f}**
                    - Ideal: prÃ³ximo a -1.0
                    - Mais negativo: vocabulÃ¡rio concentrado em poucas palavras
                    - Menos negativo: vocabulÃ¡rio mais distribuÃ­do

                    **SignificÃ¢ncia estatÃ­stica**: p-value = {zipf_results['p_value']:.6f}
                    """)

            # Tabela
            st.divider()
            st.subheader("ğŸ“‹ Tabela de FrequÃªncias")
            st.dataframe(df_freq, use_container_width=True)

            st.divider()

            # DistribuiÃ§Ã£o
            st.subheader("ğŸ“Š DistribuiÃ§Ã£o de Conceitos por Artigo")

            concepts_per_article = [len(c) for c in concepts_lists]

            fig2 = px.histogram(
                x=concepts_per_article,
                nbins=20,
                labels={'x': 'NÃºmero de conceitos', 'y': 'FrequÃªncia'},
                title="DistribuiÃ§Ã£o de Conceitos por Artigo"
            )

            st.plotly_chart(fig2, use_container_width=True)

            if len(concepts_per_article) > 0:
                col1, col2, col3 = st.columns(3)
                col1.metric("MÃ©dia", f"{sum(concepts_per_article)/len(concepts_per_article):.1f}")
                col2.metric("MÃ­nimo", min(concepts_per_article))
                col3.metric("MÃ¡ximo", max(concepts_per_article))

        # ========== SUB-ABA 3: COOCORRÃŠNCIAS ==========
        with t3:
            st.header("ğŸ”— AnÃ¡lise de CoocorrÃªncias")

            # Calcular pares
            pairs = Counter()
            for concepts in concepts_lists:
                for i, c1 in enumerate(concepts):
                    for c2 in concepts[i+1:]:
                        if c1 != c2:
                            pairs[tuple(sorted([c1, c2]))] += 1

            st.metric("Pares Ãšnicos", len(pairs))

            st.divider()

            # Top pares
            st.subheader("ğŸ† CoocorrÃªncias Mais Frequentes")

            top_pairs = st.slider("NÃºmero de pares:", 10, 100, 30, 10, key="top_pairs")

            df_pairs = pd.DataFrame([
                {
                    'Conceito 1': c1,
                    'Conceito 2': c2,
                    'FrequÃªncia': f
                }
                for (c1, c2), f in pairs.most_common(top_pairs)
            ])

            st.dataframe(df_pairs, use_container_width=True)

            st.divider()

            # Matriz de calor
            st.subheader("ğŸ”¥ Matriz de Calor de CoocorrÃªncias")

            top_heatmap = st.slider("Conceitos na matriz:", 5, 20, 10, 1, key="heatmap_size")

            top_concepts = [c for c, _ in freq.most_common(top_heatmap)]

            # Criar matriz
            matrix = pd.DataFrame(0, index=top_concepts, columns=top_concepts)

            for (c1, c2), f in pairs.items():
                if c1 in top_concepts and c2 in top_concepts:
                    matrix.loc[c1, c2] = f
                    matrix.loc[c2, c1] = f

            fig = px.imshow(
                matrix,
                labels=dict(x="Conceito", y="Conceito", color="CoocorrÃªncias"),
                title=f"Matriz de Calor - Top {top_heatmap} Conceitos",
                color_continuous_scale='Blues'
            )
            fig.update_layout(height=600)

            st.plotly_chart(fig, use_container_width=True)

            st.divider()

            # DistribuiÃ§Ã£o de frequÃªncias
            st.subheader("ğŸ“ˆ DistribuiÃ§Ã£o das FrequÃªncias de CoocorrÃªncia")

            freqs = list(pairs.values())

            fig3 = px.histogram(
                x=freqs,
                nbins=30,
                labels={'x': 'FrequÃªncia de coocorrÃªncia', 'y': 'NÃºmero de pares'},
                title="DistribuiÃ§Ã£o das FrequÃªncias"
            )

            st.plotly_chart(fig3, use_container_width=True)

        st.divider()

        # ========== SUB-ABA 4: GRAFO ==========
        with t4:
            st.header("ğŸ•¸ï¸ AnÃ¡lise do Grafo")

            # MÃ©tricas do grafo
            col1, col2, col3, col4 = st.columns(4)

            col1.metric("NÃ³s", len(G.nodes()))
            col2.metric("Arestas", len(G.edges()))

            if len(G.nodes()) > 0:
                col3.metric("Densidade", f"{nx.density(G):.4f}")
                avg_degree = sum(dict(G.degree()).values()) / len(G.nodes())
                col4.metric("Grau MÃ©dio", f"{avg_degree:.2f}")

            if len(G.nodes()) > 0:
                st.divider()

                # Centralidade
                st.subheader("ğŸ“Š AnÃ¡lise de Centralidade")

                tipo_centralidade = st.selectbox(
                    "Tipo de centralidade:",
                    ["Grau", "IntermediaÃ§Ã£o", "Proximidade"],
                    key="centrality_type"
                )

                if tipo_centralidade == "Grau":
                    centrality = nx.degree_centrality(G)
                elif tipo_centralidade == "IntermediaÃ§Ã£o":
                    centrality = nx.betweenness_centrality(G)
                else:
                    centrality = nx.closeness_centrality(G)

                top_central = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:20]

                df_central = pd.DataFrame(top_central, columns=['Conceito', 'Centralidade'])

                fig = px.bar(
                    df_central,
                    x='Centralidade',
                    y='Conceito',
                    orientation='h',
                    title=f"Top 20 - Centralidade de {tipo_centralidade}",
                    color='Centralidade',
                    color_continuous_scale='viridis'
                )
                fig.update_layout(
                    height=600,
                    yaxis={'categoryorder': 'total ascending'}
                )

                st.plotly_chart(fig, use_container_width=True)

                st.divider()

                # Comunidades
                st.subheader("ğŸ‘¥ DetecÃ§Ã£o de Comunidades (Cluster)")

                try:
                    from networkx.algorithms import community
                    communities = list(community.greedy_modularity_communities(G))

                    st.metric("NÃºmero de Comunidades", len(communities))

                    for i, comm in enumerate(communities, 1):
                        with st.expander(f"Comunidade {i} ({len(comm)} conceitos)"):
                            members = list(comm)[:20]
                            st.write(", ".join(members))
                            if len(comm) > 20:
                                st.caption(f"... e mais {len(comm)-20} conceitos")

                except Exception as e:
                    st.info("NÃ£o foi possÃ­vel detectar comunidades")

                st.divider()

                # VisualizaÃ§Ã£o interativa
                st.subheader("ğŸ¨ VisualizaÃ§Ã£o Interativa")

                if len(G.nodes()) <= 100:
                    top_viz = st.slider("NÃ³s a visualizar:", 5, min(50, len(G.nodes())), 15, key="viz_nodes")

                    top_nodes = [n for n, _ in sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:top_viz]]

                    Gv = G.subgraph(top_nodes).copy()
                    pos = nx.spring_layout(Gv, k=0.5, iterations=50, seed=42)

                    # Criar traÃ§os
                    edge_trace = go.Scatter(
                        x=[],
                        y=[],
                        mode='lines',
                        line=dict(width=0.5, color='#888'),
                        hoverinfo='none'
                    )

                    for edge in Gv.edges():
                        x0, y0 = pos[edge[0]]
                        x1, y1 = pos[edge[1]]
                        edge_trace['x'] += tuple([x0, x1, None])
                        edge_trace['y'] += tuple([y0, y1, None])

                    node_trace = go.Scatter(
                        x=[],
                        y=[],
                        mode='markers+text',
                        hoverinfo='text',
                        text=[],
                        textposition="top center",
                        marker=dict(
                            size=[],
                            color=[],
                            colorscale='Viridis',
                            showscale=True,
                            colorbar=dict(title="Centralidade")
                        )
                    )

                    for node in Gv.nodes():
                        x, y = pos[node]
                        node_trace['x'] += tuple([x])
                        node_trace['y'] += tuple([y])
                        node_trace['text'] += tuple([node[:20]])
                        node_trace['marker']['size'] += tuple([centrality[node] * 50 + 10])
                        node_trace['marker']['color'] += tuple([centrality[node]])

                    fig = go.Figure(
                        data=[edge_trace, node_trace],
                        layout=go.Layout(
                            title="Rede Interativa de Conceitos",
                            showlegend=False,
                            hovermode='closest',
                            margin=dict(b=0, l=0, r=0, t=40),
                            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                            height=700
                        )
                    )

                    st.plotly_chart(fig, use_container_width=True)

                else:
                    st.warning("âš ï¸ Grafo muito grande (>100 nÃ³s). Use filtros para reduzir o tamanho.")

        st.divider()

        # ========== SUB-ABA 5: MAPA TEMÃTICO =========
        with t5:
            st.header("ğŸ—ºï¸ Mapa TemÃ¡tico (Diagrama EstratÃ©gico)")

            st.markdown("""
            O **Mapa TemÃ¡tico** organiza os conceitos em clusters e os classifica em quatro quadrantes
            a partir de centralidade (importÃ¢ncia no campo) e densidade (coesÃ£o interna):

            - ğŸ¯ **Motor Themes**: Centrais e bem desenvolvidos (PRIORIZE)
            - ğŸ”· **Niche Themes**: Especializados e coesos
            - ğŸ”¶ **Basic Themes**: Transversais, mas em desenvolvimento
            - ğŸ”´ **Emerging/Declining**: Fronteiras de pesquisa
            """)

            if len(G.nodes()) < 5:
                st.warning("âš ï¸ Poucos conceitos no grafo para gerar um mapa temÃ¡tico confiÃ¡vel (mÃ­nimo â‰ˆ 10).")
            else:
                col1, col2 = st.columns(2)

                with col1:
                    cluster_method = st.selectbox(
                        "MÃ©todo de ClusterizaÃ§Ã£o:",
                        ["louvain", "greedy"],
                        help="Algoritmo para detectar comunidades no grafo de coocorrÃªncias"
                    )

                with col2:
                    min_cluster_size = st.slider(
                        "Tamanho mÃ­nimo do cluster:",
                        min_value=2,
                        max_value=10,
                        value=3,
                        help="Quantidade mÃ­nima de conceitos por cluster"
                    )

                if st.button("ğŸ” Gerar Mapa TemÃ¡tico", type="primary", key="generate_thematic_map"):
                    try:
                        from thematic_map_module import ThematicMapAnalyzer

                        with st.spinner("ğŸ”„ Detectando clusters e calculando mÃ©tricas do mapa temÃ¡tico..."):
                            tm_analyzer = ThematicMapAnalyzer(G, concepts_lists)
                            tm_analyzer.detect_clusters(
                                method=cluster_method,
                                min_size=min_cluster_size
                            )
                            metrics_df = tm_analyzer.analyze_clusters()

                        if metrics_df is None or len(metrics_df) == 0:
                            st.warning("âš ï¸ Nenhum cluster detectado. Verifique os parÃ¢metros ou amplie o corpus.")
                        else:
                            # ---------- Converter mÃ©tricas em estrutura 'thematic_data' ----------
                            thematic_data = []
                            tipo_map = {
                                "Q1: Motor Themes": "Motor Theme",
                                "Q2: Basic/Transversal Themes": "Basic Theme",
                                "Q3: Niche Themes": "Niche Theme",
                                "Q4: Emerging/Declining Themes": "Emerging/Declining Theme",
                            }

                            centralidades = []
                            densidades = []

                            # garante alinhamento: mesma ordem de metrics_df e tm_analyzer.clusters
                            for idx, row in metrics_df.reset_index(drop=True).iterrows():
                                quadrante = ThematicMapAnalyzer.classify_quadrant(
                                    row["centralidade_norm"],
                                    row["densidade_norm"]
                                )
                                tipo = tipo_map.get(quadrante, "Basic Theme")

                                # conceitos do cluster (set -> lista ordenada)
                                conceitos_cluster = sorted(tm_analyzer.clusters[idx])
                                tamanho_cluster = len(conceitos_cluster)

                                # conceito principal: primeiro da lista de principais ou primeiro do cluster
                                if isinstance(row.get("conceitos_principais", ""), str) and row["conceitos_principais"].strip():
                                    conceito_principal = row["conceitos_principais"].split(",")[0].strip()
                                else:
                                    conceito_principal = conceitos_cluster[0] if conceitos_cluster else ""

                                registro = {
                                    "cluster_id": idx + 1,
                                    "nome": row["nome"],
                                    "tipo": tipo,
                                    "tamanho": tamanho_cluster,
                                    "centralidade": float(row["centralidade"]),
                                    "densidade": float(row["densidade"]),
                                    "conceitos": conceitos_cluster,
                                    "conceito_principal": conceito_principal,
                                }

                                thematic_data.append(registro)
                                centralidades.append(registro["centralidade"])
                                densidades.append(registro["densidade"])

                            if not thematic_data:
                                st.warning("âš ï¸ Clusters foram detectados, mas nÃ£o foi possÃ­vel montar o mapa temÃ¡tico.")
                            else:
                                # ---------- MÃ©tricas de topo ----------
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    st.metric("Total de Clusters", len(thematic_data))
                                with col2:
                                    motor_themes = sum(1 for t in thematic_data if t["tipo"] == "Motor Theme")
                                    st.metric("Motor Themes", motor_themes)
                                with col3:
                                    total_concepts = sum(t["tamanho"] for t in thematic_data)
                                    st.metric("Conceitos Agrupados", total_concepts)
                                with col4:
                                    st.metric("Tamanho MÃ©dio", f"{total_concepts / len(thematic_data):.1f}")

                                # ---------- Diagrama estratÃ©gico ----------
                                med_centrality = sum(centralidades) / len(centralidades)
                                med_density = sum(densidades) / len(densidades)

                                color_map = {
                                    "Motor Theme": "#2ecc71",               # verde
                                    "Niche Theme": "#3498db",               # azul
                                    "Emerging/Declining Theme": "#e74c3c",  # vermelho
                                    "Basic Theme": "#f39c12",               # amarelo
                                }

                                colors_list = [color_map.get(t["tipo"], "#95a5a6") for t in thematic_data]

                                fig_mapa = go.Figure()

                                fig_mapa.add_hline(y=med_density, line_dash="dash", line_color="gray")
                                fig_mapa.add_vline(x=med_centrality, line_dash="dash", line_color="gray")

                                fig_mapa.add_trace(go.Scatter(
                                    x=centralidades,
                                    y=densidades,
                                    mode="markers+text",
                                    marker=dict(
                                        size=[20 + t["tamanho"] * 5 for t in thematic_data],
                                        color=colors_list,
                                        line=dict(width=2, color="white"),
                                        opacity=0.85,
                                    ),
                                    text=[f"C{t['cluster_id']}" for t in thematic_data],
                                    textposition="middle center",
                                    textfont=dict(size=10, color="white", family="Arial Black"),
                                    hovertemplate=(
                                        "<b>%{customdata[0]}</b><br>" +
                                        "Centralidade: %{x:.3f}<br>" +
                                        "Densidade: %{y:.3f}<br>" +
                                        "Tipo: %{customdata[1]}<br>" +
                                        "Tamanho: %{customdata[2]} conceitos<br>" +
                                        "<extra></extra>"
                                    ),
                                    customdata=[
                                        [t["nome"], t["tipo"], t["tamanho"]]
                                        for t in thematic_data
                                    ],
                                    showlegend=False
                                ))

                                fig_mapa.update_layout(
                                    title="Diagrama EstratÃ©gico dos Clusters TemÃ¡ticos",
                                    xaxis_title="Centralidade",
                                    yaxis_title="Densidade",
                                    height=600,
                                    plot_bgcolor="white",
                                    xaxis=dict(gridcolor="lightgray"),
                                    yaxis=dict(gridcolor="lightgray"),
                                )

                                st.plotly_chart(fig_mapa, use_container_width=True)

                                # ---------- Detalhamento dos clusters ----------
                                st.markdown("### ğŸ“‹ Detalhamento dos Clusters")

                                tipo_icons = {
                                    "Motor Theme": "ğŸ¯",
                                    "Niche Theme": "ğŸ”·",
                                    "Emerging/Declining Theme": "ğŸ”´",
                                    "Basic Theme": "ğŸ”¶",
                                }

                                for cluster in thematic_data:
                                    icon = tipo_icons.get(cluster["tipo"], "âšª")

                                    with st.expander(f"{icon} {cluster['nome']} - {cluster['tipo']}"):
                                        col1, col2 = st.columns([2, 1])

                                        with col1:
                                            st.write("**Conceitos:**")
                                            concepts_display = ", ".join(cluster["conceitos"][:10])
                                            if len(cluster["conceitos"]) > 10:
                                                concepts_display += f" ... (+{len(cluster['conceitos']) - 10} mais)"
                                            st.write(concepts_display)

                                        with col2:
                                            st.metric("Centralidade", f"{cluster['centralidade']:.3f}")
                                            st.metric("Densidade", f"{cluster['densidade']:.3f}")
                                            st.metric("Tamanho", cluster["tamanho"])

                                        # InterpretaÃ§Ã£o sintÃ©tica
                                        if cluster["tipo"] == "Motor Theme":
                                            st.success("ğŸ’¡ Tema central e maduro. **PRIORIZE** na revisÃ£o de literatura.")
                                        elif cluster["tipo"] == "Niche Theme":
                                            st.info(f"ğŸ’¡ Tema especializado. Ãštil para nichos relacionados a '{cluster['conceito_principal']}'.")
                                        elif cluster["tipo"] == "Basic Theme":
                                            st.warning("ğŸ’¡ Tema transversal. Oportunidade para pesquisas integradoras.")
                                        else:
                                            st.error("ğŸ’¡ Tema emergente ou em declÃ­nio. Fronteira de pesquisa.")

                            # ---------- ExplicaÃ§Ã£o metodolÃ³gica ----------
                            with st.expander("â„¹ï¸ Sobre a metodologia (Aria & Cuccurullo, 2017; He, 1999)"):
                                st.markdown("""
                                Este mapa temÃ¡tico segue a lÃ³gica do *Strategic Diagram*:

                                - **Densidade**: mÃ©dia dos pesos das arestas internas do cluster (coesÃ£o interna).
                                - **Centralidade**: soma dos pesos das arestas que ligam o cluster a outros clusters (relevÃ¢ncia global).
                                - A posiÃ§Ã£o de cada cluster no plano Centralidade Ã— Densidade permite interpretar seu papel
                                  na estrutura do campo de pesquisa.

                                ReferÃªncias:

                                - Aria, M., & Cuccurullo, C. (2017). *bibliometrix: An R-tool for comprehensive science mapping analysis.*
                                  Journal of Informetrics, 11(4), 959â€“975.

                                - He, Q. (1999). *Knowledge discovery through co-word analysis.*
                                  Library Trends, 48(1), 133â€“159.
                                """)

                    except ImportError:
                        st.error("""
                        NÃ£o foi possÃ­vel importar o mÃ³dulo `thematic_map_module`.
                        Verifique se o arquivo `thematic_map_module.py` estÃ¡ no mesmo diretÃ³rio
                        de `streamlit_app.py` e se vocÃª executou a cÃ©lula que o cria no Colab.
                        """)
                    except Exception as e:
                        st.error(f"Erro ao gerar mapa temÃ¡tico: {e}")
                        with st.expander("ğŸ› Detalhes tÃ©cnicos do erro"):
                            st.exception(e)

        # ========== SUB-ABA 6: ESTATÃSTICAS ==========
        with t6:
            st.header("ğŸ“Š EstatÃ­sticas Completas")

            st.subheader("ğŸ“‹ Resumo Geral")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**ğŸ“š Dados:**")
                st.write(f"â€¢ Artigos: {len(articles)}")
                st.write(f"â€¢ Com conceitos: {len(concepts_lists)}")
                if len(articles) > 0:
                    st.write(f"â€¢ Aproveitamento: {len(concepts_lists)/len(articles)*100:.1f}%")
                st.write(f"â€¢ Conceitos total: {len(all_concepts)}")
                st.write(f"â€¢ Ãšnicos: {len(set(all_concepts))}")

            with col2:
                st.markdown("**ğŸ•¸ï¸ Grafo:**")
                st.write(f"â€¢ NÃ³s: {len(G.nodes())}")
                st.write(f"â€¢ Arestas: {len(G.edges())}")
                if len(G.nodes()) > 0:
                    st.write(f"â€¢ Densidade: {nx.density(G):.4f}")
                    if nx.is_connected(G):
                        st.write(f"â€¢ DiÃ¢metro: {nx.diameter(G)}")
                    else:
                        st.write(f"â€¢ DiÃ¢metro: N/A (grafo desconexo)")
                    st.write(f"â€¢ Componentes: {nx.number_connected_components(G)}")

            st.divider()

            # DistribuiÃ§Ãµes
            st.subheader("ğŸ“ˆ DistribuiÃ§Ãµes")

            col1, col2 = st.columns(2)

            with col1:
                if len(G.nodes()) > 0:
                    degrees = [d for n, d in G.degree()]

                    fig = px.histogram(
                        x=degrees,
                        nbins=20,
                        labels={'x': 'Grau', 'y': 'FrequÃªncia'},
                        title="DistribuiÃ§Ã£o de Graus"
                    )

                    st.plotly_chart(fig, use_container_width=True)

            with col2:
                if len(G.edges()) > 0:
                    weights = [d['weight'] for u, v, d in G.edges(data=True)]

                    fig = px.histogram(
                        x=weights,
                        nbins=20,
                        labels={'x': 'Peso', 'y': 'FrequÃªncia'},
                        title="DistribuiÃ§Ã£o dos Pesos das Arestas"
                    )

                    st.plotly_chart(fig, use_container_width=True)

        # ========== SUB-ABA 7: EXPORTAÃ‡ÃƒO ==========
        with t7:
            st.header("ğŸ’¾ ExportaÃ§Ã£o de Dados")

            col1, col2, col3 = st.columns(3)

            # JSON
            with col1:
                st.subheader("ğŸ“„ JSON")

                st.download_button(
                    "ğŸ“¥ Artigos (JSON)",
                    json.dumps(articles, indent=2, ensure_ascii=False),
                    "articles.json",
                    "application/json",
                    use_container_width=True
                )

                st.download_button(
                    "ğŸ“¥ Conceitos (JSON)",
                    json.dumps(concepts_lists, indent=2, ensure_ascii=False),
                    "concepts.json",
                    "application/json",
                    use_container_width=True
                )

                cooc_json = [
                    {"conceito1": c1, "conceito2": c2, "frequencia": f}
                    for (c1, c2), f in pairs.items()
                ]

                st.download_button(
                    "ğŸ“¥ CoocorrÃªncias (JSON)",
                    json.dumps(cooc_json, indent=2, ensure_ascii=False),
                    "cooccurrences.json",
                    "application/json",
                    use_container_width=True
                )

            # CSV
            with col2:
                st.subheader("ğŸ“Š CSV")

                df_articles_export = pd.DataFrame([
                    {
                        'title': a.get('title', ''),
                        'year': a.get('year', ''),
                        'num_concepts': len(a.get('concepts', []))
                    }
                    for a in articles
                ])

                st.download_button(
                    "ğŸ“¥ Artigos (CSV)",
                    df_articles_export.to_csv(index=False),
                    "articles.csv",
                    "text/csv",
                    use_container_width=True
                )

                df_concepts = pd.DataFrame(
                    freq.most_common(),
                    columns=['concept', 'frequency']
                )

                st.download_button(
                    "ğŸ“¥ Conceitos (CSV)",
                    df_concepts.to_csv(index=False),
                    "concepts.csv",
                    "text/csv",
                    use_container_width=True
                )

                edges_list = [[u, v, d['weight']] for u, v, d in G.edges(data=True)]
                df_cooc = pd.DataFrame(edges_list, columns=['source', 'target', 'weight'])

                st.download_button(
                    "ğŸ“¥ CoocorrÃªncias (CSV)",
                    df_cooc.to_csv(index=False),
                    "cooccurrences.csv",
                    "text/csv",
                    use_container_width=True
                )

            # Outros formatos
            with col3:
                st.subheader("ğŸ”§ Outros")

                import tempfile

                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.graphml') as f:
                    nx.write_graphml(G, f.name)
                    with open(f.name, 'r') as file:
                        graphml_content = file.read()

                st.download_button(
                    "ğŸ“¥ Grafo (GraphML)",
                    graphml_content,
                    "graph.graphml",
                    "application/xml",
                    use_container_width=True
                )

                st.caption("Para Gephi/Cytoscape")

            st.divider()

            # Zip completo
            st.subheader("ğŸ“¦ Pacote Completo")

            if st.button("ğŸ Gerar ZIP com Todos os Dados", use_container_width=True):
                with st.spinner("ğŸ“¦ Gerando arquivo ZIP..."):
                    zip_buffer = BytesIO()

                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                        # JSON
                        zf.writestr('articles.json', json.dumps(articles, indent=2, ensure_ascii=False))
                        zf.writestr('concepts.json', json.dumps(concepts_lists, indent=2, ensure_ascii=False))
                        zf.writestr('cooccurrences.json', json.dumps(cooc_json, indent=2, ensure_ascii=False))

                        # CSV
                        zf.writestr('articles.csv', df_articles_export.to_csv(index=False))
                        zf.writestr('concepts.csv', df_concepts.to_csv(index=False))
                        zf.writestr('cooccurrences.csv', df_cooc.to_csv(index=False))

                        # GraphML
                        zf.writestr('graph.graphml', graphml_content)

                        # README
                        readme = f"""# DelinÃ©ia IX - Dados Exportados

Data: {datetime.now().strftime("%d/%m/%Y Ã s %H:%M")}
Query: {query}

## Arquivos incluÃ­dos:

### JSON
- articles.json: Lista completa de artigos
- concepts.json: Conceitos extraÃ­dos por artigo
- cooccurrences.json: Pares de coocorrÃªncias

### CSV
- articles.csv: Artigos (tÃ­tulo, ano, num_conceitos)
- concepts.csv: Conceitos e frequÃªncias
- cooccurrences.csv: Rede de coocorrÃªncias

### Grafo
- graph.graphml: Grafo no formato GraphML (Gephi/Cytoscape)

## EstatÃ­sticas:
- Artigos: {len(articles)}
- Conceitos Ãºnicos: {len(freq)}
- NÃ³s no grafo: {len(G.nodes())}
- Arestas: {len(G.edges())}
"""
                        zf.writestr('README.txt', readme)

                    st.download_button(
                        "ğŸ“¥ Baixar dashboard_completo.zip",
                        zip_buffer.getvalue(),
                        "dashboard_completo.zip",
                        "application/zip",
                        use_container_width=True
                    )
