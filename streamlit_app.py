# -*- coding: utf-8 -*-

import streamlit as st
from datetime import datetime
from research_pipeline import ResearchScopePipeline, OpenAlexClient, CooccurrenceAnalyzer, OPENALEX_EMAIL
from pdf_generator import generate_pdf_report
import pandas as pd
import networkx as nx
from collections import Counter
import plotly.express as px
import plotly.graph_objects as go
import json
import zipfile
from io import BytesIO
import numpy as np
from scipy import stats
import gspread
from google.oauth2.service_account import Credentials
import uuid
import time as time_module
import matplotlib.pyplot as plt

# ==================== GOOGLE SHEETS CONFIG ====================
GOOGLE_SHEETS_URL = "https://docs.google.com/spreadsheets/d/1BE2le2ZVm2ej20w7UF5T7RSjO-V_Ii0RuhZQ2vEQQLY/edit"
ABA_FORMULARIO_INICIAL = "formulario_inicial"
ABA_RESULTADOS_PIPELINE = "resultados_pipeline"
ABA_FORMULARIO_AVALIACAO = "formulario_avaliacao"

@st.cache_resource(show_spinner=False)
def conectar_google_sheets():
    """
    Conecta ao Google Sheets usando credenciais do Streamlit Secrets
    CORREÃ‡ÃƒO APLICADA: Tratamento da private_key para converter 
    \\n literal em quebras de linha reais.
    """
    SCOPES = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    
    try:
        # Ler credenciais DOS SECRETS
        google_creds = st.secrets["google_credentials"]
        
        # Converter para dict
        creds_dict = dict(google_creds)
        
        if "private_key" in creds_dict:
            # Primeiro tenta substituir \\n (escaped)
            pk = creds_dict["private_key"]
            if "\\n" in pk:
                pk = pk.replace("\\n", "\n")
            creds_dict["private_key"] = pk
        
        # Criar credenciais a partir do dict
        creds = Credentials.from_service_account_info(
            creds_dict,
            scopes=SCOPES
        )
        
        # Autorizar e abrir planilha
        client = gspread.authorize(creds)
        sheet = client.open_by_url(GOOGLE_SHEETS_URL)
        
        print("âœ… ConexÃ£o com Google Sheets estabelecida!")
        return sheet
        
    except Exception as e:
        st.error(f"âŒ Erro ao conectar Google Sheets: {e}")
        import traceback
        print(f"Detalhes do erro: {traceback.format_exc()}")
        return None

def enviar_formulario_inicial(form_data):
    """Envia dados do formulÃ¡rio inicial para Google Sheets"""
    try:
        sheet = conectar_google_sheets()
        
        if not sheet:
            return None
        
        worksheet = sheet.worksheet(ABA_FORMULARIO_INICIAL)
                
        # Gerar ID Ãºnico
        id_usuario = f"user_{uuid.uuid4().hex[:8]}"
        
        # Preparar linha
        row = [
            id_usuario,
            form_data['timestamp'],
            form_data['nome'],
            form_data['email'],
            form_data['tema'],
            form_data['questao'],
            form_data['palavras_chave'],
            form_data.get('google_academico', ''),
            form_data.get('confianca', '')
        ]
        
        worksheet.append_row(row, value_input_option='RAW')
        return id_usuario
        
    except Exception as e:
        st.error(f"âŒ Erro ao enviar formulÃ¡rio: {e}")
        return None

def enviar_resultados_pipeline(id_usuario, result, tempo_segundos):
    """Envia resultados do pipeline para Google Sheets"""
    try:
        sheet = conectar_google_sheets()
        if sheet is None:
            return False
        
        worksheet = sheet.worksheet(ABA_RESULTADOS_PIPELINE)
        
        # Preparar linha
        top_conceitos_str = ",".join(result.get('top_concepts', [])[:9])
        
        row = [
            id_usuario,
            datetime.now().strftime("%d/%m/%Y Ã s %H:%M"),
            result.get('search_string', ''),
            '',  # termos_sugeridos
            result.get('full_report', '')[:500],
            result.get('search_objective', ''),
            result.get('articles_count', 0),
            top_conceitos_str,
            result['graph_stats']['nodes'],
            result['graph_stats']['edges'],
            result['graph_stats'].get('density', 0),
            round(tempo_segundos, 2)
        ]
        
        worksheet.append_row(row, value_input_option='RAW')
        return True
        
    except Exception as e:
        st.error(f"âŒ Erro ao enviar resultados: {e}")
        return False

def enviar_formulario_avaliacao(id_usuario, avaliacao_data):
    """Envia avaliaÃ§Ã£o do usuÃ¡rio para Google Sheets"""
    try:
        sheet = conectar_google_sheets()
        if sheet is None:
            return False
        
        worksheet = sheet.worksheet(ABA_FORMULARIO_AVALIACAO)
        
        # Calcular tempo total
        tempo_total = 0
        if 'timestamp_formulario_inicial' in st.session_state:
            tempo_total = round(time_module.time() - st.session_state.timestamp_formulario_inicial, 2)
        
        # Preparar linha
        row = [
            id_usuario,
            datetime.now().strftime("%d/%m/%Y Ã s %H:%M"),
            avaliacao_data.get('q1', ''),
            avaliacao_data.get('q2', ''),
            avaliacao_data.get('q3', ''),
            avaliacao_data.get('q4', ''),
            avaliacao_data.get('q5', ''),
            avaliacao_data.get('q6', ''),
            avaliacao_data.get('q7', ''),
            avaliacao_data.get('q8', ''),
            avaliacao_data.get('q9', ''),
            avaliacao_data.get('q10', ''),
            avaliacao_data.get('q11', ''),
            avaliacao_data.get('q12', ''),
            avaliacao_data.get('q13', ''),
            avaliacao_data.get('q14', ''),
            avaliacao_data.get('q15', ''),
            avaliacao_data.get('q16', ''),
            avaliacao_data.get('q17', ''),
            avaliacao_data.get('q18', ''),
            avaliacao_data.get('q19', ''),
            avaliacao_data.get('q20', ''),
            avaliacao_data.get('nps', 0),
            avaliacao_data.get('nps_category', ''),
            avaliacao_data.get('q22', ''),
            avaliacao_data.get('q23', ''),
            avaliacao_data.get('q24', ''),
            avaliacao_data.get('q25', ''),
            avaliacao_data.get('q26', ''),
            avaliacao_data.get('q27', ''),
            avaliacao_data.get('q28', ''),
            avaliacao_data.get('q29', ''),
            avaliacao_data.get('q30', ''),
            'Sim' if avaliacao_data.get('aceite_continuidade', False) else 'NÃ£o',
            ",".join(st.session_state.get('badges', [])),
            tempo_total,
            st.session_state.get('play_video', False),
            st.session_state.get('open_prologo', False)
        ]
        
        worksheet.append_row(row, value_input_option='RAW')
        return True
        
    except Exception as e:
        st.error(f"âŒ Erro ao enviar avaliaÃ§Ã£o: {e}")
        return False

# ==================== FUNÃ‡ÃƒO DE ANÃLISE DE ZIPF =================
def analyze_zipf(frequency_data):
    """
    Analisa a distribuiÃ§Ã£o de frequÃªncias segundo a Lei de Zipf

    Args:
        frequency_data: Lista de tuplas (palavra, frequÃªncia) ordenada por frequÃªncia

    Returns:
        dict com mÃ©tricas e dados para plotagem
    """
    # Extrair frequÃªncias
    frequencies = [freq for _, freq in frequency_data]

    # Criar ranks (1, 2, 3, ...)
    ranks = np.arange(1, len(frequencies) + 1)

    # Converter para arrays numpy
    ranks_array = np.array(ranks)
    freq_array = np.array(frequencies)

    # Aplicar log para anÃ¡lise linear
    log_ranks = np.log10(ranks_array)
    log_freqs = np.log10(freq_array)

    # RegressÃ£o linear no espaÃ§o log-log
    slope, intercept, r_value, p_value, std_err = stats.linregress(log_ranks, log_freqs)

    # Calcular RÂ²
    r_squared = r_value ** 2

    # Gerar linha de tendÃªncia
    trend_line = 10 ** (slope * log_ranks + intercept)

    # InterpretaÃ§Ã£o
    if r_squared > 0.90:
        interpretation = "âœ… Forte aderÃªncia Ã  Lei de Zipf"
        quality = "excelente"
    elif r_squared > 0.75:
        interpretation = "âš ï¸ AderÃªncia moderada Ã  Lei de Zipf"
        quality = "boa"
    else:
        interpretation = "âŒ Fraca aderÃªncia Ã  Lei de Zipf"
        quality = "baixa"

    # AnÃ¡lise da inclinaÃ§Ã£o
    if -1.2 < slope < -0.8:
        slope_interpretation = "prÃ³ximo ao ideal (-1.0)"
    elif slope < -1.2:
        slope_interpretation = "vocabulÃ¡rio mais concentrado que o esperado"
    else:
        slope_interpretation = "vocabulÃ¡rio mais disperso que o esperado"

    return {
        'ranks': ranks_array,
        'frequencies': freq_array,
        'log_ranks': log_ranks,
        'log_freqs': log_freqs,
        'trend_line': trend_line,
        'slope': slope,
        'intercept': intercept,
        'r_squared': r_squared,
        'p_value': p_value,
        'interpretation': interpretation,
        'quality': quality,
        'slope_interpretation': slope_interpretation
    }

# ==================== CONFIGURAÃ‡ÃƒO DA PÃGINA ====================
st.set_page_config(
    page_title="DelinÃ©ia",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== CSS CUSTOMIZADO (BOTÃ•ES VERDES) ====================
st.markdown("""
<style>
    /* BotÃµes primÃ¡rios em verde claro */
    .stButton > button[kind="primary"] {
        background-color: #10b981 !important;
        color: white !important;
        border: none !important;
    }
    
    .stButton > button[kind="primary"]:hover {
        background-color: #059669 !important;
        color: white !important;
    }
    
    .stButton > button[kind="primary"]:active {
        background-color: #047857 !important;
    }
    
    /* Form submit buttons */
    .stFormSubmitButton > button {
        background-color: #10b981 !important;
        color: white !important;
        border: none !important;
    }
    
    .stFormSubmitButton > button:hover {
        background-color: #059669 !important;
    }
    
    /* Download buttons com type="primary" */
    .stDownloadButton > button[kind="primary"] {
        background-color: #10b981 !important;
        color: white !important;
    }
</style>
""", unsafe_allow_html=True)

# ==================== ESTADOS DA SESSÃƒO ====================
if 'step' not in st.session_state:
    st.session_state.step = 1
if 'resultado' not in st.session_state:
    st.session_state.resultado = None
if 'form_data' not in st.session_state:
    st.session_state.form_data = {}
if 'dashboard_data' not in st.session_state:
    st.session_state.dashboard_data = None
if 'dashboard_query' not in st.session_state:
    st.session_state.dashboard_query = ""
if 'avaliacao_completa' not in st.session_state:
    st.session_state.avaliacao_completa = False
if 'badges' not in st.session_state:
    st.session_state.badges = []
if 'play_video' not in st.session_state:
    st.session_state.play_video = False
if 'open_prologo' not in st.session_state:
    st.session_state.open_prologo = False
if 'selected_concepts' not in st.session_state:
    st.session_state.selected_concepts = []
if 'interpretation_generated' not in st.session_state:
    st.session_state.interpretation_generated = False
if 'personalized_interpretation' not in st.session_state:
    st.session_state.personalized_interpretation = None
if 'suggested_keywords' not in st.session_state:
    st.session_state.suggested_keywords = []
if 'suggested_strings' not in st.session_state:
    st.session_state.suggested_strings = {}
if 'sub_step' not in st.session_state:
    st.session_state.sub_step = 'a'  # 'a', 'b', 'c'

# ==================== FUNÃ‡Ã•ES AUXILIARES ====================
def add_badge(badge_name: str) -> bool:
    """Adiciona badge ao perfil do usuÃ¡rio"""
    if badge_name not in st.session_state.badges:
        st.session_state.badges.append(badge_name)
        return True
    return False

# ==================== ABAS PRINCIPAIS ====================
tab1, tab2 = st.tabs(["ğŸ“š DelineascÃ³pio", "ğŸ“Š Painel"])

# ==================== ABA 1: DELINEASCÃ“PIO ====================
with tab1:
    st.title("ğŸ“š DelinÃ©ia - Delineamento de Escopo TemÃ¡tico")
    st.caption("Sistema de apoio ao delineamento de projetos de pesquisa com IA e Bibliometria")

    # Barra de progresso gamificada (5 etapas)
    sub_step = st.session_state.get('sub_step', 'a')
    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        if st.session_state.step >= 1:
            st.success("âœ… 1. FormulÃ¡rio inicial")
            if 'ğŸ¯ Explorador' not in st.session_state.badges:
                add_badge('ğŸ¯ Explorador')
        else:
            st.info("â³ 1. FormulÃ¡rio inicial")

    with col2:
        if st.session_state.step >= 2:
            st.success("âœ… 2. Grafo de conceitos")
            if 'ğŸ”¬ Pesquisador' not in st.session_state.badges:
                add_badge('ğŸ”¬ Pesquisador')
        else:
            st.info("â³ 2. Grafo de conceitos")

    with col3:
        if st.session_state.step >= 2 and sub_step in ['b', 'c']:
            st.success("âœ… 3. SeleÃ§Ã£o de conceitos")
            if 'ğŸ§© Seletor' not in st.session_state.badges:
                add_badge('ğŸ§© Seletor')
        elif st.session_state.step == 2 and sub_step == 'a':
            st.info("â³ 3. SeleÃ§Ã£o de conceitos")
        else:
            st.info("â³ 3. SeleÃ§Ã£o de conceitos")

    with col4:
        if st.session_state.step >= 2 and sub_step == 'c':
            st.success("âœ… 4. RelatÃ³rio")
            if 'ğŸ† Delineador' not in st.session_state.badges:
                add_badge('ğŸ† Delineador')
        elif st.session_state.step > 2:
            st.success("âœ… 4. RelatÃ³rio")
            if 'ğŸ† Delineador' not in st.session_state.badges:
                add_badge('ğŸ† Delineador')
        else:
            st.info("â³ 4. RelatÃ³rio")

    with col5:
        if st.session_state.get('avaliacao_completa', False):
            st.success("âœ… 5. AvaliaÃ§Ã£o")
            if 'ğŸ’ Avaliador' not in st.session_state.badges:
                add_badge('ğŸ’ Avaliador')
        elif st.session_state.step >= 3:
            st.warning("ğŸ”„ 5. AvaliaÃ§Ã£o")
        else:
            st.info("â³ 5. AvaliaÃ§Ã£o")

    # Mostrar badges conquistados
    if st.session_state.badges:
        st.markdown(f"**ğŸ… Conquistas:** {' '.join(st.session_state.badges)}")

    st.divider()

    # ========== ETAPA 1: FORMULÃRIO INICIAL ==========
    if st.session_state.step == 1:
        st.header("ğŸ“ 1. FormulÃ¡rio Inicial")

        with st.form("formulario_inicial"):
            st.subheader("ğŸ‘¤ IdentificaÃ§Ã£o")
            col1, col2 = st.columns(2)

            with col1:
                nome = st.text_input(
                    "Nome completo*",
                    placeholder="Ex: Ana Silva",
                    help="Seu nome completo"
                )

            with col2:
                email = st.text_input(
                    "E-mail*",
                    placeholder="Ex: ana@email.com",
                    help="Seu e-mail para contato"
                )

            st.divider()
            st.subheader("ğŸ”¬ Projeto de Pesquisa")

            tema = st.text_input(
                "F1.1. Tema da Pesquisa*",
                placeholder="Ex: Jogos como estratÃ©gia de ensino e aprendizagem na escola",
                help="Tema principal do seu projeto"
            )

            questao = st.text_area(
                "F1.2. QuestÃ£o de Pesquisa*",
                placeholder="Ex: Qual a percepÃ§Ã£o dos professores sobre a eficÃ¡cia dos jogos como estratÃ©gia de ensino e aprendizagem na escola?",
                height=100,
                help="Pergunta principal que vocÃª quer responder"
            )

            palavras_chave = st.text_input(
                "F1.3. Palavras-chave* (separadas entre vÃ­rgulas)",
                placeholder="Ex: Jogos, Ensino, Aprendizagem, PercepÃ§Ã£o dos professores",
                help="Separe as palavras-chave por vÃ­rgula"
            )

            google_academico = st.text_area(
                "F1.4. Se vocÃª fosse pesquisar referÃªncias para seu projeto no Google AcadÃªmico, o que vocÃª colocaria no campo de busca?*",
                placeholder="Ex: Uso de jogos na escola",
                help="Campo livre para indicar palavras, frases, etc. que vocÃª quer pesquisar",
                height=100
            )

            st.divider()
            st.subheader("ğŸ’­ AutoavaliaÃ§Ã£o")

            confianca = st.radio(
                "F1.5. Qual seu nÃ­vel de seguranÃ§a em relaÃ§Ã£o Ã s palavras-chave escolhidas?",
                options=[
                    "Totalmente seguro",
                    "Seguro",
                    "Neutro",
                    "Inseguro",
                    "Totalmente inseguro"
                ],
                index=2,  # Neutro como padrÃ£o
                horizontal=True,
                help="Selecione seu nÃ­vel de confianÃ§a nas palavras-chave escolhidas"
            )
       
            st.divider()

            submitted = st.form_submit_button(
                "ğŸš€ Gerar RelatÃ³rio de Delineamento",
                type="primary",
                use_container_width=True
            )

            if submitted:
                if not all([nome, email, tema, questao, palavras_chave]):
                    st.error("âš ï¸ Por favor, preencha todos os campos obrigatÃ³rios (*)")
                else:
                    # Salvar dados do formulÃ¡rio
                    st.session_state.form_data = {
                        'nome': nome,
                        'email': email,
                        'tema': tema,
                        'questao': questao,
                        'palavras_chave': palavras_chave,
                        'confianca': confianca,
                        'google_academico': google_academico,
                        'timestamp': datetime.now().strftime("%d/%m/%Y Ã s %H:%M")
                    }

                    # Enviar para Google Sheets e salvar ID
                    id_usuario = enviar_formulario_inicial(st.session_state.form_data)
                    if id_usuario:
                        st.session_state.id_usuario = id_usuario
                        st.session_state.timestamp_formulario_inicial = time_module.time()

                    with st.spinner("ğŸ”„ Processando... (aguarde 2-3 minutos)"):
                        try:
                            # Inicializar pipeline
                            pipe = ResearchScopePipeline(OPENALEX_EMAIL)

                            # Processar palavras-chave
                            kws = [k.strip() for k in palavras_chave.split(',') if k.strip()]

                            # Executar pipeline
                            tempo_inicio = time_module.time()
                            st.session_state.resultado = pipe.process(nome, tema, questao, kws)
                            tempo_fim = time_module.time()

                            # Enviar resultados para Google Sheets
                            if 'id_usuario' in st.session_state:
                                enviar_resultados_pipeline(
                                    st.session_state.id_usuario,
                                    st.session_state.resultado,
                                    tempo_fim - tempo_inicio
                                )

                            # AvanÃ§ar para prÃ³xima etapa
                            st.session_state.step = 2
                            st.rerun()

                        except Exception as e:
                            st.error(f"âŒ Erro ao processar: {str(e)}")
                            st.exception(e)

    # ========== ETAPA 2: TRILHA DE APRENDIZAGEM ATIVA ==========
    elif st.session_state.step == 2:
        d = st.session_state.form_data
        r = st.session_state.resultado
        sub_step = st.session_state.get('sub_step', 'a')

        # ========== SUB-ETAPA 2a: VISUALIZAÃ‡ÃƒO DO GRAFO ==========
        if sub_step == 'a':
            st.header("ğŸ•¸ï¸ 2. Grafo de conceitos")
            st.caption("Etapa 2: Explore o grafo e o glossÃ¡rio antes de selecionar os conceitos")

            # BotÃ£o voltar
            if st.button("â¬…ï¸ Voltar ao FormulÃ¡rio"):
                st.session_state.step = 1
                st.rerun()

            st.divider()

            # InformaÃ§Ãµes do projeto (resumido)
            with st.expander("ğŸ“‹ Dados do Projeto", expanded=False):
                st.write(f"**Tema:** {d['tema']}")
                st.write(f"**QuestÃ£o:** {d['questao']}")
                st.write(f"**Palavras-chave:** {d['palavras_chave']}")

            # MÃ©tricas
            col1, col2, col3 = st.columns(3)
            col1.metric("ğŸ“š Artigos Analisados", r.get('articles_count', 0))
            col2.metric("ğŸ§© Conceitos no Grafo", r['graph_stats']['nodes'])
            col3.metric("ğŸ”— ConexÃµes", r['graph_stats']['edges'])

            # Layout: Grafo e GlossÃ¡rio lado a lado
            col_grafo, col_glossario = st.columns([1, 1])

            with col_grafo:
                st.subheader("ğŸ•¸ï¸ Grafo de CoocorrÃªncias")
                if r.get('visualization_path'):
                    st.image(r['visualization_path'], use_container_width=True)
                else:
                    st.warning("âš ï¸ VisualizaÃ§Ã£o nÃ£o disponÃ­vel")

            with col_glossario:
                st.subheader("ğŸ“– GlossÃ¡rio de Conceitos")
                with st.container(height=400):
                    st.markdown(r.get('glossary', 'âš ï¸ GlossÃ¡rio nÃ£o disponÃ­vel'))

            # InstruÃ§Ã£o para prÃ³xima etapa
            st.divider()
            st.info("""
            ğŸ’¡ **PrÃ³ximo passo:** Observe atentamente o grafo e o glossÃ¡rio acima. 
            Na prÃ³xima etapa, vocÃª selecionarÃ¡ os conceitos mais relevantes para sua pesquisa.
            Essa seleÃ§Ã£o serÃ¡ usada para gerar uma interpretaÃ§Ã£o personalizada do grafo.
            """)

            # BotÃ£o avanÃ§ar
            if st.button("Continuar para SeleÃ§Ã£o de Conceitos â–¶ï¸", type="primary", use_container_width=True):
                st.session_state.sub_step = 'b'
                st.rerun()

        # ========== SUB-ETAPA 2b: SELEÃ‡ÃƒO DE CONCEITOS ==========
        elif sub_step == 'b':
            top_concepts = r.get('top_concepts', [])[:9]

            st.header("ğŸ¯ 3. SeleÃ§Ã£o de Conceitos")
            st.caption("Etapa 3: Escolha os conceitos mais relevantes para sua pesquisa")

            # NavegaÃ§Ã£o
            if st.button("â¬…ï¸ Voltar ao Grafo"):
                st.session_state.sub_step = 'a'
                st.rerun()

            st.divider()

            # Contexto
            primeiro_nome = d['nome'].split()[0]
            st.markdown(f"""
            ### {primeiro_nome}, quais conceitos do grafo sÃ£o mais relevantes para seu projeto?

            Considerando seu tema **"{d['tema']}"**, selecione os conceitos que vocÃª considera 
            mais importantes para o delineamento do escopo da sua pesquisa.

            *Selecione pelo menos 1 conceito para continuar.*
            """)

            # Mostrar grafo como referÃªncia (menor)
            with st.expander("ğŸ•¸ï¸ Ver grafo novamente", expanded=False):
                if r.get('visualization_path'):
                    st.image(r['visualization_path'], use_container_width=True)

            st.divider()

            # SeleÃ§Ã£o de conceitos com checkboxes
            st.subheader("ğŸ“‹ Conceitos Identificados na Rede")

            # Criar 3 colunas para os checkboxes
            cols = st.columns(3)
            selected = []

            for i, concept in enumerate(top_concepts):
                col_idx = i % 3
                with cols[col_idx]:
                    # Verificar se jÃ¡ estava selecionado antes
                    default_value = concept in st.session_state.get('selected_concepts', [])
                    if st.checkbox(concept, value=default_value, key=f"concept_{i}"):
                        selected.append(concept)

            # Atualizar session_state
            st.session_state.selected_concepts = selected

            # Contador
            st.divider()
            num_selected = len(selected)

            if num_selected == 0:
                st.warning("âš ï¸ Selecione pelo menos 1 conceito para continuar")
            else:
                st.success(f"âœ… **{num_selected} conceito(s) selecionado(s):** {', '.join(selected)}")

            # BotÃ£o avanÃ§ar (sÃ³ habilitado se tiver seleÃ§Ã£o)
            st.divider()

            col1, col2 = st.columns(2)

            with col2:
                if num_selected >= 1:
                    if st.button("Gerar RelatÃ³rio de Delineamento â–¶ï¸", type="primary", use_container_width=True):
                        with st.spinner("ğŸ”„ Gerando relatÃ³rio... (aguarde 1-2 minutos)"):
                            # Gerar conteÃºdo personalizado
                            from research_pipeline import GeminiQueryGenerator
                            gemini = GeminiQueryGenerator()

                            primeiro_nome = d['nome'].split()[0]
                            tema = d['tema']
                            original_kws = [k.strip() for k in d.get('palavras_chave', '').split(',') if k.strip()]
                            all_concepts = r.get('top_concepts', [])[:9]

                            # Gerar interpretaÃ§Ã£o contextualizada
                            st.session_state.personalized_interpretation = gemini.generate_contextualized_interpretation(
                                tema, primeiro_nome, selected, all_concepts
                            )

                            # Gerar sugestÃµes de palavras-chave
                            st.session_state.suggested_keywords = gemini.generate_keyword_suggestions(
                                tema, primeiro_nome, selected, original_kws
                            )

                            # Gerar strings de busca
                            st.session_state.suggested_strings = gemini.generate_search_strings(
                                tema, selected, original_kws
                            )

                            st.session_state.interpretation_generated = True

                        st.session_state.sub_step = 'c'
                        st.rerun()
                else:
                    st.button("Gerar InterpretaÃ§Ã£o Personalizada â–¶ï¸", disabled=True, use_container_width=True)

        # ========== SUB-ETAPA 2c: INTERPRETAÃ‡ÃƒO PERSONALIZADA ==========
        elif sub_step == 'c':
            selected = st.session_state.get('selected_concepts', [])

            st.header("ğŸ“‹ 4. RelatÃ³rio")
            st.caption("Etapa 4: InterpretaÃ§Ã£o baseada nos conceitos que vocÃª selecionou")

            # NavegaÃ§Ã£o
            col_nav1, col_nav2 = st.columns([1, 3])
            with col_nav1:
                if st.button("â¬…ï¸ Voltar Ã  SeleÃ§Ã£o"):
                    st.session_state.sub_step = 'b'
                    st.rerun()

            st.divider()

            # Resumo da seleÃ§Ã£o
            st.success(f"âœ… **Conceitos selecionados:** {', '.join(selected)}")

            # InformaÃ§Ãµes do projeto
            with st.container(border=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**ğŸ‘¤ Aluno:** {d['nome']}")
                    st.write(f"**ğŸ“§ E-mail:** {d['email']}")
                with col2:
                    st.write(f"**ğŸ“… Data:** {d['timestamp']}")
                    st.write(f"**ğŸ’­ ConfianÃ§a:** {d['confianca']}")

            with st.container(border=True):
                st.write(f"**ğŸ¯ Tema:** {d['tema']}")
                st.write(f"**â“ QuestÃ£o:** {d['questao']}")
                st.write(f"**ğŸ”‘ Palavras-chave:** {d['palavras_chave']}")

            # ========== SEÃ‡ÃƒO 1: AVALIAÃ‡ÃƒO INICIAL DO PROJETO ==========
            st.subheader("ğŸ“‹ AvaliaÃ§Ã£o do Projeto")
            with st.container(border=True):
                st.markdown(r.get('full_report', 'âš ï¸ AvaliaÃ§Ã£o nÃ£o disponÃ­vel'))

            # ========== SEÃ‡ÃƒO 2: INTERPRETAÃ‡ÃƒO PERSONALIZADA ==========
            st.subheader("ğŸ’¡ InterpretaÃ§Ã£o Personalizada do Grafo")
            with st.container(border=True):
                interpretation = st.session_state.get('personalized_interpretation', '')
                if interpretation:
                    st.markdown(interpretation)
                else:
                    st.markdown(r.get('graph_interpretation', 'âš ï¸ InterpretaÃ§Ã£o nÃ£o disponÃ­vel'))

            # ========== SEÃ‡ÃƒO 3: GRAFO ==========
            st.subheader("ğŸ•¸ï¸ Grafo de CoocorrÃªncias")
            if r.get('visualization_path'):
                st.image(r['visualization_path'], use_container_width=True)

            # ========== SEÃ‡ÃƒO 4: GLOSSÃRIO ==========
            st.subheader("ğŸ“– GlossÃ¡rio de Conceitos")
            with st.expander("Ver glossÃ¡rio completo", expanded=False):
                st.markdown(r.get('glossary', 'âš ï¸ GlossÃ¡rio nÃ£o disponÃ­vel'))

            # ========== SEÃ‡ÃƒO 5: SUGESTÃ•ES DE PALAVRAS-CHAVE ==========
            st.subheader("ğŸ”‘ SugestÃµes de Palavras-chave")

            suggested_kws = st.session_state.get('suggested_keywords', [])

            if suggested_kws:
                for kw in suggested_kws:
                    with st.container(border=True):
                        col1, col2 = st.columns([1, 3])
                        with col1:
                            st.markdown(f"**{kw.get('term_en', 'N/A')}**")
                            st.caption(f"({kw.get('term_pt', 'N/A')})")
                        with col2:
                            st.write(kw.get('description', ''))
            else:
                st.info("SugestÃµes de palavras-chave nÃ£o disponÃ­veis")

            # ========== SEÃ‡ÃƒO 6: STRINGS DE BUSCA SUGERIDAS ==========
            st.subheader("ğŸ” Strings de Busca Sugeridas")
            st.caption("Copie as strings abaixo para usar no Painel ou em bases de dados")

            suggested_strings = st.session_state.get('suggested_strings', {})

            if suggested_strings:
                for key, data in suggested_strings.items():
                    with st.container(border=True):
                        st.markdown(f"**{data.get('titulo', key)}**")
                        st.caption(data.get('descricao', ''))

                        col_str, col_btn = st.columns([4, 1])

                        with col_str:
                            st.code(data.get('string', ''), language='text')

                        with col_btn:
                            if st.button("ğŸ“‹ Copiar", key=f"copy_{key}", use_container_width=True):
                                st.session_state.dashboard_query = data.get('string', '')
                                st.toast(f"âœ… String copiada para o Painel!")
            else:
                # Fallback: mostrar string original
                search_string = r.get('search_string', 'N/A')
                with st.container(border=True):
                    st.markdown("**ğŸ” String de Busca Original**")
                    col_str, col_btn = st.columns([4, 1])
                    with col_str:
                        st.code(search_string, language='text')
                    with col_btn:
                        if st.button("ğŸ“‹ Copiar", key="copy_original", use_container_width=True):
                            st.session_state.dashboard_query = search_string
                            st.toast("âœ… String copiada para o Painel!")

            # ========== SEÃ‡ÃƒO 7: AÃ‡Ã•ES FINAIS ==========
            st.divider()

            col1, col2, col3 = st.columns(3)

            with col1:
                # PDF disponÃ­vel apÃ³s completar a trilha
                try:
                    # Adicionar dados da seleÃ§Ã£o ao resultado para o PDF
                    r_completo = r.copy()
                    r_completo['selected_concepts'] = selected
                    r_completo['personalized_interpretation'] = st.session_state.get('personalized_interpretation', '')
                    r_completo['suggested_keywords'] = st.session_state.get('suggested_keywords', [])
                    r_completo['suggested_strings'] = st.session_state.get('suggested_strings', {})

                    pdf_bytes = generate_pdf_report(d, r_completo)
                    st.download_button(
                        "ğŸ“¥ Baixar PDF Completo",
                        pdf_bytes,
                        f"delineamento_{d['nome'].replace(' ', '_')}.pdf",
                        "application/pdf",
                        use_container_width=True,
                        type="primary"
                    )
                except Exception as e:
                    st.error(f"Erro ao gerar PDF: {str(e)}")

            with col2:
                if st.button("ğŸ“Š Ir ao Painel", use_container_width=True):
                    st.info("ğŸ’¡ Use as strings sugeridas no Painel para explorar mais a literatura!")

            with col3:
                if st.button("ğŸ“ Avaliar Sistema", type="primary", use_container_width=True):
                    st.session_state.step = 3
                    st.rerun()

            # Dica final
            st.divider()
            st.info("""
            ğŸ‰ **ParabÃ©ns!** VocÃª completou a trilha de delineamento!

            Agora vocÃª pode:
            - ğŸ“¥ **Baixar o PDF** com o relatÃ³rio completo
            - ğŸ“Š **Usar o Painel** para explorar mais a literatura
            - ğŸ“ **Avaliar o sistema** e nos ajudar a melhorar
            """)

            # BotÃ£o novo projeto
            if st.button("ğŸ”„ Iniciar Novo Projeto", use_container_width=True):
                st.session_state.step = 1
                st.session_state.resultado = None
                st.session_state.form_data = {}
                st.session_state.avaliacao_completa = False
                st.session_state.badges = []
                st.session_state.sub_step = 'a'
                st.session_state.selected_concepts = []
                st.session_state.interpretation_generated = False
                st.session_state.personalized_interpretation = None
                st.session_state.suggested_keywords = []
                st.session_state.suggested_strings = {}
                st.rerun()

# ========== ETAPA 3: AVALIAÃ‡ÃƒO EXPANDIDA ==========
    elif st.session_state.step == 3:
        st.header("â­ 5. AvaliaÃ§Ã£o")
        st.caption("Suas respostas sÃ£o fundamentais para aprimorarmos o sistema!")

        st.info("""
ğŸ“Š **Termo de Consentimento Livre e Esclarecido**
 
Convidamos vocÃª a participar da pesquisa sobre o uso de palavras-chave na pesquisa acadÃªmica. Sua participaÃ§Ã£o Ã© totalmente voluntÃ¡ria, e vocÃª pode desistir a qualquer momento sem nenhum prejuÃ­zo.

O objetivo do estudo Ã© investigar como a avaliaÃ§Ã£o automatizada de definiÃ§Ãµes preliminares de um projeto, como tema, questÃ£o de pesquisa e palavras-chave, pode apoiar estudantes no delineamento do escopo do estudo e na delimitaÃ§Ã£o mais precisa de suas propostas.

Ressaltamos que nenhuma informaÃ§Ã£o identificÃ¡vel Ã© utilizada na pesquisa.

Caso tenha dÃºvidas ou necessite de mais informaÃ§Ãµes, entre em contato por e-mail com o pesquisador responsÃ¡vel, Rafael Antunes dos Santos (rafael.antunes@ufrgs.br), doutorando do Programa de PÃ³s-GraduaÃ§Ã£o em InformÃ¡tica na EducaÃ§Ã£o, da Universidade Federal do Rio Grande do Sul.
                
Ao prosseguir com o preenchimento deste formulÃ¡rio, vocÃª declara que entende os objetivos da pesquisa e concorda em participar voluntariamente.
""")

        with st.form("formulario_avaliacao"):

            # ==================== SEÃ‡ÃƒO 1: UTILIDADE PERCEBIDA ====================
            st.subheader("ğŸ’¼ Utilidade Percebida")

            q1 = st.radio(
                "F2.1. Usar o DelinÃ©ia melhora a minha capacidade de escolha de palavras-chave para o escopo da pesquisa",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q1"
            )

            q2 = st.radio(
                "F2.2. Usar o DelinÃ©ia aumenta minha produtividade na definiÃ§Ã£o do projeto",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q2"
            )

            q3 = st.radio(
                "F2.3. O DelinÃ©ia Ã© Ãºtil para delimitar meu projeto de pesquisa",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q3"
            )

            q4 = st.radio(
                "F2.4. O DelinÃ©ia me ajuda a posicionar meu projeto na literatura do meu tema",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q4"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 2: FACILIDADE DE USO ====================
            st.subheader("ğŸ¯ Facilidade de Uso Percebida")

            q5 = st.radio(
                "F2.5. O DelinÃ©ia Ã© fÃ¡cil de usar",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q5"
            )

            q6 = st.radio(
                "F2.6. A interaÃ§Ã£o com o DelinÃ©ia Ã© clara e compreensÃ­vel",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q6"
            )

            q7 = st.radio(
                "F2.7. A navegaÃ§Ã£o entre as diferentes funcionalidades Ã© intuitiva",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q7"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 3: QUALIDADE DA INFORMAÃ‡ÃƒO ====================
            st.subheader("ğŸ“Š Qualidade da InformaÃ§Ã£o")

            q8 = st.radio(
                "F2.8. As anÃ¡lises e sugestÃµes do DelinÃ©ia sÃ£o relevantes para meu projeto",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q8"
            )

            q9 = st.radio(
                "F2.9. A avaliaÃ§Ã£o gerada pela IA Ã© construtiva para meu projeto",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q9"
            )

            q10 = st.radio(
                "F2.10. A string oferecida Ã© precisa para o meu tema",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q10"
            )

            q11 = st.radio(
                "F2.11. O grafo de coocorrÃªncias me ajudou a visualizar relaÃ§Ãµes entre conceitos",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q11"
            )

            q12 = st.radio(
                "F2.12. O DelinÃ©ia me ajudou a formular perguntas de pesquisa mais precisas",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q12"
            )

            q13 = st.radio(
                "F2.13. O relatÃ³rio em PDF Ã© adequado para apresentar ao meu orientador",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q13"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 4: INTENÃ‡ÃƒO DE USO ====================
            st.subheader("ğŸ”® IntenÃ§Ã£o de Uso")

            q14 = st.radio(
                "F2.14. O tempo gasto usando o DelinÃ©ia compensa os resultados obtidos",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q14"
            )

            q15 = st.radio(
                "F2.15. Eu pretendo usar o DelinÃ©ia em projetos futuros",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q15"
            )

            q16 = st.radio(
                "F2.16. Eu usaria o DelinÃ©ia em diferentes fases da minha pesquisa (projeto, qualificaÃ§Ã£o, defesa)",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q16"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 5: CONFIANÃ‡A NO SISTEMA ====================
            st.subheader("ğŸ”’ ConfianÃ§a no Sistema")

            q17 = st.radio(
                "F2.17. Eu confio nas anÃ¡lises geradas pelo DelinÃ©ia",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q17"
            )

            q18 = st.radio(
                "F2.18. Eu me sinto confortÃ¡vel em basear decisÃµes acadÃªmicas com os resultados do DelinÃ©ia",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q18"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 6: EXPERIÃŠNCIA DO USUÃRIO ====================
            st.subheader("âœ¨ ExperiÃªncia do UsuÃ¡rio")

            q19 = st.radio(
                "F2.19. O design da interface Ã© agradÃ¡vel",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q19"
            )

            q20 = st.radio(
                "F2.20. O tempo de processamento do relatÃ³rio foi adequado",
                ["Concordo Totalmente", "Concordo", "Neutro", "Discordo", "Discordo Totalmente"],
                horizontal=True,
                key="q20"
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 7: NET PROMOTER SCORE ====================
            st.subheader("â­ SatisfaÃ§Ã£o Geral (Net Promoter Score)")

            nps = st.slider(
                "F2.21. Em uma escala de 0 a 10, quanto vocÃª recomendaria o DelinÃ©ia para um colega?",
                min_value=0,
                max_value=10,
                value=5,
                help="0 = Definitivamente nÃ£o recomendaria | 10 = Definitivamente recomendaria"
            )

            # Mostrar categoria NPS em tempo real
            if nps >= 9:
                st.success("ğŸŒŸ **Promotor** - Obrigado pelo entusiasmo!")
            elif nps >= 7:
                st.info("ğŸ˜ **Neutro** - O que podemos melhorar?")
            else:
                st.warning("ğŸ˜ **Desanimado** - Queremos ouvir suas sugestÃµes!")

            st.divider()

            # ==================== SEÃ‡ÃƒO 8: COMENTÃRIOS ADICIONAIS ====================
            st.subheader("ğŸ’¬ ComentÃ¡rios Adicionais")

            q22 = st.text_area(
                "F2.22. O que vocÃª mais gostou no DelinÃ©ia?",
                height=100,
                key="q22",
                placeholder="Descreva os aspectos mais positivos da sua experiÃªncia..."
            )

            q23 = st.text_area(
                "F2.23. O que poderia ser melhorado?",
                height=100,
                key="q23",
                placeholder="SugestÃµes de melhorias, funcionalidades ausentes, problemas encontrados..."
            )

            q24 = st.text_area(
                "F2.24. Funcionalidades que vocÃª gostaria de ver no futuro:",
                height=100,
                key="q24",
                placeholder="Ideias para prÃ³ximas versÃµes..."
            )

            q25 = st.text_area(
                "F2.25. Como vocÃª usou (ou pretende usar) os resultados do DelinÃ©ia na sua pesquisa?",
                height=100,
                key="q25",
                placeholder="Ex: projeto de qualificaÃ§Ã£o, artigo, revisÃ£o de literatura..."
            )

            st.divider()

            # ==================== SEÃ‡ÃƒO 9: AUTOAVALIAÃ‡ÃƒO ====================
            st.subheader("ğŸ”„ AutoavaliaÃ§Ã£o")

            st.markdown("""
            **ReflexÃ£o sobre seu processo:**  
            No formulÃ¡rio inicial (F1.5), vocÃª indicou seu nÃ­vel de seguranÃ§a em relaÃ§Ã£o Ã s palavras-chave escolhidas.  
            Agora, apÃ³s ter lido o relatÃ³rio e as anÃ¡lises do DelinÃ©ia, como vocÃª avalia sua escolha inicial?
            """)

            q26 = st.radio(
                "F2.26. Considerando as palavras-chave escolhidas inicialmente e a leitura do relatÃ³rio, qual seu nÃ­vel de seguranÃ§a em relaÃ§Ã£o Ã s palavras-chave que vocÃª definiu para a pesquisa bibliogrÃ¡fica do seu projeto?",
                ["Totalmente seguro", "Seguro", "Neutro", "Inseguro", "Totalmente inseguro"],
                horizontal=True,
                key="q26"
            )

            # Mostrar comparaÃ§Ã£o se disponÃ­vel
            if 'form_data' in st.session_state and 'confianca' in st.session_state.form_data:
                confianca_inicial = st.session_state.form_data['confianca']
                st.info(f"ğŸ’¡ **Sua resposta inicial (F1.5):** {confianca_inicial}")

            st.divider()

            # ==================== SEÃ‡ÃƒO 10: PERFIL DO RESPONDENTE ====================
            st.subheader("ğŸ‘¤ Perfil do Respondente (Opcional)")

            col1, col2 = st.columns(2)

            with col1:
                q27 = st.selectbox(
                    "F2.27. NÃ­vel acadÃªmico:",
                    ["Prefiro nÃ£o informar", "GraduaÃ§Ã£o", "EspecializaÃ§Ã£o", "Mestrado",
                     "Doutorado", "PÃ³s-Doutorado", "Docente"],
                    key="q27"
                )

                q28 = st.selectbox(
                    "F2.28. ExperiÃªncia prÃ©via com bibliometria:",
                    ["Nenhuma", "BÃ¡sica", "IntermediÃ¡ria", "AvanÃ§ada"],
                    key="q28"
                )

            with col2:
                q29 = st.selectbox(
                    "F2.29. Ãrea do conhecimento:",
                    ["Prefiro nÃ£o informar", "CiÃªncias Exatas", "CiÃªncias BiolÃ³gicas", "CiÃªncias da SaÃºde",
                     "CiÃªncias AgrÃ¡rias", "CiÃªncias Sociais Aplicadas", "CiÃªncias Humanas",
                     "LinguÃ­stica/Letras/Artes", "Engenharias", "Multidisciplinar"],
                    key="q29"
                )

                q30 = st.selectbox(
                    "F2.30. Tempo gasto usando o DelinÃ©ia hoje:",
                    ["< 15 min", "15-30 min", "30-60 min", "> 1 hora"],
                    key="q30"
                )

            st.divider()

            # ==================== SEÃ‡ÃƒO 11: CONVITE Ã€ CONTINUIDADE ====================
            st.subheader("ğŸ¤ Convite Ã  Continuidade da Pesquisa")

            st.markdown("""
            **Queremos continuar contando com vocÃª!**
            
            Esta pesquisa nÃ£o termina aqui. Estamos desenvolvendo novas funcionalidades e gostarÃ­amos 
            de convidÃ¡-lo(a) para participar de outras etapas do estudo, como:
            
            - ğŸ¥ **SessÃµes mediadas por videoconferÃªncia** para observaÃ§Ã£o de uso
            - ğŸ“ **Oficinas e treinamentos** sobre bibliometria e ferramentas de pesquisa
            - ğŸ§ª **Testes de novas funcionalidades** antes do lanÃ§amento pÃºblico
            - ğŸ“Š **Entrevistas em profundidade** sobre suas estratÃ©gias de pesquisa
            
            Sua participaÃ§Ã£o Ã© voluntÃ¡ria e vocÃª poderÃ¡ desistir a qualquer momento. 
            Caso aceite, entraremos em contato por e-mail com mais informaÃ§Ãµes.
            """)

            aceite_continuidade = st.checkbox(
                "âœ… **Sim, aceito participar de outras fases desta pesquisa e autorizo contato por e-mail**",
                key="aceite_continuidade",
                help="Ao marcar esta opÃ§Ã£o, vocÃª demonstra interesse em contribuir com o desenvolvimento do DelinÃ©ia"
            )

            if aceite_continuidade:
                st.success("ğŸ‰ Obrigado por aceitar continuar conosco! VocÃª receberÃ¡ um e-mail com mais informaÃ§Ãµes em breve.")

            st.divider()

            # ==================== BOTÃƒO DE ENVIO ====================
            submitted = st.form_submit_button(
                "ğŸ“¤ Enviar AvaliaÃ§Ã£o",
                type="primary",
                use_container_width=True
            )

            if submitted:
                # Calcular categoria NPS
                if nps >= 9:
                    nps_category = "Promotor ğŸŒŸ"
                elif nps >= 7:
                    nps_category = "Neutro ğŸ˜"
                else:
                    nps_category = "Detrator ğŸ˜"

                # Armazenar respostas
                avaliacao_data = {
                    # Perguntas Likert (F2.1-F2.20)
                    'q1': q1, 'q2': q2, 'q3': q3, 'q4': q4, 'q5': q5,
                    'q6': q6, 'q7': q7, 'q8': q8, 'q9': q9, 'q10': q10,
                    'q11': q11, 'q12': q12, 'q13': q13, 'q14': q14, 'q15': q15,
                    'q16': q16, 'q17': q17, 'q18': q18, 'q19': q19, 'q20': q20,
                    # NPS (F2.21)
                    'nps': nps,
                    'nps_category': nps_category,
                    # Campos abertos (F2.22-F2.25)
                    'q22': q22,
                    'q23': q23,
                    'q24': q24,
                    'q25': q25,
                    # AutoavaliaÃ§Ã£o (F2.26)
                    'q26': q26,
                    # Perfil (F2.27-F2.30)
                    'q27': q27,
                    'q28': q28,
                    'q29': q29,
                    'q30': q30,
                    # Convite Ã  continuidade
                    'aceite_continuidade': aceite_continuidade,
                    # Metadados
                    'timestamp': datetime.now().isoformat()
                }

                # Salvar em session_state
                st.session_state.avaliacao_completa = True
                st.session_state.avaliacao_data = avaliacao_data

                # Enviar para Google Sheets
                if 'id_usuario' in st.session_state:
                    enviar_formulario_avaliacao(
                        st.session_state.id_usuario,
                        avaliacao_data
                    )

                # Badge de conclusÃ£o
                if 'ğŸ’ Avaliador' not in st.session_state.badges:
                    add_badge('ğŸ’ Avaliador')

                # Feedback visual
                st.success("âœ… AvaliaÃ§Ã£o enviada com sucesso!")
                st.balloons()

                # Resumo da avaliaÃ§Ã£o
                continuidade_msg = "Sim âœ…" if aceite_continuidade else "NÃ£o"
                
                st.info(f"""
                ğŸ“Š **Resumo da sua avaliaÃ§Ã£o:**

                â€¢ **NPS:** {nps}/10 ({nps_category})
                â€¢ **NÃ­vel acadÃªmico:** {q27}
                â€¢ **ExperiÃªncia bibliomÃ©trica:** {q28}
                â€¢ **Ãrea:** {q29}
                â€¢ **Tempo de uso:** {q30}
                â€¢ **Aceite para continuidade:** {continuidade_msg}

                ğŸ† **Badge desbloqueado:** Avaliador

                Obrigado por dedicar seu tempo para avaliar o DelinÃ©ia!
                Seu feedback Ã© essencial para o desenvolvimento contÃ­nuo do sistema.
                """)

                # AvanÃ§ar para prÃ³xima etapa
                st.session_state.step = 4
                st.rerun()
    
    # ========== ETAPA 4: CONCLUSÃƒO ==========
    elif st.session_state.step == 4:
        st.success("ğŸ‰ ParabÃ©ns! VocÃª completou todas as etapas!")
        st.markdown("### ğŸ† Conquista Desbloqueada: Delineador!")
        st.balloons()

        primeiro_nome = st.session_state.form_data['nome'].split()[0]

        st.write(f"**{primeiro_nome}**, vocÃª concluiu com sucesso:")
        st.write("âœ… Delineamento completo do projeto")
        st.write("âœ… AnÃ¡lise bibliomÃ©trica avanÃ§ada")
        st.write("âœ… AvaliaÃ§Ã£o do sistema DelinÃ©ia")
        st.write(f"\n**ğŸ… Suas conquistas:** {' '.join(st.session_state.badges)}")

        st.divider()

        # ========== PRÃŠMIO: VÃDEO MUSICAL ==========
        st.markdown("### ğŸµ PrÃªmio Especial: Uma palavra no escuro")
        
        st.markdown("""
        <div style="text-align: justify; 
                    background-color: #ffffff; 
                    border-left: 4px solid #28a745; 
                    padding: 1rem; 
                    border-radius: 0.25rem;
                    color: #000000;">
        Como reconhecimento pela sua dedicaÃ§Ã£o, presenteamos vocÃª com uma obra que simboliza 
        o processo de construÃ§Ã£o do conhecimento: a busca por palavras que iluminam 
        caminhos no escuro da incerteza. Uma homenagem Ã  Jorge Luis Borges e Ã  sua Biblioteca de Babel.
        <div>
        """, unsafe_allow_html=True)

        # Embedar vÃ­deo do YouTube
        video_url = "https://www.youtube.com/embed/aoKVEJc-7MU"
        
        st.markdown(
            f"""
            <div style="display: flex; justify-content: center; margin: 2rem 0;">
                <iframe width="700" height="394" 
                        src="{video_url}" 
                        frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                        allowfullscreen>
                </iframe>
            </div>
            """,
            unsafe_allow_html=True
        )

        # CrÃ©ditos em expander
        with st.expander("ğŸ“œ CrÃ©ditos e InformaÃ§Ãµes"):
            st.markdown("""
            <div style="text-align: center; 
                        background-color: #f8f9fa; 
                        padding: 1.5rem; 
                        border-radius: 0.5rem;
                        color: #000000;">
            
            **TÃ­tulo:** A palavra no escuro ou os dialetos do poÃ§o
                        
            **Ãlbum:** Os olhos de Borges (VersÃ£o musical do livro homÃ´nimo)
                        
            **Livro:** BRASIL, J.V. *Os olhos de Borges*. Porto Alegre: WS Editor, 1997.
                        
            **Autoria:** Jaime Vaz Brasil
                        
            **IntÃ©rprete(s):** Hique Gomez

            **Letra:** Jaime Vaz Brasil
                                    
            **MÃºsica:** Hique Gomez 
                                   
            **ProduÃ§Ã£o:** FUMPROARTE/POA e Instituto Fernando Pessoa
                                    
            **Ano:** 1999
            
            ---
            
            **ConexÃ£o com o DelinÃ©ia:**
            
            Esta mÃºsica integra o universo poÃ©tico que inspira a construÃ§Ã£o do sistema DelinÃ©ia. 
            A metÃ¡fora da "palavra no escuro" ecoa o processo de delineamento do escopo de pesquisa: 
            buscar, na vastidÃ£o da literatura cientÃ­fica, as palavras-chave que iluminam o caminho 
            do conhecimento.
            
            Assim como os "dialetos do poÃ§o" sugerem mÃºltiplas vozes emergindo da profundidade, 
            o DelinÃ©ia revela as mÃºltiplas dimensÃµes conceituais que estruturam um campo de pesquisa, 
            auxiliando estudantes a encontrarem suas prÃ³prias vozes acadÃªmicas.
            </div>
            """, unsafe_allow_html=True)
        col1, col2, col3 = st.columns([1, 2, 1])

        with col2:
            if st.button("ğŸ“œ Leia o prÃ³logo da tese", use_container_width=True):
                st.session_state.open_prologo = True
                st.info("""
                **O DelineascÃ³pio**

Esta Ã© uma palavra que respira. *Delineamento*â€¦

NÃ£o Ã© uma palavra-ponto, uma palavra-fim. NÃ£o Ã© limite, fronteira ou conclusÃ£o. Embora o Novo DicionÃ¡rio AurÃ©lio, em sua precisÃ£o cartogrÃ¡fica, nos diga que delinear tenha o significado de "[...] fixar os limites de; estremar, demarcar", a verdadeira alma da palavra reside em sua outra definiÃ§Ã£o: "[...] traÃ§ar as linhas gerais de; esboÃ§ar, debuxar".[^1] Esta Ã© uma palavra-processo. Uma palavra-verbo que se disfarÃ§a de substantivo. No seu coraÃ§Ã£o, pulsa o ato de delinear, do latim *delineare*, "[...] por via erudita".[^2] Em sua famÃ­lia, registrada nas colunas dos lÃ©xicos do vocabulÃ¡rio ortogrÃ¡fico da Academia Brasileira de Letras[^3], encontramos o delineador (aquele que traÃ§a) e o delineado (aquilo que foi traÃ§ado). Mas o delineamento Ã© algo mais. Ã‰ o "[...] ato de delinear".[^4] NÃ£o Ã© o traÃ§o, mas o traÃ§ar. NÃ£o Ã© o mapa, mas o mapear. Ã‰ "[...] o primeiro esboÃ§o ou projeto de qualquer obra; plano geral".[^5] Ã‰ o gesto inaugural da criaÃ§Ã£o. Ã‰ o primeiro traÃ§o.

O DicionÃ¡rio Houaiss nos conta um segredo: a palavra jÃ¡ circulava em 1552[^6]. Mil quinhentos e cinquenta e dois. Pensemos nisso. Esta nÃ£o Ã© uma palavra da RevoluÃ§Ã£o Industrial. NÃ£o nasceu fria, metÃ¡lica, otimizada sob uma linha de montagem, no distanciamento entre idealizaÃ§Ã£o e produÃ§Ã£o. Ela nasceu no auge do Renascimento, numa era de exploraÃ§Ã£o febril, quando o mundo conhecido se expandia e exigia ser desenhado, quando os mapas eram mais suposiÃ§Ã£o do que certeza. Sua primeira definiÃ§Ã£o registrada, "[...] ato ou efeito de delinear(-se); esboÃ§o, delineaÃ§Ã£o, traÃ§ado [...]", era usada para o "[...] esboÃ§o do projeto de reparaÃ§Ã£o a ser feita em qualquer parte de embarcaÃ§Ã£o".[^7]

Que poÃ©tica inaugural! O delineamento nÃ£o Ã© sobre construir o navio do zero; Ã© sobre o reparo. Ã‰ sobre olhar para uma estrutura que jÃ¡ existe (uma ideia, um navio, um campo de estudo) e traÃ§ar o plano para sua renovaÃ§Ã£o, sua travessia. O navio da pesquisa do estudante jÃ¡ existe, ancorado no porto da sua intuiÃ§Ã£o, mas com o casco opaco de incertezas. Ele precisa ser delineado para poder navegar.

Frequentemente, quando buscamos uma traduÃ§Ã£o apressada, a lÃ­ngua inglesa nos oferece, friamente, *design*. Mas *design* Ã© uma palavra que trai a alma do delineamento. *Design* carrega o peso da indÃºstria, do produto final, da ergonomia. O *design* Ã© assertivo, muitas vezes dogmÃ¡tico. Ele se impÃµe Ã  matÃ©ria. O *design* Ã© a cadeira, o *iPhone*, o motor: soluÃ§Ãµes acabadas, polidas, fechadas em si. Delineamento Ã© o oposto. Ã‰ uma palavra de escuta. O delineamento Ã© a pergunta ganhando forma.

O verbo delinear, "[...] traÃ§ar as linhas gerais de; esboÃ§ar, debuxar",[^8] Ã© um ato de humildade. O delineador nÃ£o inventa o contorno do continente; ele traÃ§a o contorno que descobre. O *design* fecha; o delineamento abre. O *design* Ã© a certeza do engenheiro; o delineamento Ã© a hesitaÃ§Ã£o do artista diante da tela em branco. Ã‰ por isso que o delineamento Ã© a palavra-raiz da cultura das descobertas, sejam elas artÃ­sticas, filosÃ³ficas, cientÃ­ficas ou mesmo industriais. A descoberta nÃ£o Ã© um *design*, mas um delineamento. Ã‰ o ato de tatear no escuro e, aos poucos, "[...] traÃ§ar as linhas gerais, o plano de; projetar, planejar".[^9] Ã‰ a transformaÃ§Ã£o da incerteza em foco.

E aqui, uma busca interessante se revela. A palavra delineamento Ã©, em si, um ato da crÃ­tica, da anÃ¡lise e da academia, mas Ã© rara dentro da prosa de ficÃ§Ã£o ou dos versos de poesia. Parece ser uma palavra que usamos para observar a literatura, e nÃ£o uma palavra que a literatura usa para observar o mundo. Um romancista provavelmente escreveria "o contorno do seu rosto" ou "o traÃ§ado do plano", mas raramente "o delineamento do seu rosto". A palavra pertence ao analista, ao pesquisador. A encontramos em textos de crÃ­tica literÃ¡ria, operando do mesmo modo como esta tese propÃµe: o processo de dar forma, traÃ§ar perfis e estruturar a descoberta.

Um ensaio sobre Erico Verissimo e Graham Greene menciona o "[...] delineamento de dois perfis de personagens [...]".[^10] Um estudo sobre Machado de Assis foca no "[...] delineamento do percurso da escrita de 'O alienista' [...]",[^11] analisando como Machado de Assis esboÃ§ou e refez sua obra. Um crÃ­tico, sobre o poeta DemÃ©trio Vieira Diniz, afirma que seu livro "[...] atesta e faz saber o delineamento de uma singular dicÃ§Ã£o".[^12] Ã‰ a palavra que usamos para entender a criaÃ§Ã£o, perfeita para descrever o processo de descoberta que o aluno, no centro desta tese, estÃ¡ colocado a realizar.

Em um canto esquecido da estante, em um DicionÃ¡rio de ComunicaÃ§Ã£o, encontramos um artefato. Ao buscar uma remissiva da entrada principal do verbete "EpiscÃ³pio", lemos: "Aparelho baseado na reflexÃ£o de luz, que se destina Ã  projeÃ§Ã£o de imagens de objetos opacos (tais como fotografias, desenhos etc.). TambÃ©m chamado de delineascÃ³pio ou de projetor opaco".[^13] *DelineascÃ³pio*: o-que-projeta-o-delineado [sic].

Um aparelho (*scÃ³pio*) que torna visÃ­vel (*projeÃ§Ã£o*) um esboÃ§o ou traÃ§ado (*delÃ­nea*). Aqui, a poÃ©tica se completa. O conhecimento comeÃ§a nÃ£o com a luz, mas com um objeto opaco. Qual Ã© o "objeto opaco" senÃ£o a ideia inicial de um pesquisador? Ã‰ aqui que a palavra encontra sua casa nesta tese: "*Grandes modelos de linguagem e anÃ¡lise de coocorrÃªncia de palavras-chave para o delineamento do escopo de projetos de pesquisa no ensino superior*".

O estudante chega ao ensino superior carregando esse objeto opaco. Ele o segura nas mÃ£os. O projeto o chama, em linguagem tÃ©cnica, de "necessidade de informaÃ§Ã£o", de uma etapa de "formulaÃ§Ã£o" marcada por "sentimentos iniciais de dÃºvida e confusÃ£o", ou o estado de "prÃ©-foco" onde a "incerteza Ã© um estado cognitivo que comumente causa sintomas afetivos de ansiedade e falta de confianÃ§a".[^14] Como encontrar as agulhas certas nos palheiros mais loucos?

Simbolicamente, Ã© uma intuiÃ§Ã£o turva. Um vulto. Um interesse que ainda nÃ£o tem palavras. Ã‰ um desenho que nÃ£o pode ser visto. Ã‰ um mapa por fazer. Como traÃ§ar o que ainda nÃ£o se vÃª? Ã‰ preciso, entÃ£o, um delineascÃ³pio. Um aparelho de luz refletida. NÃ£o a luz que cega, mas a que projeta os contornos do que jÃ¡ estÃ¡ lÃ¡. Esta tese Ã© uma das engrenagens da engenharia desta mÃ¡quina. O estudante coloca seu objeto opaco (sua ideia de tema, sua questÃ£o de pesquisa inicial, suas primeiras palavras-chave) na mÃ¡quina. A mÃ¡quina, entÃ£o, usa duas fontes de luz para projetar essa ideia na grande teia da literatura cientÃ­fica.

A primeira luz Ã© a anÃ¡lise de coocorrÃªncia de palavras. Ela funciona exatamente como um episcÃ³pio: ela reflete a luz sobre o objeto opaco do aluno e projeta as conexÃµes que ele nÃ£o podia ver. O estudante vÃª seu termo (por exemplo, "*gamification*") e, de repente, projetado na tela, ele o vÃª ligado a "*motivation*", "*higher education*", "*engagement*", "*learning outcomes*". O grafo de coocorrÃªncia Ã© a projeÃ§Ã£o. O opaco tornou-se visÃ­vel, relacional, delineÃ¡vel. O estudante pode, agora, pegar seu lÃ¡pis e traÃ§ar as conexÃµes que a luz revelou. A mÃ¡quina oferece uma visÃ£o complementar dos conceitos centrais.

A segunda luz Ã© generativa. SÃ£o os grandes modelos de linguagem (LLMs). Se a coocorrÃªncia Ã© a projeÃ§Ã£o, o LLM Ã© o *feedback*, a mediaÃ§Ã£o. Ã‰ a voz que ajuda o estudante a ajustar o foco do delineascÃ³pio. Ele nÃ£o se limita a projetar o que existe; ele conversa com a projeÃ§Ã£o. Ele oferece o *feedback* textual automatizado. Ele olha para a projeÃ§Ã£o e sussurra: "As palavras-chave designadas para o projeto se mostram alinhadas... No entanto, algumas expressÃµes ainda podem ser consideradas genÃ©ricas... Ã‰ recomendÃ¡vel que vocÃª considere a possibilidade de incorporar termos mais descritivosâ€¦ Converse com seu orientadorâ€¦".[^15] Ele sugere novas lentes, novas palavras. O delineamento do escopo deixa de ser uma tarefa burocrÃ¡tica de definiÃ§Ã£o de limites e se torna um ato poÃ©tico de projeÃ§Ã£o e descoberta. Deixa de ser um ato de solidÃ£o e passa a ser um ato de mediaÃ§Ã£o. E no centro deste ato, o estudante. Este projeto coloca o aluno no centro desse processo. O estudante nÃ£o Ã© um receptor passivo de *design*. Ele Ã© o delineador[^16].

Esta tese reconhece a luta humana nesse processo. Ela se ancora em modelos teÃ³ricos que sÃ£o, em essÃªncia, mapas da alma deste estudante-pesquisador. Ela se fundamenta no modelo de Kuhlthau, que entende a busca como uma passagem dolorosa e necessÃ¡ria da "incerteza" para a confianÃ§a.[^17] Ela se baseia no modelo cognitivo de escrita de Flower e Hayes, que entende a escrita nÃ£o como uma traduÃ§Ã£o linear, mas como um processo recursivo de "planejamento, geraÃ§Ã£o de ideias, organizaÃ§Ã£o e definiÃ§Ã£o de metas"[^18], ou seja, o prÃ³prio ato de delinear. E se alicerÃ§a no modelo de comportamento informacional de Wilson, que mapeia o "comportamento de busca" e as "barreiras" que tornam a ideia opaca em primeiro lugar.[^19]

O delineamento proposto nesta tese Ã©, portanto, terapÃªutico. Ele oferece ao estudante, que "enfrenta dificuldades" e "inÃºmeros desafios", as ferramentas nÃ£o para resolver seu problema, mas para vÃª-lo projetado. A ferramenta torna-se uma mediadora do pensamento cientÃ­fico, um andaime para a autonomia investigativa, um fomento ao pensamento crÃ­tico.

Em 1552, o delineamento era o esboÃ§o para reparar um navio e preparÃ¡-lo para a travessia. Hoje, o delineamento Ã© o esboÃ§o para reparar a confianÃ§a do estudante-pesquisador, dando-lhe o mapa: o delineascÃ³pio para sua prÃ³pria travessia intelectual. A pesquisa, assim como a arte, nÃ£o Ã© sobre ter respostas prontas, mas sobre a coragem de fazer o traÃ§o inicial, de navegar a incerteza e, aos poucos, dar forma ao pensamento. Minha tese Ã© a histÃ³ria da construÃ§Ã£o desse delineascÃ³pio. Ã‰ um convite para trocar a ansiedade da pÃ¡gina em branco pela descoberta mediada do primeiro traÃ§o. Ã‰ uma palavra que acolhe a jornada do estudante, celebrando o esboÃ§o tanto quanto a obra final.

Para que todo estudante, segurando seu objeto opaco, possa encontrar a luz para projetÃ¡-lo e, enfim, comeÃ§ar a delinearâ€¦

â€¦ *DelinÃ©ia !!!*

---

**Notas:**

[^1]: FERREIRA, A.B.H. *Novo dicionÃ¡rio AurÃ©lio da lÃ­ngua portuguesa*. 4.ed. Curitiba: Positivo, 2009.
[^2]: NASCENTES, A. *DicionÃ¡rio etimolÃ³gico resumido*. Rio de Janeiro: INL, 1966.
[^3]: ACADEMIA BRASILEIRA DE LETRAS. *VocabulÃ¡rio ortogrÃ¡fico da lÃ­ngua portuguesa*. 5.ed. SÃ£o Paulo: Global, 2009.
[^4]: FERREIRA, op. cit., p. 614.
[^5]: Ibid.
[^6]: HOUAISS, A.; VILLAR, M.S. *DicionÃ¡rio Houaiss da lÃ­ngua portuguesa*. Rio de Janeiro: Objetiva, 2009.
[^7]: Ibid.
[^8]: FERREIRA, op. cit. p. 614.
[^9]: HOUAISS, op. cit., p. 610.
[^10]: DIAS, R.C. Americanos ingÃªnuos e vietnamitas silenciosas: uma abordagem intertextual de O americano tranquilo e O prisioneiro. *PapÃ©is*. Campo Grande, v. 23, n. 46, p. 61-75, 2019.
[^11]: CRESTANI, J.L. O Alienista: anÃ¡lise das variantes do folhetim e do livro. *SOLETRAS*, v. 10, n. 19, p. 156-166, 2010.
[^12]: DANTAS, M.L. O trem azul do destino da poesia de DemÃ©trio Diniz. *Letras In.verso e Re.verso*. 2016.
[^13]: RABAÃ‡A, C.A.; BARBOSA, G.G. *DicionÃ¡rio de comunicaÃ§Ã£o*. 2.ed. Rio de Janeiro: Campus, 2002.
[^14]: Trechos da tese sobre modelos de comportamento informacional.
[^15]: Exemplo de feedback gerado pelo sistema DelinÃ©ia.
[^16]: FERREIRA, op. cit., p. 614.
[^17]: KUHLTHAU, C.C. *Seeking meaning:* a process approach to library and information services. 2.ed. Westport: Libraries Unlimited, 2004.
[^18]: FLOWER, L.; HAYES, J.R. A cognitive process theory of writing. *College Composition and Communication*, v. 32, n. 4, p. 365â€“387, 1981.
[^19]: WILSON, T.D. On user studies and information needs. *Journal of Documentation*, v. 37, n. 1, p. 3-15, 1981.

**Desnorte**

O mundo Ã© este monte: palha e pÃ³.
 
Um caos de fibra, um tato quase cego,
 
Onde me perco e nada mais congrego,
 
Mergulhado em um vasto e mudo "sÃ³".

                        
Perdi o mapa; a rota Ã© sÃ³ tormento.
 
A perspectiva Ã© turva, escura nÃ©voa;
 
A dÃºvida Ã© um peso, noite, treva,
 
E o "quÃª fazer" corrÃ³i a cada momento.


A inÃ©rcia abre a estrada do fracasso;
 
O nÃ£o saber Ã© um jugo, um precipÃ­cio,
 
NÃ£o hÃ¡ repouso ou fim neste compasso.
                        

Resta encontrar, no caos, o puro indÃ­cio:
 
A agulha. O aÃ§o. O ponto duro e escasso.
 
Que sangre o dedo, mas que estanque o vÃ­cio.


ğŸ”

                        
""")

        st.divider()

        if st.button("ğŸ”„ Iniciar Novo Delineamento", use_container_width=True):
            st.session_state.step = 1
            st.session_state.resultado = None
            st.session_state.form_data = {}
            st.session_state.avaliacao_completa = False
            st.session_state.badges = []
            st.rerun()

# ==================== ABA 2: PAINEL DE ANÃLISE ====================
with tab2:
    st.title("ğŸ“Š Painel de ExploraÃ§Ã£o de Dados")
    st.caption("AnÃ¡lise profunda dos dados do OpenAlex")

    # Sidebar para configuraÃ§Ã£o
    with st.sidebar:
        st.header("âš™ï¸ Configurar Busca")

        # Campo de busca
        query = st.text_input(
            "String de Busca:",
            value=st.session_state.get('dashboard_query', "HIV/AIDS AND Brasil"),
            help="Use operadores: AND, OR, NOT"
        )

        if 'dashboard_query' in st.session_state and st.session_state.dashboard_query:
            st.info("ğŸ“‹ String copiada do DelineascÃ³pio")

        st.divider()
        st.subheader("ğŸ”§ Filtros")

        # OpÃ§Ã£o de sincronizar configuraÃ§Ãµes
        with st.expander("âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas"):
            sync_config = st.checkbox("Usar configuraÃ§Ã£o padrÃ£o", value=True)

            if sync_config:
                st.info("**ConfiguraÃ§Ã£o PadrÃ£o:**\n- Limite: 500 artigos\n- Score mÃ­nimo: 0.35\n- Level mÃ­nimo: 0")
                limit = 500
                min_score = 0.35
                min_level = 0
            else:
                limit = st.slider("Limite de artigos:", 10, 500, 100, 10,
                    help="NÃºmero mÃ¡ximo de artigos a buscar na API OpenAlex")
                min_score = st.slider("Score mÃ­nimo:", 0.0, 1.0, 0.35, 0.05,
                    help="RelevÃ¢ncia mÃ­nima do conceito (0-1). Valores maiores = conceitos mais relevantes")
                min_level = st.slider("Level mÃ­nimo:", 0, 5, 0, 1,
                    help="NÃ­vel hierÃ¡rquico do conceito (0-5). 0 = geral, 5 = muito especÃ­fico")

        min_cooc = st.slider("CoocorrÃªncia mÃ­nima:", 1, 10, 2, 1,
            help="FrequÃªncia mÃ­nima de coocorrÃªncia para formar aresta no grafo")

        st.divider()

        # BotÃ£o de buscar
        if st.button("ğŸ” Buscar", type="primary", use_container_width=True):
            with st.spinner("ğŸ”„ Em processamento, confira no Painel"):
                try:
                    # Inicializar cliente
                    client = OpenAlexClient(OPENALEX_EMAIL)

                    # Buscar artigos
                    articles = client.search_articles(client.normalize_query(query), limit)

                    # Extrair conceitos
                    concepts_lists = []
                    for article in articles:
                        concepts = [
                            c['name'] for c in article.get('concepts', [])
                            if c['score'] >= min_score and c['level'] >= min_level
                        ]
                        if concepts:
                            concepts_lists.append(concepts)

                    # Construir grafo
                    analyzer = CooccurrenceAnalyzer()
                    G = analyzer.build_graph(concepts_lists, min_cooc)

                    # Salvar dados
                    st.session_state.dashboard_data = {
                        'articles': articles,
                        'concepts_lists': concepts_lists,
                        'graph': G
                    }

                    # Mostrar detalhes
                    with st.expander("ğŸ“‹ Detalhes da Busca"):
                        st.write(f"**String enviada:** {query}")
                        st.write(f"**Limite:** {limit}")
                        st.write(f"**CoocorrÃªncia mÃ­nima:** {min_cooc}")
                        st.write(f"**Filtros:** scoreâ‰¥{min_score}, levelâ‰¥{min_level}")
                        st.write(f"**Artigos retornados:** {len(articles)}")
                        st.write(f"**Conceitos extraÃ­dos:** {len(concepts_lists)}")
                        st.write(f"**NÃ³s no grafo:** {len(G.nodes())}")

                    st.success(f"âœ… {len(articles)} artigos | {len(G.nodes())} conceitos")

                except Exception as e:
                    st.error(f"âŒ Erro: {str(e)}")

        st.divider()

        # ========== SEÃ‡ÃƒO SOBRE ==========
        with st.expander("ğŸ“‹ Sobre o DelinÃ©ia"):
            st.markdown("""
            ### O que Ã© o DelinÃ©ia?
            O DelinÃ©ia Ã© um sistema de apoio ao delineamento do escopo temÃ¡tico de projetos de pesquisa no ensino superior e foi desenvolvido como parte de uma tese de doutorado em InformÃ¡tica na EducaÃ§Ã£o. O sistema combina inteligÃªncia artificial generativa (Google Gemini) com anÃ¡lise bibliomÃ©trica de coocorrÃªncia de palavras (OpenAlex) para auxiliar estudantes de graduaÃ§Ã£o e de pÃ³s-graduaÃ§Ã£o no esboÃ§o de seus projetos de pesquisa.
        
            ### Desenvolvimento
            **Autor:** Rafael Antunes dos Santos  
            
            **InstituiÃ§Ã£o:**             
            - Universidade Federal do Rio Grande do Sul (UFRGS) 
            - Centro Interdisciplinar de Novas Tecnologias na EducaÃ§Ã£o (Cinted)
            - Programa de PÃ³s-GraduaÃ§Ã£o em InformÃ¡tica na EducaÃ§Ã£o (PPGIE)
              
            **NÃ­vel:** Doutorado  
            **Orientador:** Prof. Dr. Eliseo Berni Reategui  
        
            **FormaÃ§Ã£o Anterior:**
            - Mestre em ComunicaÃ§Ã£o e InformaÃ§Ã£o pela UFRGS (PPGCOM)  
            - Bacharel em Biblioteconomia pela UFRGS (DCI/FABICO) - CRB10/1898
        
            **CurrÃ­culo Lattes:** [http://lattes.cnpq.br/5228660998907867](http://lattes.cnpq.br/5228660998907867)
        
            ### Abordagem Interdisciplinar
            Este projeto situa-se no diÃ¡logo entre InformÃ¡tica na EducaÃ§Ã£o e CiÃªncia da InformaÃ§Ã£o, explorando como tecnologias de IA podem apoiar processos de pesquisa cientÃ­fica no ensino superior.
        
            ### Funcionalidades
            - **DelineascÃ³pio:** Feedback personalizado sobre projetos de pesquisa
            - **Painel:** AnÃ¡lise profunda de dados do OpenAlex:
              - **Artigos:** Contagens de artigos e links de acesso
              - **Conceitos:** Contagens de conceitos, nuvem de palavras e Lei de Zipf
              - **CoocorrÃªncias:** Contagens de associaÃ§Ãµes entre conceitos e matrizes
              - **Grafo:** VisualizaÃ§Ã£o interativa
              - **Mapa TemÃ¡tico:** PosiÃ§Ã£o do cluster
              - **EstatÃ­sticas:** Resumo breve
              - **ExportaÃ§Ã£o:** Dados em JSON, CSV, GraphML, BibTeX, RIS
        
            ### Tecnologias
            - Python / Streamlit
            - Google Gemini AI 2.5 Pro / Anthropic Claude Opus 4.5
            - OpenAlex API
            - NetworkX, Plotly, ReportLab
        
            ### Contato
            ğŸ“§ rafael.antunes@ufrgs.br
            ğŸ“§ rderafa@gmail.com           
        
            ### VersÃ£o
            DelinÃ©ia I - 2025

            ### Agradecimentos
            Ao **Orientador** Eliseo Berni Reategui; Aos **Professores** Alexandra Lorandi, Alexandre Ribas Semeler, Dante Augusto Couto Barone, Elisa Boff, Fernando Becker, Gabriela Trindade Perry, Ida Regina Chitto Stumpf, Leandro Krug Wives, Marcus Vinicius de Azevedo Basso, Maria de FÃ¡tima Santos Maia, Milton Antonio Zaro, PatrÃ­cia Fernanda da Silva, Rafael Port da Rocha, Regina Helena Van der Laan, Renato Ventura Bayan Henriques, Rosa Maria Vicari, Samile AndrÃ©a de Souza Vanz, SÃ©rgio Roberto Kieling Franco, Sonia Elisa Caregnato e Vanessa Soares Maurente. Aos colegas do grupo de pesquisa **GTech.Edu** e Ã  **CAPES**, pela concessÃ£o de bolsa de estudos.
            """)
    
    # Ãrea principal do painel
    if st.session_state.dashboard_data is None:
        st.info("ğŸ‘ˆ Configure os parÃ¢metros na barra lateral e clique em **Buscar** para iniciar a anÃ¡lise")

        # Mostrar exemplo
        with st.expander("ğŸ’¡ Exemplo de uso"):
            st.markdown("""
            **Como usar o Painel:**

            1. **Digite uma string de busca** (ex: "machine learning AND education")
            2. **Ajuste os filtros** conforme necessÃ¡rio
            3. **Clique em Buscar** para processar
            4. **Explore as abas** com diferentes anÃ¡lises
            5. **Exporte os dados** quando necessÃ¡rio

            **Dica:** VocÃª pode copiar a string de busca do DelineascÃ³pio!
            """)

    else:
        # Recuperar dados
        data = st.session_state.dashboard_data
        articles = data['articles']
        concepts_lists = data['concepts_lists']
        G = data['graph']

        # Criar sub-abas para anÃ¡lises
        t1, t2, t3, t4, t5, t6, t7 = st.tabs([
            "ğŸ“š Artigos",
            "ğŸ§© Conceitos",
            "ğŸ”— CoocorrÃªncias",
            "ğŸ•¸ï¸ Grafo",
            "ğŸ—ºï¸ Mapa TemÃ¡tico",
            "ğŸ“Š EstatÃ­sticas",
            "ğŸ’¾ ExportaÃ§Ã£o"
        ])

        # ========== SUB-ABA 1: ARTIGOS (COM DOI/URL) - VERSÃƒO CORRIGIDA ==========
        with t1:
            st.header("ğŸ“š Artigos Analisados")
            st.metric("Total de Artigos", len(articles))

            # âœ¨ TABELA COM COLUNA DOI/URL âœ¨
            df_articles = pd.DataFrame([
                {
                    'TÃ­tulo': (lambda t: t[:80] + '...' if len(t) > 80 else t)(a.get('title') or 'Sem tÃ­tulo'),
                    'Ano': a.get('year', 'N/A'),
                    'Conceitos': len(a.get('concepts', [])),
                    'DOI/URL': a.get('doi', a.get('url', 'N/A'))
                }
                for a in articles
            ])

            # Configurar coluna como link clicÃ¡vel
            st.dataframe(
                df_articles,
                use_container_width=True,
                height=400,
                column_config={
                    "DOI/URL": st.column_config.LinkColumn(
                        "ğŸ”— DOI/URL",
                        help="Clique para abrir o artigo",
                        display_text="Abrir artigo"
                    )
                }
            )
    
            if len(articles) > 0:
                st.divider()
                st.subheader("ğŸ” Detalhes do Artigo")
    
                # Seletor de artigo - CORRIGIDO
                idx = st.selectbox(
                    "Selecione um artigo:",
                    range(len(articles)),
                    format_func=lambda i: f"{i+1}. {(articles[i].get('title') or 'Sem tÃ­tulo')[:60]}..."
                )
    
                selected = articles[idx]
    
                col1, col2 = st.columns([2, 1])
    
                with col1:
                    st.write(f"**TÃ­tulo:** {selected.get('title') or 'Sem tÃ­tulo'}")
                    st.write(f"**Ano:** {selected.get('year', 'N/A')}")
    
                    # âœ¨ EXIBIR LINK CLICÃVEL âœ¨
                    link = selected.get('doi', selected.get('url', ''))
                    if link:
                        st.markdown(f"**ğŸ”— Link:** [{link}]({link})")
                    else:
                        st.write("**ğŸ”— Link:** N/A")
    
                with col2:
                    st.metric("Conceitos", len(selected.get('concepts', [])))
    
                st.subheader("ğŸ“‹ Conceitos do Artigo")
    
                concepts_df = pd.DataFrame([
                    {
                        'Conceito': c['name'],
                        'Score': f"{c['score']:.3f}",
                        'Level': c['level']
                    }
                    for c in selected.get('concepts', [])
                ])
    
                if not concepts_df.empty:
                    st.dataframe(concepts_df, use_container_width=True)
                else:
                    st.info("Nenhum conceito encontrado")
    
                with st.expander("ğŸ” Ver JSON completo"):
                    st.json(selected)

        # ========== SUB-ABA 2: CONCEITOS ==========
        with t2:
            st.header("ğŸ§© AnÃ¡lise de Conceitos")

            # EstatÃ­sticas gerais
            all_concepts = [c for cl in concepts_lists for c in cl]
            freq = Counter(all_concepts)

            col1, col2, col3 = st.columns(3)
            col1.metric("Artigos com Conceitos", len(concepts_lists))
            col2.metric("Conceitos Ãšnicos", len(freq))
            col3.metric("Total de OcorrÃªncias", len(all_concepts))

            st.divider()

            # ===== NUVEM DE PALAVRAS (com Plotly) =====
            st.subheader("â˜ï¸ Nuvem de Conceitos")
            
            # Criar dicionÃ¡rio de frequÃªncias
            freq_dict = dict(freq.most_common(50))
            
            if freq_dict:
                import random
                random.seed(42)
                
                # Preparar dados
                words = list(freq_dict.keys())
                frequencies = list(freq_dict.values())
                max_freq = max(frequencies)
                min_freq = min(frequencies)
                
                # Normalizar tamanhos (entre 12 e 80)
                sizes = [12 + (f - min_freq) / (max_freq - min_freq) * 68 if max_freq > min_freq else 40 for f in frequencies]
                
                # PosiÃ§Ãµes em espiral/orgÃ¢nica
                n = len(words)
                x_positions = []
                y_positions = []
                for i in range(n):
                    angle = i * 2.4  # Ã‚ngulo Ã¡ureo
                    radius = 10 + i * 1.5
                    x_positions.append(50 + radius * np.cos(angle) * 0.8)
                    y_positions.append(50 + radius * np.sin(angle) * 0.5)
                
                # Paleta de cores mais harmÃ´nica
                color_palette = ['#e63946', '#f4a261', '#2a9d8f', '#264653', '#e9c46a', 
                                '#023e8a', '#0077b6', '#8338ec', '#ff006e', '#06d6a0']
                colors = [color_palette[i % len(color_palette)] for i in range(n)]
                
                # Criar figura
                fig_cloud = go.Figure()
                
                for i, word in enumerate(words):
                    fig_cloud.add_trace(go.Scatter(
                        x=[x_positions[i]],
                        y=[y_positions[i]],
                        mode='text',
                        text=[word],
                        textfont=dict(size=sizes[i], color=colors[i], family='Arial Black'),
                        hoverinfo='text',
                        hovertext=f'{word}: {frequencies[i]} ocorrÃªncias',
                        showlegend=False
                    ))
                
                fig_cloud.update_layout(
                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 100]),
                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[0, 100]),
                    height=450,
                    margin=dict(l=0, r=0, t=10, b=10),
                    plot_bgcolor='white'
                )
                
                st.plotly_chart(fig_cloud, use_container_width=True)
            else:
                st.info("Sem dados suficientes para gerar nuvem de palavras")
            
            st.divider()

            # Top conceitos
            st.subheader("ğŸ† Conceitos Mais Frequentes")

            top_n = st.slider("NÃºmero de conceitos:", 10, 50, 20, 5, key="top_concepts")

            df_freq = pd.DataFrame(
                freq.most_common(top_n),
                columns=['Conceito', 'FrequÃªncia']
            )

            # GrÃ¡fico de barras
            fig = px.bar(
                df_freq,
                x='FrequÃªncia',
                y='Conceito',
                orientation='h',
                title=f"Top {top_n} Conceitos Mais Frequentes",
                color='FrequÃªncia',
                color_continuous_scale='blues'
            )
            fig.update_layout(
                height=600,
                yaxis={'categoryorder': 'total ascending'}
            )

            st.plotly_chart(fig, use_container_width=True)

            # AnÃ¡lise de Zipf
            def analyze_zipf(frequency_data):
                """
                Analisa a distribuiÃ§Ã£o de frequÃªncias segundo a Lei de Zipf

                Args:
                    frequency_data: Lista de tuplas (palavra, frequÃªncia) ordenada por frequÃªncia

                Returns:
                    dict com mÃ©tricas e dados para plotagem
                """
                # Extrair frequÃªncias
                frequencies = [freq for _, freq in frequency_data]

                # Criar ranks (1, 2, 3, ...)
                ranks = np.arange(1, len(frequencies) + 1)

                # Converter para arrays numpy
                ranks_array = np.array(ranks)
                freq_array = np.array(frequencies)

                # Aplicar log para anÃ¡lise linear
                log_ranks = np.log10(ranks_array)
                log_freqs = np.log10(freq_array)

                # RegressÃ£o linear no espaÃ§o log-log
                slope, intercept, r_value, p_value, std_err = stats.linregress(log_ranks, log_freqs)

                # Calcular RÂ²
                r_squared = r_value ** 2

                # Gerar linha de tendÃªncia
                trend_line = 10 ** (slope * log_ranks + intercept)

                # InterpretaÃ§Ã£o
                if r_squared > 0.90:
                    interpretation = "âœ… Forte aderÃªncia Ã  Lei de Zipf"
                    quality = "excelente"
                elif r_squared > 0.75:
                    interpretation = "âš ï¸ AderÃªncia moderada Ã  Lei de Zipf"
                    quality = "boa"
                else:
                    interpretation = "âŒ Fraca aderÃªncia Ã  Lei de Zipf"
                    quality = "baixa"

                # AnÃ¡lise da inclinaÃ§Ã£o
                if -1.2 < slope < -0.8:
                    slope_interpretation = "prÃ³ximo ao ideal (-1.0)"
                elif slope < -1.2:
                    slope_interpretation = "vocabulÃ¡rio mais concentrado que o esperado"
                else:
                    slope_interpretation = "vocabulÃ¡rio mais disperso que o esperado"

                return {
                    'ranks': ranks_array,
                    'frequencies': freq_array,
                    'log_ranks': log_ranks,
                    'log_freqs': log_freqs,
                    'trend_line': trend_line,
                    'slope': slope,
                    'intercept': intercept,
                    'r_squared': r_squared,
                    'p_value': p_value,
                    'interpretation': interpretation,
                    'quality': quality,
                    'slope_interpretation': slope_interpretation
                }

            # Executar anÃ¡lise de Zipf
            if len(freq) > 0:
                st.divider()
                st.subheader("ğŸ“ˆ AnÃ¡lise da Lei de Zipf")

                st.markdown("""
                A **Lei de Zipf** prediz que a frequÃªncia de uma palavra Ã© inversamente proporcional
                ao seu ranking. Em um grÃ¡fico log-log, isso aparece como uma linha reta com inclinaÃ§Ã£o
                prÃ³xima a -1.0.
                """)

                # Preparar dados (tuplas de palavra, frequÃªncia)
                frequency_data = freq.most_common()

                # Chamar a funÃ§Ã£o de anÃ¡lise
                zipf_results = analyze_zipf(frequency_data)

                # Exibir mÃ©tricas
                col1, col2, col3 = st.columns(3)
                col1.metric("RÂ² (AderÃªncia)", f"{zipf_results['r_squared']:.3f}")
                col2.metric("InclinaÃ§Ã£o", f"{zipf_results['slope']:.3f}")
                col3.metric("Qualidade", zipf_results['quality'].upper())

                # InterpretaÃ§Ãµes
                st.info(f"**{zipf_results['interpretation']}** - InclinaÃ§Ã£o {zipf_results['slope_interpretation']}")

                # GrÃ¡fico log-log
                fig_zipf = go.Figure()

                # Dados reais
                fig_zipf.add_trace(go.Scatter(
                    x=zipf_results['ranks'],
                    y=zipf_results['frequencies'],
                    mode='markers',
                    name='Dados Observados',
                    marker=dict(size=8, color='blue'),
                    text=[word for word, _ in frequency_data],
                    hovertemplate='<b>%{text}</b><br>Rank: %{x}<br>FrequÃªncia: %{y}<extra></extra>'
                ))

                # Linha de tendÃªncia (Lei de Zipf)
                fig_zipf.add_trace(go.Scatter(
                    x=zipf_results['ranks'],
                    y=zipf_results['trend_line'],
                    mode='lines',
                    name='Lei de Zipf (teÃ³rico)',
                    line=dict(color='red', dash='dash', width=2)
                ))

                fig_zipf.update_layout(
                    title='DistribuiÃ§Ã£o de Zipf (Escala Log-Log)',
                    xaxis_title='Ranking (log)',
                    yaxis_title='FrequÃªncia (log)',
                    xaxis_type='log',
                    yaxis_type='log',
                    height=500,
                    hovermode='closest'
                )

                st.plotly_chart(fig_zipf, use_container_width=True)

                # ExplicaÃ§Ã£o adicional
                with st.expander("â„¹ï¸ Como interpretar"):
                    st.markdown(f"""
                    **RÂ² = {zipf_results['r_squared']:.3f}**
                    - RÂ² > 0.90: Excelente aderÃªncia Ã  Lei de Zipf
                    - 0.75 < RÂ² < 0.90: Boa aderÃªncia
                    - RÂ² < 0.75: Baixa aderÃªncia

                    **InclinaÃ§Ã£o = {zipf_results['slope']:.3f}**
                    - Ideal: prÃ³ximo a -1.0
                    - Mais negativo: vocabulÃ¡rio concentrado em poucas palavras
                    - Menos negativo: vocabulÃ¡rio mais distribuÃ­do

                    **SignificÃ¢ncia estatÃ­stica**: p-value = {zipf_results['p_value']:.6f}
                    """)

            # Tabela
            st.divider()
            st.subheader("ğŸ“‹ Tabela de FrequÃªncias")
            st.dataframe(df_freq, use_container_width=True)

            st.divider()

            # DistribuiÃ§Ã£o
            st.subheader("ğŸ“Š DistribuiÃ§Ã£o de Conceitos por Artigo")

            concepts_per_article = [len(c) for c in concepts_lists]

            fig2 = px.histogram(
                x=concepts_per_article,
                nbins=20,
                labels={'x': 'NÃºmero de conceitos', 'y': 'FrequÃªncia'},
                title="DistribuiÃ§Ã£o de Conceitos por Artigo"
            )

            st.plotly_chart(fig2, use_container_width=True)

            if len(concepts_per_article) > 0:
                col1, col2, col3 = st.columns(3)
                col1.metric("MÃ©dia", f"{sum(concepts_per_article)/len(concepts_per_article):.1f}")
                col2.metric("MÃ­nimo", min(concepts_per_article))
                col3.metric("MÃ¡ximo", max(concepts_per_article))

        # ========== SUB-ABA 3: COOCORRÃŠNCIAS ==========
        with t3:
            st.header("ğŸ”— AnÃ¡lise de CoocorrÃªncias")

            # Calcular pares
            pairs = Counter()
            for concepts in concepts_lists:
                for i, c1 in enumerate(concepts):
                    for c2 in concepts[i+1:]:
                        if c1 != c2:
                            pairs[tuple(sorted([c1, c2]))] += 1

            st.metric("Pares Ãšnicos", len(pairs))

            st.divider()

            # Top pares
            st.subheader("ğŸ† CoocorrÃªncias Mais Frequentes")

            top_pairs = st.slider("NÃºmero de pares:", 10, 100, 30, 10, key="top_pairs")

            df_pairs = pd.DataFrame([
                {
                    'Conceito 1': c1,
                    'Conceito 2': c2,
                    'FrequÃªncia': f
                }
                for (c1, c2), f in pairs.most_common(top_pairs)
            ])

            st.dataframe(df_pairs, use_container_width=True)

            st.divider()

            # Matriz de calor
            st.subheader("ğŸ”¥ Matriz de Calor de CoocorrÃªncias")

            top_heatmap = st.slider("Conceitos na matriz:", 5, 20, 10, 1, key="heatmap_size")

            top_concepts = [c for c, _ in freq.most_common(top_heatmap)]

            # Criar matriz
            matrix = pd.DataFrame(0, index=top_concepts, columns=top_concepts)

            for (c1, c2), f in pairs.items():
                if c1 in top_concepts and c2 in top_concepts:
                    matrix.loc[c1, c2] = f
                    matrix.loc[c2, c1] = f

            fig = px.imshow(
                matrix,
                labels=dict(x="Conceito", y="Conceito", color="CoocorrÃªncias"),
                title=f"Matriz de Calor - Top {top_heatmap} Conceitos",
                color_continuous_scale='Blues'
            )
            fig.update_layout(height=600)

            st.plotly_chart(fig, use_container_width=True)

            st.divider()

            # DistribuiÃ§Ã£o de frequÃªncias
            st.subheader("ğŸ“ˆ DistribuiÃ§Ã£o das FrequÃªncias de CoocorrÃªncia")

            freqs = list(pairs.values())

            fig3 = px.histogram(
                x=freqs,
                nbins=30,
                labels={'x': 'FrequÃªncia de coocorrÃªncia', 'y': 'NÃºmero de pares'},
                title="DistribuiÃ§Ã£o das FrequÃªncias"
            )

            st.plotly_chart(fig3, use_container_width=True)

        st.divider()

        # ========== SUB-ABA 4: GRAFO ==========
        with t4:
            st.header("ğŸ•¸ï¸ AnÃ¡lise do Grafo")

            # MÃ©tricas do grafo
            col1, col2, col3, col4 = st.columns(4)

            col1.metric("NÃ³s", len(G.nodes()))
            col2.metric("Arestas", len(G.edges()))

            if len(G.nodes()) > 0:
                col3.metric("Densidade", f"{nx.density(G):.4f}")
                avg_degree = sum(dict(G.degree()).values()) / len(G.nodes())
                col4.metric("Grau MÃ©dio", f"{avg_degree:.2f}")

            if len(G.nodes()) > 0:
                st.divider()

                # Centralidade
                st.subheader("ğŸ“Š AnÃ¡lise de Centralidade")

                tipo_centralidade = st.selectbox(
                    "Tipo de centralidade:",
                    ["Grau", "IntermediaÃ§Ã£o", "Proximidade"],
                    key="centrality_type"
                )

                if tipo_centralidade == "Grau":
                    centrality = nx.degree_centrality(G)
                elif tipo_centralidade == "IntermediaÃ§Ã£o":
                    centrality = nx.betweenness_centrality(G)
                else:
                    centrality = nx.closeness_centrality(G)

                top_central = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:20]

                df_central = pd.DataFrame(top_central, columns=['Conceito', 'Centralidade'])

                fig = px.bar(
                    df_central,
                    x='Centralidade',
                    y='Conceito',
                    orientation='h',
                    title=f"Top 20 - Centralidade de {tipo_centralidade}",
                    color='Centralidade',
                    color_continuous_scale='viridis'
                )
                fig.update_layout(
                    height=600,
                    yaxis={'categoryorder': 'total ascending'}
                )

                st.plotly_chart(fig, use_container_width=True)

                st.divider()

                # Comunidades
                st.subheader("ğŸ‘¥ DetecÃ§Ã£o de Comunidades (Cluster)")

                try:
                    from networkx.algorithms import community
                    communities = list(community.greedy_modularity_communities(G))

                    st.metric("NÃºmero de Comunidades", len(communities))

                    for i, comm in enumerate(communities, 1):
                        with st.expander(f"Comunidade {i} ({len(comm)} conceitos)"):
                            members = list(comm)[:20]
                            st.write(", ".join(members))
                            if len(comm) > 20:
                                st.caption(f"... e mais {len(comm)-20} conceitos")

                except Exception as e:
                    st.info("NÃ£o foi possÃ­vel detectar comunidades")

                st.divider()

                # VisualizaÃ§Ã£o interativa
                st.subheader("ğŸ¨ VisualizaÃ§Ã£o Interativa")

                if len(G.nodes()) <= 100:
                    top_viz = st.slider("NÃ³s a visualizar:", 5, min(50, len(G.nodes())), 15, key="viz_nodes")

                    top_nodes = [n for n, _ in sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:top_viz]]

                    Gv = G.subgraph(top_nodes).copy()
                    pos = nx.spring_layout(Gv, k=0.5, iterations=50, seed=42)

                    # Criar traÃ§os
                    edge_trace = go.Scatter(
                        x=[],
                        y=[],
                        mode='lines',
                        line=dict(width=0.5, color='#888'),
                        hoverinfo='none'
                    )

                    for edge in Gv.edges():
                        x0, y0 = pos[edge[0]]
                        x1, y1 = pos[edge[1]]
                        edge_trace['x'] += tuple([x0, x1, None])
                        edge_trace['y'] += tuple([y0, y1, None])

                    node_trace = go.Scatter(
                        x=[],
                        y=[],
                        mode='markers+text',
                        hoverinfo='text',
                        text=[],
                        textposition="top center",
                        marker=dict(
                            size=[],
                            color=[],
                            colorscale='Viridis',
                            showscale=True,
                            colorbar=dict(title="Centralidade")
                        )
                    )

                    for node in Gv.nodes():
                        x, y = pos[node]
                        node_trace['x'] += tuple([x])
                        node_trace['y'] += tuple([y])
                        node_trace['text'] += tuple([node[:20]])
                        node_trace['marker']['size'] += tuple([centrality[node] * 50 + 10])
                        node_trace['marker']['color'] += tuple([centrality[node]])

                    fig = go.Figure(
                        data=[edge_trace, node_trace],
                        layout=go.Layout(
                            title="Rede Interativa de Conceitos",
                            showlegend=False,
                            hovermode='closest',
                            margin=dict(b=0, l=0, r=0, t=40),
                            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                            height=700
                        )
                    )

                    st.plotly_chart(fig, use_container_width=True)

                else:
                    st.warning("âš ï¸ Grafo muito grande (>100 nÃ³s). Use filtros para reduzir o tamanho.")

        st.divider()

        # ========== SUB-ABA 5: MAPA TEMÃTICO =========
        with t5:
            st.header("ğŸ—ºï¸ Mapa TemÃ¡tico (Diagrama EstratÃ©gico)")

            st.markdown("""
            O **Mapa TemÃ¡tico** organiza os conceitos em clusters e os classifica em quatro quadrantes
            a partir de centralidade (importÃ¢ncia no campo) e densidade (coesÃ£o interna):

            - ğŸ¯ **Temas Motores**: Centrais e bem desenvolvidos (PRIORIZE)
            - ğŸ”· **Temas Nicho**: Especializados e coesos
            - ğŸ”¶ **Temas BÃ¡sicos**: Transversais, mas em desenvolvimento
            - ğŸ”´ **Temas Emergentes / Declinantes**: Fronteiras de pesquisa
            """)

            if len(G.nodes()) < 5:
                st.warning("âš ï¸ Poucos conceitos no grafo para gerar um mapa temÃ¡tico confiÃ¡vel (mÃ­nimo â‰ˆ 10).")
            else:
                col1, col2 = st.columns(2)

                with col1:
                    cluster_method = st.selectbox(
                        "MÃ©todo de ClusterizaÃ§Ã£o:",
                        ["louvain", "greedy"],
                        help="Algoritmo para detectar comunidades no grafo de coocorrÃªncias"
                    )

                with col2:
                    min_cluster_size = st.slider(
                        "Tamanho mÃ­nimo do cluster:",
                        min_value=2,
                        max_value=10,
                        value=3,
                        help="Quantidade mÃ­nima de conceitos por cluster"
                    )

                if st.button("ğŸ” Gerar Mapa TemÃ¡tico", type="primary", key="generate_thematic_map"):
                    try:
                        from thematic_map_module import ThematicMapAnalyzer

                        with st.spinner("ğŸ”„ Detectando clusters e calculando mÃ©tricas do mapa temÃ¡tico..."):
                            tm_analyzer = ThematicMapAnalyzer(G, concepts_lists)
                            tm_analyzer.detect_clusters(
                                method=cluster_method,
                                min_size=min_cluster_size
                            )
                            metrics_df = tm_analyzer.analyze_clusters()

                        if metrics_df is None or len(metrics_df) == 0:
                            st.warning("âš ï¸ Nenhum cluster detectado. Verifique os parÃ¢metros ou amplie o corpus.")
                        else:
                            # ---------- Converter mÃ©tricas em estrutura 'thematic_data' ----------
                            thematic_data = []
                            tipo_map = {
                                "Q1: Motor Themes": "Motor Theme",
                                "Q2: Basic/Transversal Themes": "Basic Theme",
                                "Q3: Niche Themes": "Niche Theme",
                                "Q4: Emerging/Declining Themes": "Emerging/Declining Theme",
                            }

                            centralidades = []
                            densidades = []

                            # garante alinhamento: mesma ordem de metrics_df e tm_analyzer.clusters
                            for idx, row in metrics_df.reset_index(drop=True).iterrows():
                                quadrante = ThematicMapAnalyzer.classify_quadrant(
                                    row["centralidade_norm"],
                                    row["densidade_norm"]
                                )
                                tipo = tipo_map.get(quadrante, "Basic Theme")

                                # conceitos do cluster (set -> lista ordenada)
                                conceitos_cluster = sorted(tm_analyzer.clusters[idx])
                                tamanho_cluster = len(conceitos_cluster)

                                # conceito principal: primeiro da lista de principais ou primeiro do cluster
                                if isinstance(row.get("conceitos_principais", ""), str) and row["conceitos_principais"].strip():
                                    conceito_principal = row["conceitos_principais"].split(",")[0].strip()
                                else:
                                    conceito_principal = conceitos_cluster[0] if conceitos_cluster else ""

                                registro = {
                                    "cluster_id": idx + 1,
                                    "nome": row["nome"],
                                    "tipo": tipo,
                                    "tamanho": tamanho_cluster,
                                    "centralidade": float(row["centralidade"]),
                                    "densidade": float(row["densidade"]),
                                    "conceitos": conceitos_cluster,
                                    "conceito_principal": conceito_principal,
                                }

                                thematic_data.append(registro)
                                centralidades.append(registro["centralidade"])
                                densidades.append(registro["densidade"])

                            if not thematic_data:
                                st.warning("âš ï¸ Clusters foram detectados, mas nÃ£o foi possÃ­vel montar o mapa temÃ¡tico.")
                            else:
                                # ---------- MÃ©tricas de topo ----------
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    st.metric("Total de Clusters", len(thematic_data))
                                with col2:
                                    motor_themes = sum(1 for t in thematic_data if t["tipo"] == "Motor Theme")
                                    st.metric("Motor Themes", motor_themes)
                                with col3:
                                    total_concepts = sum(t["tamanho"] for t in thematic_data)
                                    st.metric("Conceitos Agrupados", total_concepts)
                                with col4:
                                    st.metric("Tamanho MÃ©dio", f"{total_concepts / len(thematic_data):.1f}")

                                # ---------- Diagrama estratÃ©gico ----------
                                med_centrality = sum(centralidades) / len(centralidades)
                                med_density = sum(densidades) / len(densidades)

                                color_map = {
                                    "Motor Theme": "#2ecc71",               # verde
                                    "Niche Theme": "#3498db",               # azul
                                    "Emerging/Declining Theme": "#e74c3c",  # vermelho
                                    "Basic Theme": "#f39c12",               # amarelo
                                }

                                colors_list = [color_map.get(t["tipo"], "#95a5a6") for t in thematic_data]

                                fig_mapa = go.Figure()

                                fig_mapa.add_hline(y=med_density, line_dash="dash", line_color="gray")
                                fig_mapa.add_vline(x=med_centrality, line_dash="dash", line_color="gray")

                                fig_mapa.add_trace(go.Scatter(
                                    x=centralidades,
                                    y=densidades,
                                    mode="markers+text",
                                    marker=dict(
                                        size=[20 + t["tamanho"] * 5 for t in thematic_data],
                                        color=colors_list,
                                        line=dict(width=2, color="white"),
                                        opacity=0.85,
                                    ),
                                    text=[f"C{t['cluster_id']}" for t in thematic_data],
                                    textposition="middle center",
                                    textfont=dict(size=10, color="white", family="Arial Black"),
                                    hovertemplate=(
                                        "<b>%{customdata[0]}</b><br>" +
                                        "Centralidade: %{x:.3f}<br>" +
                                        "Densidade: %{y:.3f}<br>" +
                                        "Tipo: %{customdata[1]}<br>" +
                                        "Tamanho: %{customdata[2]} conceitos<br>" +
                                        "<extra></extra>"
                                    ),
                                    customdata=[
                                        [t["nome"], t["tipo"], t["tamanho"]]
                                        for t in thematic_data
                                    ],
                                    showlegend=False
                                ))

                                fig_mapa.update_layout(
                                    title="Diagrama EstratÃ©gico dos Clusters TemÃ¡ticos",
                                    xaxis_title="Centralidade",
                                    yaxis_title="Densidade",
                                    height=600,
                                    plot_bgcolor="white",
                                    xaxis=dict(gridcolor="lightgray"),
                                    yaxis=dict(gridcolor="lightgray"),
                                )

                                st.plotly_chart(fig_mapa, use_container_width=True)

                                # ---------- Detalhamento dos clusters ----------
                                st.markdown("### ğŸ“‹ Detalhamento dos Clusters")

                                tipo_icons = {
                                    "Motor Theme": "ğŸ¯",
                                    "Basic Theme": "ğŸ”¶",
                                    "Niche Theme": "ğŸ’",
                                    "Emerging/Declining Theme": "ğŸ”´",
                                }

                                for cluster in thematic_data:
                                    icon = tipo_icons.get(cluster["tipo"], "âšª")

                                    with st.expander(f"{icon} {cluster['nome']} - {cluster['tipo']}"):
                                        col1, col2 = st.columns([2, 1])

                                        with col1:
                                            st.write("**Conceitos:**")
                                            concepts_display = ", ".join(cluster["conceitos"][:10])
                                            if len(cluster["conceitos"]) > 10:
                                                concepts_display += f" ... (+{len(cluster['conceitos']) - 10} mais)"
                                            st.write(concepts_display)

                                        with col2:
                                            st.metric("Centralidade", f"{cluster['centralidade']:.3f}")
                                            st.metric("Densidade", f"{cluster['densidade']:.3f}")
                                            st.metric("Tamanho", cluster["tamanho"])

                                        # InterpretaÃ§Ã£o sintÃ©tica
                                        if "Motor" in cluster["tipo"]:
                                            st.success("ğŸ¯ Tema central e maduro. **PRIORIZE** na revisÃ£o de literatura.")
                                        elif "Niche" in cluster["tipo"]:
                                            st.info(f"ğŸ’ Tema especializado. Ãštil para nichos relacionados a '{cluster['conceito_principal']}'.")
                                        elif "Basic" in cluster["tipo"]:
                                            st.warning("ğŸ”¶ Tema transversal. Oportunidade para pesquisas integradoras.")
                                        else:
                                            st.error("ğŸ”´ Tema emergente ou em declÃ­nio. Fronteira de pesquisa.")

                            # ---------- ExplicaÃ§Ã£o metodolÃ³gica ----------
                            with st.expander("â„¹ï¸ Sobre a metodologia"):
                                st.markdown("""
                                Este mapa temÃ¡tico segue a lÃ³gica do *Diagrama EstratÃ©gico*:

                                - **Densidade**: mÃ©dia dos pesos das arestas internas do cluster (coesÃ£o interna).
                                - **Centralidade**: soma dos pesos das arestas que ligam o cluster a outros clusters (relevÃ¢ncia global).
                                - A posiÃ§Ã£o de cada cluster no plano Centralidade Ã— Densidade permite interpretar seu papel
                                  na estrutura do campo de pesquisa.

                                ReferÃªncias:

                                - ARIA, M.; CUCCURULLO, C. Bibliometrix: An R-tool for comprehensive science mapping analysis. *Journal of Informetrics*, v.11, n.4, p.959â€“975, 2017. Doi: http://dx.doi.org/10.1016/j.joi.2017.08.007
                                - HE, Q. (1999). Knowledge discovery through co-word analysis. *Library Trends*, v.48, n.1, p.133â€“159, 1999. DisponÃ­vel em: https://www.proquest.com/scholarly-journals/knowledge-discovery-through-co-word-analysis/docview/220452924/se-2 
                                """)

                    except ImportError:
                        st.error("""
                        NÃ£o foi possÃ­vel importar o mÃ³dulo `thematic_map_module`.
                        Verifique se o arquivo `thematic_map_module.py` estÃ¡ no mesmo diretÃ³rio
                        de `streamlit_app.py` e se vocÃª executou a cÃ©lula que o cria no Colab.
                        """)
                    except Exception as e:
                        st.error(f"Erro ao gerar mapa temÃ¡tico: {e}")
                        with st.expander("ğŸ› Detalhes tÃ©cnicos do erro"):
                            st.exception(e)

        # ========== SUB-ABA 6: ESTATÃSTICAS ==========
        with t6:
            st.header("ğŸ“Š EstatÃ­sticas Completas")

            st.subheader("ğŸ“‹ Resumo Geral")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**ğŸ“š Dados:**")
                st.write(f"â€¢ Artigos: {len(articles)}")
                st.write(f"â€¢ Com conceitos: {len(concepts_lists)}")
                if len(articles) > 0:
                    st.write(f"â€¢ Aproveitamento: {len(concepts_lists)/len(articles)*100:.1f}%")
                st.write(f"â€¢ Conceitos total: {len(all_concepts)}")
                st.write(f"â€¢ Ãšnicos: {len(set(all_concepts))}")

            with col2:
                st.markdown("**ğŸ•¸ï¸ Grafo:**")
                st.write(f"â€¢ NÃ³s: {len(G.nodes())}")
                st.write(f"â€¢ Arestas: {len(G.edges())}")
                if len(G.nodes()) > 0:
                    st.write(f"â€¢ Densidade: {nx.density(G):.4f}")
                    if nx.is_connected(G):
                        st.write(f"â€¢ DiÃ¢metro: {nx.diameter(G)}")
                    else:
                        st.write(f"â€¢ DiÃ¢metro: N/A (grafo desconexo)")
                    st.write(f"â€¢ Componentes: {nx.number_connected_components(G)}")

            st.divider()

            # DistribuiÃ§Ãµes
            st.subheader("ğŸ“ˆ DistribuiÃ§Ãµes")

            col1, col2 = st.columns(2)

            with col1:
                if len(G.nodes()) > 0:
                    degrees = [d for n, d in G.degree()]

                    fig = px.histogram(
                        x=degrees,
                        nbins=20,
                        labels={'x': 'Grau', 'y': 'FrequÃªncia'},
                        title="DistribuiÃ§Ã£o de Graus"
                    )

                    st.plotly_chart(fig, use_container_width=True)

            with col2:
                if len(G.edges()) > 0:
                    weights = [d['weight'] for u, v, d in G.edges(data=True)]

                    fig = px.histogram(
                        x=weights,
                        nbins=20,
                        labels={'x': 'Peso', 'y': 'FrequÃªncia'},
                        title="DistribuiÃ§Ã£o dos Pesos das Arestas"
                    )

                    st.plotly_chart(fig, use_container_width=True)

        # ========== SUB-ABA 7: EXPORTAÃ‡ÃƒO ==========
        with t7:
            st.header("ğŸ’¾ ExportaÃ§Ã£o de Dados")

            col1, col2, col3 = st.columns(3)

            # JSON
            with col1:
                st.subheader("ğŸ“„ JSON")

                st.download_button(
                    "ğŸ“¥ Artigos (JSON)",
                    json.dumps(articles, indent=2, ensure_ascii=False),
                    "articles.json",
                    "application/json",
                    use_container_width=True
                )

                st.download_button(
                    "ğŸ“¥ Conceitos (JSON)",
                    json.dumps(concepts_lists, indent=2, ensure_ascii=False),
                    "concepts.json",
                    "application/json",
                    use_container_width=True
                )

                cooc_json = [
                    {"conceito1": c1, "conceito2": c2, "frequencia": f}
                    for (c1, c2), f in pairs.items()
                ]

                st.download_button(
                    "ğŸ“¥ CoocorrÃªncias (JSON)",
                    json.dumps(cooc_json, indent=2, ensure_ascii=False),
                    "cooccurrences.json",
                    "application/json",
                    use_container_width=True
                )

            # CSV
            with col2:
                st.subheader("ğŸ“Š CSV")

                df_articles_export = pd.DataFrame([
                    {
                        'title': a.get('title', ''),
                        'year': a.get('year', ''),
                        'num_concepts': len(a.get('concepts', []))
                    }
                    for a in articles
                ])

                st.download_button(
                    "ğŸ“¥ Artigos (CSV)",
                    df_articles_export.to_csv(index=False),
                    "articles.csv",
                    "text/csv",
                    use_container_width=True
                )

                df_concepts = pd.DataFrame(
                    freq.most_common(),
                    columns=['concept', 'frequency']
                )

                st.download_button(
                    "ğŸ“¥ Conceitos (CSV)",
                    df_concepts.to_csv(index=False),
                    "concepts.csv",
                    "text/csv",
                    use_container_width=True
                )

                edges_list = [[u, v, d['weight']] for u, v, d in G.edges(data=True)]
                df_cooc = pd.DataFrame(edges_list, columns=['source', 'target', 'weight'])

                st.download_button(
                    "ğŸ“¥ CoocorrÃªncias (CSV)",
                    df_cooc.to_csv(index=False),
                    "cooccurrences.csv",
                    "text/csv",
                    use_container_width=True
                )

            # Outros formatos
            with col3:
                st.subheader("ğŸ”§ Outros")

                import tempfile

                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.graphml') as f:
                    nx.write_graphml(G, f.name)
                    with open(f.name, 'r') as file:
                        graphml_content = file.read()

                st.download_button(
                    "ğŸ“¥ Grafo (GraphML)",
                    graphml_content,
                    "graph.graphml",
                    "application/xml",
                    use_container_width=True
                )

                st.caption("Para Gephi/Cytoscape")

            st.divider()

            # Zip completo
            st.subheader("ğŸ“¦ Pacote Completo")

            if st.button("ğŸ Gerar ZIP com Todos os Dados", use_container_width=True):
                with st.spinner("ğŸ“¦ Gerando arquivo ZIP..."):
                    zip_buffer = BytesIO()

                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                        # JSON
                        zf.writestr('articles.json', json.dumps(articles, indent=2, ensure_ascii=False))
                        zf.writestr('concepts.json', json.dumps(concepts_lists, indent=2, ensure_ascii=False))
                        zf.writestr('cooccurrences.json', json.dumps(cooc_json, indent=2, ensure_ascii=False))

                        # CSV
                        zf.writestr('articles.csv', df_articles_export.to_csv(index=False))
                        zf.writestr('concepts.csv', df_concepts.to_csv(index=False))
                        zf.writestr('cooccurrences.csv', df_cooc.to_csv(index=False))

                        # GraphML
                        zf.writestr('graph.graphml', graphml_content)

                        # README
                        readme = f"""# DelinÃ©ia IX - Dados Exportados

Data: {datetime.now().strftime("%d/%m/%Y Ã s %H:%M")}
Query: {query}

## Arquivos incluÃ­dos:

### JSON
- articles.json: Lista completa de artigos
- concepts.json: Conceitos extraÃ­dos por artigo
- cooccurrences.json: Pares de coocorrÃªncias

### CSV
- articles.csv: Artigos (tÃ­tulo, ano, num_conceitos)
- concepts.csv: Conceitos e frequÃªncias
- cooccurrences.csv: Rede de coocorrÃªncias

### Grafo
- graph.graphml: Grafo no formato GraphML (Gephi/Cytoscape)

## EstatÃ­sticas:
- Artigos: {len(articles)}
- Conceitos Ãºnicos: {len(freq)}
- NÃ³s no grafo: {len(G.nodes())}
- Arestas: {len(G.edges())}
"""
                        zf.writestr('README.txt', readme)

                    st.download_button(
                        "ğŸ“¥ Baixar painel_completo.zip",
                        zip_buffer.getvalue(),
                        "painel_completo.zip",
                        "application/zip",
                        use_container_width=True
                    )